{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy.linalg as LA\n",
    "import random\n",
    "import pandas as pd\n",
    "from numpy import inf\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "import pyprind\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data_irl_model/Feb23_data_exploratory_policy.json')\n",
    "#f = open('../data_irl_model/Feb22_dataSVO.json')\n",
    "data_irl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keys=list(data_irl.keys())\n",
    "data_keys.sort()\n",
    "\n",
    "keys_for_training=[]\n",
    "keys_for_testing=[]\n",
    "\n",
    "index=0\n",
    "for vehicle in data_keys:\n",
    "    if index%10==0:\n",
    "        keys_for_testing.append(vehicle)\n",
    "        index+=1\n",
    "    else:\n",
    "        keys_for_training.append(vehicle)\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  [-50.0, -48.00000959491307, -46.000038513319524, -44.000087269879714, -42.000156438656006, -40.00024642268436, -38.00035769377065, -36.00049081444543, -34.00064644271893, -32.00082533931872, -30.00102840504124, -28.00125668872575, -26.00151120767363, -24.001792382791493, -22.002099833316123, -20.002432376013743, -18.002787437319792, -16.003160131001316, -14.003541860606148, -12.003918337158034, -10.004267320991964, -8.004557419881444, -6.004750413867271, -3.9448847480055775, -1.765019082143887, 0.5348465837178011]\n",
      "1:  [-64.01737173704754, -62.83531527736229, -61.533258817677044, -60.1112023579918, -58.56914589830655, -56.907089438621306, -55.12503297893606, -53.222976519250814, -51.20092005956557, -49.05886359988032, -46.79680714019507, -44.435783573886155, -42.03579318943008, -39.63580342381655, -37.23581436583025, -34.83582611992979, -32.435838815383825, -30.035852614743888, -27.635867726241045, -25.23588442248834, -22.83590306972686, -20.435924175542993, -18.035948470786764, -15.635977059163423, -13.236011922538268, -10.836056718052575, -8.436118267962158, -6.036206772818808, -3.63630751453519, -1.2363667387964767]\n",
      "num_timesteps:  20\n"
     ]
    }
   ],
   "source": [
    "key=keys_for_training[97]\n",
    "key=str(key)                \n",
    "############# Create the data for the training locally- we are restricting the number of timesteps to num_timesteps######\n",
    "negative_vals=[]\n",
    "for i in [0,1]:\n",
    "    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "num_timesteps=min(50,len(negative_vals[0]),len(negative_vals[1]))\n",
    "\n",
    "print(\"0: \", negative_vals[0])\n",
    "print(\"1: \", negative_vals[1])\n",
    "\n",
    "print(\"num_timesteps: \", num_timesteps)\n",
    "\n",
    "key=keys_for_training[159]\n",
    "\n",
    "key=str(key)  \n",
    "\n",
    "negative_vals=[]\n",
    "\n",
    "for i in [0,1]:\n",
    "    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "\n",
    "num_timesteps=min(50,len(negative_vals[0]),len(negative_vals[1]))\n",
    "\n",
    "index_before_zero=data_irl[key][1].index(negative_vals[1][len(negative_vals[1])-1])\n",
    "\n",
    "print(index_before_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################################ AIS_gen ################################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class GenerateAis1(nn.Module):\n",
    "\n",
    "    #def __init__(self,n_input,n_state,n_psi2_in=64,n_psi2_out=128):\n",
    "    def __init__(self,n_input,n_state,n_psi2_in=8,n_psi2_out=16):\n",
    "        super(GenerateAis1,self).__init__()\n",
    "        self.PSI_layer1=nn.Linear(n_input,n_psi2_in)     # Use RELU after\n",
    "        self.PSI_layer2=nn.Linear(n_psi2_in,n_psi2_out)      # Use RELU after\n",
    "        self.PSI_layer3=nn.GRUCell(n_psi2_out,n_state)       # This is the Gated layer\n",
    "\n",
    "    def forward(self,x,h):\n",
    "        #x=torch.transpose(x,0,1)\n",
    "        #h=torch.transpose(h,0,1)\n",
    "        x=torch.relu(self.PSI_layer1(x))\n",
    "        x=torch.relu(self.PSI_layer2(x))\n",
    "        h=self.PSI_layer3(x,h)\n",
    "        return h     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################################ AIS_pred ###############################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class PredictAis1(nn.Module):\n",
    "    \n",
    "    #def __init__(self,n_output,n_state,n_phi2_in=16,n_phi2_out=8):\n",
    "    def __init__(self,n_output,n_decoder_in,n_phi2_in=6,n_phi2_out=8):\n",
    "        super(PredictAis1,self).__init__()\n",
    "        self.PHI_layer1=nn.Linear(n_decoder_in,n_phi2_in)  # Use RELU after\n",
    "        self.PHI_layer2=nn.Linear(n_phi2_in,n_phi2_out)     # Use RELU after\n",
    "        self.PHI_layer3=nn.Linear(n_phi2_out,n_output)         # mean vector of a unit-variance multivariate Gaussian distribution, samples from which are used to predict the next observation\n",
    "\n",
    "    # x here is the hidden state and the current action that is chosen \n",
    "    # to predict the next observations for the horizon\n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.PHI_layer1(x))\n",
    "        x=torch.relu(self.PHI_layer2(x))\n",
    "        output=self.PHI_layer3(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_structure(object):\n",
    "    def __init__(self,n_epochs,min_timesteps,n_rollout,n_skips_per_rollout,n_test,n_input,n_output,n_state_enc,learning_rate,ais_gen_model,ais_pred_model,device):\n",
    "        self.n_epochs=n_epochs\n",
    "        self.min_timesteps=min_timesteps\n",
    "        self.rollout=n_rollout\n",
    "        self.n_skips=n_skips_per_rollout\n",
    "        self.n_test=n_test\n",
    "        self.n_input=n_input\n",
    "        self.n_output=n_output\n",
    "        self.n_state_enc=n_state_enc    # Hidden state size in RNN\n",
    "        self.learning_rate=learning_rate                \n",
    "        self.device=device\n",
    "        self.ais_gen_model=ais_gen_model\n",
    "        self.ais_pred_model=ais_pred_model\n",
    "\n",
    "        self.n_psi2_in=8\n",
    "        self.n_psi2_out=16\n",
    "        self.n_phi2_in=2\n",
    "        self.n_phi2_out=4\n",
    "        self.n_psi1_out=8\n",
    "        \n",
    "        if ais_gen_model==1:\n",
    "            self.gen_model=GenerateAis1(self.n_input,self.n_state_enc).to(self.device)      \n",
    "        \n",
    "        #if ais_gen_model==2: \n",
    "            #self.gen_model=GenerateAis2(self.n_input,self.n_state_enc,self.n_psi1_out).to(self.device)        \n",
    "            #self.gen_model=GenerateAis2_LSTM(self.n_input,self.n_state_enc,self.n_psi1_out).to(self.device)\n",
    "            #self.gen_model=GenerateAis_LSTMShallow(self.n_input,self.n_state_enc).to(self.device)  \n",
    "\n",
    "        if ais_pred_model==1:\n",
    "            self.pred_model=PredictAis1(self.n_output,self.n_state_enc+1).to(self.device) # self.n_state_enc+1 implies ais_t and the (action of cav)_t\n",
    "        \n",
    "        #if ais_pred_model==2:\n",
    "            #self.pred_model=PredictAis2(self.n_output,self.n_state_enc+1,self.n_state_dec).to(self.device)\n",
    "            #self.pred_model=PredictAis2_LSTM(self.n_output,self.n_state_enc+1,self.n_state_dec).to(self.device)\n",
    "            #self.pred_model=PredictAis_LSTMShallow(self.n_state_enc+1,self.n_state_dec).to(self.device)\n",
    "\n",
    "    def save_model_weights(self,text=\"(:*_*:)\"):\n",
    "        #name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "        #torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        \n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        if self.ais_pred_model==1:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "\n",
    "        if self.ais_pred_model==2:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_multi_rnn_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_multi_rnn_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "\n",
    "        torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "\n",
    "        return \"saved\"\n",
    "    \n",
    "    def load_model_weights(self,text=\"(:*_*:)\"):\n",
    "        #name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "        #torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        #self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        #self.gen_model.eval()\n",
    "\n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        \n",
    "        if self.ais_pred_model==1:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "\n",
    "        if self.ais_pred_model==2:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_multi_rnn_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_multi_rnn_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "        \n",
    "        #torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "        self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        self.gen_model.eval()\n",
    "\n",
    "        self.pred_model.load_state_dict(torch.load(name_pred_path))\n",
    "        self.pred_model.eval()\n",
    "\n",
    "        print(\"names of files-Encoder\",name_gen_path,\"\\n\")\n",
    "        print(\"names of files-Decoder\",name_pred_path,\"\\n\")\n",
    "\n",
    "        return \"loaded\"\n",
    "    \n",
    "\n",
    "    def train(self,load_previous_weights=\"False\"):\n",
    "        print(\"LOading previous weights\")\n",
    "        # Load previous weights\n",
    "        #if load_previous_weights==\"True\":\n",
    "        print(\"Got into the loop!\")\n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        text_load=\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included\"\n",
    "        name_pred_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(200)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text_load+\".pth\"\n",
    "        name_gen_path=\"../trained_models/IRL_based_models/IRL_explorepolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(200)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text_load+\".pth\"\n",
    "\n",
    "        self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        self.gen_model.eval()\n",
    "\n",
    "        self.pred_model.load_state_dict(torch.load(name_pred_path))\n",
    "        self.pred_model.eval()      \n",
    "\n",
    "        print(\"Loaded trained weights\")     \n",
    "\n",
    "        train_bar=pyprind.ProgBar(self.n_epochs)\n",
    "        self.optimizer = torch.optim.Adam(list(self.gen_model.parameters()) + list(self.pred_model.parameters()), lr=self.learning_rate, amsgrad=True)\n",
    "\n",
    "        time_step_loss=0\n",
    "        for epoch in range(200,self.n_epochs):\n",
    "\n",
    "            train_bar.update()\n",
    "            keys_training=sample(keys_for_training,len(keys_for_training)) #shuffle the keys\n",
    "            #train_bar=pyprind.ProgBar(len(keys_for_training))\n",
    "            epoch_loss=0\n",
    "            for key in keys_training:\n",
    "                #for key in keys_for_testing[0]:\n",
    "                #train_bar.update()\n",
    "                key=str(key) \n",
    "                #print(key)                               \n",
    "                ############# Create the data for the training locally- we are restricting the number of timesteps to num_timesteps ######\n",
    "                negative_vals=[]\n",
    "                for i in [0,1]:\n",
    "                    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "                num_timesteps=min(self.min_timesteps,len(negative_vals[0]),len(negative_vals[1]))\n",
    "                index_before_zero=data_irl[key][1].index(negative_vals[1][len(negative_vals[1])-1])\n",
    "                #print(\"index_before_zero: \", index_before_zero)\n",
    "                #num_timesteps=20\n",
    "                indices_to_train=[]\n",
    "                if index_before_zero-num_timesteps>=0:\n",
    "                    indices_to_train=range(index_before_zero-num_timesteps,index_before_zero+1)\n",
    "                else:\n",
    "                    indices_to_train=range(0,index_before_zero+2)\n",
    "                #print(\"ndices_to_train: \", indices_to_train)\n",
    "                #######################################\n",
    "\n",
    "                #### IMPORTANT Cropping the indices as per availability of data - \n",
    "                # What if index_before_zero == length of the list and we are looking \n",
    "                # to predict data that is in existent\n",
    "\n",
    "                '''\n",
    "                ## No skip between predictions\n",
    "                indices_to_train_cropped=[]\n",
    "                if index_before_zero in [len(data_irl[key][1])-1,len(data_irl[key][1])-2,len(data_irl[key][1])-3]:\n",
    "                    indices_to_train_cropped=indices_to_train[0:-1*self.rollout]\n",
    "                else:\n",
    "                    indices_to_train_cropped=indices_to_train\n",
    "                '''\n",
    "                \n",
    "                ## Use this when we want to skip between predictions\n",
    "                ## Skip indicates the predicitons are for t+n_skips,t+2*n_skips,t+3*n_skips,...\n",
    "                indices_to_train_cropped=[]\n",
    "                if index_before_zero in range(len(data_irl[key][1])-1,len(data_irl[key][1])-self.rollout*(self.n_skips+1),-1):\n",
    "                    indices_to_train_cropped=indices_to_train[0:-self.rollout*(self.n_skips+1)]\n",
    "                else:\n",
    "                    indices_to_train_cropped=indices_to_train\n",
    "\n",
    "                # Ais initialization\n",
    "                ais_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device)\n",
    "                state_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device) # Only if we use a LSTM\n",
    "                action_list=[0,0] ## initialize the action list differently - but we can try giving it the actual values to iterate                \n",
    "\n",
    "                time_step_loss=0\n",
    "\n",
    "                # Initialize the origin offset only for position\n",
    "                #origin_offset_CAV=data_irl[key][0][indices_to_train[0]]\n",
    "                #origin_offset_HDV=data_irl[key][1][indices_to_train[0]]\n",
    "                origin_offset_CAV=0    \n",
    "                origin_offset_HDV=0\n",
    "\n",
    "                for time_step in indices_to_train_cropped:\n",
    "\n",
    "                    observation_list=[]\n",
    "                    for i in range(len(data_irl[key])-2): # exclude the last two columns (actions/inputs)\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if i==0:\n",
    "                            temp=temp-origin_offset_CAV\n",
    "                        elif i==1:\n",
    "                            temp=temp-origin_offset_HDV\n",
    "                        if temp!= None:\n",
    "                            observation_list.append(temp)\n",
    "                    input_list=[]\n",
    "                    input_list.extend(observation_list)\n",
    "                    input_list.extend(action_list)\n",
    "                    input_tensor=torch.tensor(input_list,dtype=torch.float).to(self.device)                    \n",
    "\n",
    "                    # Update action list for the next time step \n",
    "                    for i in [4,5]:\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if temp!= None:\n",
    "                            action_list[i-4]=temp\n",
    "                        else:\n",
    "                            action_list[i-4]=0\n",
    "\n",
    "                    '''\n",
    "                    ### For no skip between predictions\n",
    "                    reference_list=[]\n",
    "                    for k in range(self.rollout):\n",
    "                        for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                            if i==1:# min is self.rollout\n",
    "                                #rint(\"key\",key)\n",
    "                                #print(\"i\",i)\n",
    "                                #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                            \n",
    "                            elif i==3:\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                            elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                reference_list.append(data_irl[key][i][time_step+k])\n",
    "                            \n",
    "                            else:\n",
    "                                reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                    '''\n",
    "\n",
    "                    \n",
    "                    ### Skip between predictions\n",
    "                    reference_list=[]\n",
    "                    if (time_step+self.rollout*(self.n_skips+1))>=len(data_irl[key][i]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        for k in range(self.n_skips,self.rollout*(self.n_skips+1),self.n_skips+1):\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is self.rollout\n",
    "                                    #rint(\"key\",key)\n",
    "                                    #print(\"i\",i)\n",
    "                                    #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                                           \n",
    "\n",
    "                    '''\n",
    "                    # This is to be as 3* as long as the number of rollouts - 3 for each rollout\n",
    "                    internal_rollout=min(self.rollout,len(data_irl[key][0])-time_step-2)\n",
    "                    \n",
    "\n",
    "                    reference_list=[]\n",
    "\n",
    "                    if internal_rollout==self.rollout:\n",
    "                        for k in range(self.rollout):\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is self.rollout\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "                            \n",
    "                    else:\n",
    "                        for k in range(internal_rollout):\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is not self.rollout\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "                                    \n",
    "                        for k in range(internal_rollout,self.rollout):\n",
    "                            for i in [1,3,5]:\n",
    "                                reference_list.append(0)\n",
    "                    '''\n",
    "\n",
    "\n",
    "                    reference_tensor=torch.tensor(reference_list,dtype=torch.float).to(self.device)\n",
    "                    ais_rollout_enc=self.gen_model(input_tensor,ais_rollout_enc)\n",
    "                    # Adding the (action of CAV)_t as an inpug to the decoder\n",
    "                    decoder_input=torch.cat((ais_rollout_enc,torch.tensor([action_list[0]],dtype=torch.float).to(self.device)),dim=0)\n",
    "\n",
    "                    decoder_prediction=self.pred_model(decoder_input)\n",
    "\n",
    "                    ## Mulitvariate normal distribution loss\n",
    "                    #time_step_loss+=torch.distributions.MultivariateNormal(decoder_prediction,torch.eye(self.n_output).to(self.device)).log_prob(reference_tensor)\n",
    "                    ## MSE loss\n",
    "                    time_step_loss+=torch.nn.functional.mse_loss(decoder_prediction,reference_tensor)                    \n",
    "                    #print(\"time_step_loss: \",time_step_loss)\n",
    "                    #print(\"reference_tensor: \",reference_tensor)\n",
    "                    #print(\"decoder_prediction: \",decoder_prediction,\"\\n\")\n",
    "                    \n",
    "                    \n",
    "               \n",
    "                epoch_loss+=time_step_loss\n",
    "                self.optimizer.zero_grad()\n",
    "                time_step_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                ## Printing the gradients\n",
    "                '''\n",
    "                print(\"Printing the gradients-encoder\")\n",
    "                print(self.gen_model.PSI_layer3.weight_ih.grad)\n",
    "                print(self.gen_model.PSI_layer3.weight_hh.grad)\n",
    "                print(self.gen_model.PSI_layer3.bias_ih.grad)\n",
    "                print(self.gen_model.PSI_layer3.bias_hh.grad)\n",
    "\n",
    "                print(\"Printing the gradients-decoder\")                \n",
    "                print(self.pred_model.PHI_layer1.weight.grad)\n",
    "                print(self.pred_model.PHI_layer2.weight.grad)\n",
    "                print(self.pred_model.PHI_layer3.weight.grad)           \n",
    "                '''\n",
    "                \n",
    "            print(\"epoch_loss is \",epoch_loss,\"\\n\")                \n",
    "            print(\"saving model weights for epoch \",epoch)\n",
    "            #status=self.save_model_weights(\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_Multivarloss\")\n",
    "            status=self.save_model_weights(\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included\")\n",
    "\n",
    "    def test(self,test_key):\n",
    "            test_results=[]\n",
    "            time_step_loss=0\n",
    "            keys_testing=keys_for_testing[test_key]# sample(keys_for_training,len(keys_for_training)) #shuffle the keys\n",
    "            #train_bar=pyprind.ProgBar(len(keys_for_training))\n",
    "            epoch_loss=0\n",
    "            for key in keys_testing:\n",
    "                #for key in keys_for_testing[0]:\n",
    "                #train_bar.update()\n",
    "                key=str(key) \n",
    "                #print(key)                               \n",
    "                ############# Create the data for the training locally- we are restricting the number of timesteps to num_timesteps ######\n",
    "                negative_vals=[]\n",
    "                for i in [0,1]:\n",
    "                    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "                num_timesteps=min(self.min_timesteps,len(negative_vals[0]),len(negative_vals[1]))\n",
    "                index_before_zero=data_irl[key][1].index(negative_vals[1][len(negative_vals[1])-1])\n",
    "                #print(\"index_before_zero: \", index_before_zero)\n",
    "                #num_timesteps=20\n",
    "                indices_to_test=[]\n",
    "                if index_before_zero-num_timesteps>=0:\n",
    "                    indices_to_test=range(index_before_zero-num_timesteps,index_before_zero+1)\n",
    "                else:\n",
    "                    indices_to_test=range(0,index_before_zero+2)\n",
    "                #print(\"ndices_to_train: \", indices_to_train)\n",
    "                #######################################\n",
    "\n",
    "                #### IMPORTANT Cropping the indices as per availability of data - \n",
    "                # What if index_before_zero == length of the list and we are looking \n",
    "                # to predict data that is in existent\n",
    "\n",
    "                '''\n",
    "                ## No skip between predictions\n",
    "                indices_to_train_cropped=[]\n",
    "                if index_before_zero in [len(data_irl[key][1])-1,len(data_irl[key][1])-2,len(data_irl[key][1])-3]:\n",
    "                    indices_to_train_cropped=indices_to_train[0:-1*self.rollout]\n",
    "                else:\n",
    "                    indices_to_train_cropped=indices_to_train\n",
    "                '''\n",
    "                \n",
    "                ## Use this when we want to skip between predictions\n",
    "                ## Skip indicates the predicitons are for t+n_skips,t+2*n_skips,t+3*n_skips,...\n",
    "                indices_to_test_cropped=[]\n",
    "                if index_before_zero in range(len(data_irl[key][1])-1,len(data_irl[key][1])-self.rollout*(self.n_skips+1),-1):\n",
    "                    indices_to_test_cropped=indices_to_test[0:-self.rollout*(self.n_skips+1)]\n",
    "                else:\n",
    "                    indices_to_test_cropped=indices_to_test\n",
    "\n",
    "                # Ais initialization\n",
    "                ais_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device)\n",
    "                state_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device) # Only if we use a LSTM\n",
    "                action_list=[0,0] ## initialize the action list differently - but we can try giving it the actual values to iterate                \n",
    "\n",
    "                time_step_loss=0\n",
    "\n",
    "                # Initialize the origin offset only for position\n",
    "                #origin_offset_CAV=data_irl[key][0][indices_to_train[0]]\n",
    "                #origin_offset_HDV=data_irl[key][1][indices_to_train[0]]\n",
    "                \n",
    "                # For now we are not doing origin offset \n",
    "                origin_offset_CAV=0    \n",
    "                origin_offset_HDV=0\n",
    "\n",
    "                for time_step in indices_to_test_cropped:\n",
    "\n",
    "                    observation_list=[]\n",
    "                    for i in range(len(data_irl[key])-2): # exclude the last two columns (actions/inputs)\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if i==0:\n",
    "                            temp=temp-origin_offset_CAV\n",
    "                        elif i==1:\n",
    "                            temp=temp-origin_offset_HDV\n",
    "                        if temp!= None:\n",
    "                            observation_list.append(temp)\n",
    "                    input_list=[]\n",
    "                    input_list.extend(observation_list)\n",
    "                    input_list.extend(action_list)\n",
    "                    input_tensor=torch.tensor(input_list,dtype=torch.float).to(self.device) \n",
    "\n",
    "                    print(\"observation_list\",observation_list)                   \n",
    "                    print(\"action_list\",action_list)                   \n",
    "\n",
    "\n",
    "                    # Update action list for the next time step \n",
    "                    for i in [4,5]:\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if temp!= None:\n",
    "                            action_list[i-4]=temp\n",
    "                        else:\n",
    "                            action_list[i-4]=0\n",
    "                    \n",
    "                    print(\"new_action_list\",action_list) \n",
    "\n",
    "                    '''\n",
    "                    ### For no skip between predictions\n",
    "                    reference_list=[]\n",
    "                    for k in range(self.rollout):\n",
    "                        for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                            if i==1:# min is self.rollout\n",
    "                                #rint(\"key\",key)\n",
    "                                #print(\"i\",i)\n",
    "                                #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                            \n",
    "                            elif i==3:\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                            elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                reference_list.append(data_irl[key][i][time_step+k])\n",
    "                            \n",
    "                            else:\n",
    "                                reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                    '''\n",
    "\n",
    "                    \n",
    "                    ### Skip between predictions\n",
    "                    reference_list=[]\n",
    "                    if (time_step+self.rollout*(self.n_skips+1))>=len(data_irl[key][i]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        for k in range(self.n_skips,self.rollout*(self.n_skips+1),self.n_skips+1):\n",
    "                            #print(range(self.n_skips,self.rollout*(self.n_skips+1),self.n_skips+1))\n",
    "                            #print(\"k\",k,\"\\n\")\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is self.rollout\n",
    "                                    #rint(\"key\",key)\n",
    "                                    #print(\"i\",i)\n",
    "                                    #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "\n",
    "                    reference_tensor=torch.tensor(reference_list,dtype=torch.float).to(self.device)\n",
    "                    \n",
    "                    temp=[]\n",
    "                    temp.append(reference_tensor.detach().cpu().numpy().tolist())\n",
    "\n",
    "                    ais_rollout_enc=self.gen_model(input_tensor,ais_rollout_enc)\n",
    "                    # Adding the (action of CAV)_t as an inpug to the decoder\n",
    "                    decoder_input=torch.cat((ais_rollout_enc,torch.tensor([action_list[0]],dtype=torch.float).to(self.device)),dim=0)\n",
    "\n",
    "                    decoder_prediction=self.pred_model(decoder_input)\n",
    "\n",
    "                    ## Mulitvariate normal distribution loss\n",
    "                    #time_step_loss+=torch.distributions.MultivariateNormal(decoder_prediction,torch.eye(self.n_output).to(self.device)).log_prob(reference_tensor)\n",
    "                    ## MSE loss\n",
    "                    time_step_loss+=torch.nn.functional.mse_loss(decoder_prediction,reference_tensor)                    \n",
    "                    #print(\"time_step_loss: \",time_step_loss)\n",
    "                    print(\"time_step: \",time_step)\n",
    "                    print(\"reference_tensor: \",reference_tensor)\n",
    "                    print(\"decoder_prediction: \",decoder_prediction,\"\\n\")\n",
    "\n",
    "                    temp.append(decoder_prediction.detach().cpu().numpy().tolist())\n",
    "                    test_results.append(temp)\n",
    "                \n",
    "            return test_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Parameters #######\n",
    "n_epochs=400\n",
    "min_timesteps=50\n",
    "n_rollout=10\n",
    "n_skips_per_rollout=0\n",
    "n_test=1\n",
    "n_input=6\n",
    "n_output=n_rollout*3 # 3 for each of the next n_rollout time steps\n",
    "n_state_enc=4\n",
    "learning_rate=0.0003\n",
    "gen_model=1\n",
    "pred_model=1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for k in range(n_skips_per_rollout,n_rollout*(n_skips_per_rollout+1),n_skips_per_rollout+1):\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started\n",
      "LOading previous weights\n",
      "Got into the loop!\n",
      "Loaded trained weights\n",
      "epoch_loss is  tensor(54801.7031, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  200\n",
      "epoch_loss is  tensor(53587.1094, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  201\n",
      "epoch_loss is  tensor(53245.1133, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  202\n",
      "epoch_loss is  tensor(52380.9375, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  203\n",
      "epoch_loss is  tensor(52078.6719, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  204\n",
      "epoch_loss is  tensor(52110.9375, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  205\n",
      "epoch_loss is  tensor(52262.3398, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  206\n",
      "epoch_loss is  tensor(52553.7031, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  207\n",
      "epoch_loss is  tensor(51580.9805, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  208\n",
      "epoch_loss is  tensor(51660.1367, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  209\n",
      "epoch_loss is  tensor(51998.5625, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  210\n",
      "epoch_loss is  tensor(51562.3711, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#                             ] 100% | ETA: 16:55:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(51268.4961, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  212\n",
      "epoch_loss is  tensor(51149.0352, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  213\n",
      "epoch_loss is  tensor(51361.9414, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  214\n",
      "epoch_loss is  tensor(51086.9297, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  215\n",
      "epoch_loss is  tensor(51396.6094, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  216\n",
      "epoch_loss is  tensor(51025.2422, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  217\n",
      "epoch_loss is  tensor(50851.7266, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  218\n",
      "epoch_loss is  tensor(50632.2891, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  219\n",
      "epoch_loss is  tensor(50970.0117, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  220\n",
      "epoch_loss is  tensor(50488.7266, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  221\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m network\u001b[39m=\u001b[39mNN_structure(n_epochs,min_timesteps,n_rollout,n_skips_per_rollout,n_test,n_input,n_output,n_state_enc,learning_rate,gen_model,pred_model,device)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining has started\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m network\u001b[39m.\u001b[39;49mtrain(load_previous_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[7], line 304\u001b[0m, in \u001b[0;36mNN_structure.train\u001b[1;34m(self, load_previous_weights)\u001b[0m\n\u001b[0;32m    302\u001b[0m epoch_loss\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mtime_step_loss\n\u001b[0;32m    303\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 304\u001b[0m time_step_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    307\u001b[0m \u001b[39m## Printing the gradients\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nish\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nish\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####### Initialise the neural network #######\n",
    "\n",
    "network=NN_structure(n_epochs,min_timesteps,n_rollout,n_skips_per_rollout,n_test,n_input,n_output,n_state_enc,learning_rate,gen_model,pred_model,device)\n",
    "\n",
    "print(\"Training has started\")\n",
    "network.train(load_previous_weights=True)\n",
    "\n",
    "## try with shifted origin\n",
    "## try shifted origin with both 1 and 0.1 standard deviation \n",
    "\n",
    "# Ended with epoch 221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names of files-Encoder ../trained_models/IRL_based_models/IRL_explorepolicy_ais_gen1_816_pred1_24_epochs200_learning_rate0.0003_hidden_states4encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included.pth \n",
      "\n",
      "names of files-Decoder ../trained_models/IRL_based_models/IRL_explorepolicy_ais_pred1_24_gen1_816_epochs200_learning_rate0.0003_hidden_states4encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included.pth \n",
      "\n",
      "observation_list [-50.0, -61.86467554171904, 10.0, 7.39800250381899]\n",
      "action_list [0, 0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  0\n",
      "reference_tensor:  tensor([-60.4851,   6.3980,  -5.0000, -59.3055,   5.3980,  -5.0000, -58.3259,\n",
      "          4.3980,  -5.0000, -57.5463,   3.3980,  -5.0000, -56.9667,   2.3980,\n",
      "         -5.0000, -56.5871,   1.3980,  -5.0000, -56.4075,   0.3980,  -5.0000,\n",
      "        -56.3677,   0.0000,  -1.9900, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-60.8954,   7.5233,  -2.0630, -59.4258,   7.1647,  -1.9498, -57.9909,\n",
      "          6.8326,  -1.9006, -56.6597,   6.4936,  -1.8697, -55.4448,   6.1418,\n",
      "         -1.8182, -54.1980,   5.6982,  -1.7081, -53.0972,   5.4217,  -1.6085,\n",
      "        -52.0719,   5.1774,  -1.3852, -51.0500,   4.9402,  -1.1371, -49.9937,\n",
      "          4.7248,  -0.9227], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-48.1, -60.48507504095524, 9.0, 6.39800250381899]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  1\n",
      "reference_tensor:  tensor([-59.3055,   5.3980,  -5.0000, -58.3259,   4.3980,  -5.0000, -57.5463,\n",
      "          3.3980,  -5.0000, -56.9667,   2.3980,  -5.0000, -56.5871,   1.3980,\n",
      "         -5.0000, -56.4075,   0.3980,  -5.0000, -56.3677,   0.0000,  -1.9900,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-5.9024e+01,  5.0453e+00, -5.9781e+00, -5.8140e+01,  3.9529e+00,\n",
      "        -5.5664e+00, -5.7452e+01,  2.9460e+00, -4.9771e+00, -5.6973e+01,\n",
      "         2.0925e+00, -4.2704e+00, -5.6615e+01,  1.4030e+00, -3.4761e+00,\n",
      "        -5.6386e+01,  8.7431e-01, -2.6624e+00, -5.6268e+01,  4.8472e-01,\n",
      "        -1.9695e+00, -5.6194e+01,  1.7130e-01, -1.4153e+00, -5.6157e+01,\n",
      "        -2.6489e-02, -9.9185e-01, -5.6212e+01, -1.4098e-01, -6.6467e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-46.4, -59.30547454019144, 8.0, 5.39800250381899]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  2\n",
      "reference_tensor:  tensor([-58.3259,   4.3980,  -5.0000, -57.5463,   3.3980,  -5.0000, -56.9667,\n",
      "          2.3980,  -5.0000, -56.5871,   1.3980,  -5.0000, -56.4075,   0.3980,\n",
      "         -5.0000, -56.3677,   0.0000,  -1.9900, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-58.0867,   4.0706,  -6.1039, -57.4002,   2.9566,  -5.5947, -56.9317,\n",
      "          1.9499,  -4.8812, -56.6454,   1.1319,  -4.0364, -56.4516,   0.5058,\n",
      "         -3.1143, -56.4213,   0.1157,  -2.2214, -56.4432,  -0.2064,  -1.4701,\n",
      "        -56.4838,  -0.4470,  -0.9564, -56.5732,  -0.5648,  -0.6039, -56.7754,\n",
      "         -0.6053,  -0.3471], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-44.9, -58.325874039427646, 7.0, 4.39800250381899]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  3\n",
      "reference_tensor:  tensor([-57.5463,   3.3980,  -5.0000, -56.9667,   2.3980,  -5.0000, -56.5871,\n",
      "          1.3980,  -5.0000, -56.4075,   0.3980,  -5.0000, -56.3677,   0.0000,\n",
      "         -1.9900, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-5.7369e+01,  2.9442e+00, -5.6946e+00, -5.6893e+01,  1.9192e+00,\n",
      "        -5.0989e+00, -5.6629e+01,  1.0239e+00, -4.3160e+00, -5.6507e+01,\n",
      "         3.2349e-01, -3.4149e+00, -5.6453e+01, -1.7702e-01, -2.4731e+00,\n",
      "        -5.6566e+01, -4.2637e-01, -1.6132e+00, -5.6674e+01, -6.4854e-01,\n",
      "        -9.0199e-01, -5.6791e+01, -7.9498e-01, -4.7379e-01, -5.6954e+01,\n",
      "        -8.4071e-01, -2.1419e-01, -5.7217e+01, -8.2450e-01, -5.1333e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-43.6, -57.54627353866385, 6.0, 3.39800250381899]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  4\n",
      "reference_tensor:  tensor([-56.9667,   2.3980,  -5.0000, -56.5871,   1.3980,  -5.0000, -56.4075,\n",
      "          0.3980,  -5.0000, -56.3677,   0.0000,  -1.9900, -56.3677,   0.0000,\n",
      "          0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-56.7257,   1.8670,  -4.6662, -56.4330,   1.0566,  -4.0203, -56.3101,\n",
      "          0.3935,  -3.2577, -56.2776,  -0.1071,  -2.4225, -56.3016,  -0.4292,\n",
      "         -1.6069, -56.4535,  -0.5639,  -0.9191, -56.5599,  -0.6675,  -0.3676,\n",
      "        -56.6841,  -0.7130,  -0.0656, -56.8372,  -0.7115,   0.0923, -57.0362,\n",
      "         -0.6730,   0.1521], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-42.5, -56.966673037900044, 5.0, 2.39800250381899]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  5\n",
      "reference_tensor:  tensor([-56.5871,   1.3980,  -5.0000, -56.4075,   0.3980,  -5.0000, -56.3677,\n",
      "          0.0000,  -1.9900, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,\n",
      "          0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-5.6418e+01,  1.2063e+00, -3.7797e+00, -5.6229e+01,  5.7983e-01,\n",
      "        -3.1156e+00, -5.6171e+01,  1.0992e-01, -2.3999e+00, -5.6166e+01,\n",
      "        -2.3292e-01, -1.6532e+00, -5.6215e+01, -4.2184e-01, -9.7352e-01,\n",
      "        -5.6351e+01, -4.9467e-01, -4.4819e-01, -5.6422e+01, -5.1589e-01,\n",
      "        -4.3662e-02, -5.6526e+01, -4.9507e-01,  1.6312e-01, -5.6640e+01,\n",
      "        -4.7368e-01,  2.5354e-01, -5.6749e+01, -4.3450e-01,  2.4449e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-41.6, -56.58707253713625, 4.0, 1.39800250381899]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  6\n",
      "reference_tensor:  tensor([-56.4075,   0.3980,  -5.0000, -56.3677,   0.0000,  -1.9900, -56.3677,\n",
      "          0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,\n",
      "          0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-5.6337e+01,  7.2001e-01, -2.9949e+00, -5.6221e+01,  2.5634e-01,\n",
      "        -2.3233e+00, -5.6198e+01, -4.4498e-02, -1.6596e+00, -5.6200e+01,\n",
      "        -2.5291e-01, -1.0025e+00, -5.6256e+01, -3.3106e-01, -4.5372e-01,\n",
      "        -5.6359e+01, -3.6337e-01, -7.8050e-02, -5.6386e+01, -3.1844e-01,\n",
      "         1.9218e-01, -5.6460e+01, -2.4637e-01,  3.1969e-01, -5.6528e+01,\n",
      "        -2.1544e-01,  3.5791e-01, -5.6546e+01, -1.8280e-01,  2.9511e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.9, -56.407472036372454, 3.0, 0.39800250381899005]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -1.9900125190949502]\n",
      "time_step:  7\n",
      "reference_tensor:  tensor([-56.3677,   0.0000,  -1.9900, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,\n",
      "          0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-5.6376e+01,  2.6894e-01, -2.1918e+00, -5.6326e+01, -2.8013e-02,\n",
      "        -1.5165e+00, -5.6329e+01, -1.5659e-01, -9.1069e-01, -5.6328e+01,\n",
      "        -2.2983e-01, -3.5058e-01, -5.6383e+01, -1.9784e-01,  5.9156e-02,\n",
      "        -5.6444e+01, -1.9562e-01,  2.7867e-01, -5.6420e+01, -8.6029e-02,\n",
      "         4.0931e-01, -5.6459e+01,  3.4999e-02,  4.5811e-01, -5.6474e+01,\n",
      "         7.1717e-02,  4.4650e-01, -5.6391e+01,  9.4191e-02,  3.3197e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.4, -56.36767178599055, 2.0, 0.0]\n",
      "action_list [-5.0, -1.9900125190949502]\n",
      "new_action_list [-5.0, 0.0]\n",
      "time_step:  8\n",
      "reference_tensor:  tensor([-56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,\n",
      "          0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-5.5755e+01, -3.1419e-01, -1.1558e+00, -5.5790e+01, -3.9873e-01,\n",
      "        -4.7943e-01, -5.5830e+01, -3.0879e-01,  4.8730e-02, -5.5828e+01,\n",
      "        -2.0858e-01,  4.8239e-01, -5.5884e+01, -3.7563e-02,  7.1600e-01,\n",
      "        -5.5892e+01,  1.3680e-02,  7.3868e-01, -5.5805e+01,  2.0319e-01,\n",
      "         6.9371e-01, -5.5800e+01,  3.8670e-01,  6.4058e-01, -5.5750e+01,\n",
      "         4.3401e-01,  5.6391e-01, -5.5542e+01,  4.4545e-01,  3.8435e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.1, -56.36767178599055, 1.0, 0.0]\n",
      "action_list [-5.0, 0.0]\n",
      "new_action_list [-5.0, 0.0]\n",
      "time_step:  9\n",
      "reference_tensor:  tensor([-56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,\n",
      "          0.0000, -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000,\n",
      "        -56.3677,   0.0000,   0.0000, -56.3677,   0.0000,   0.0000, -56.3677,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-5.6188e+01,  1.7224e-01, -2.0956e+00, -5.6154e+01, -1.0520e-01,\n",
      "        -1.4167e+00, -5.6170e+01, -2.1285e-01, -8.1380e-01, -5.6177e+01,\n",
      "        -2.6783e-01, -2.6053e-01, -5.6239e+01, -2.2003e-01,  1.3760e-01,\n",
      "        -5.6303e+01, -2.0674e-01,  3.4160e-01, -5.6279e+01, -8.7060e-02,\n",
      "         4.5809e-01, -5.6319e+01,  4.2993e-02,  4.9521e-01, -5.6333e+01,\n",
      "         8.4358e-02,  4.7426e-01, -5.6244e+01,  1.0900e-01,  3.5066e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-50.0, -57.53125212207903, 10.0, 11.13705438254732]\n",
      "action_list [0, 0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  0\n",
      "reference_tensor:  tensor([-55.4038,  10.1371,  -5.0000, -53.4764,   9.1371,  -5.0000, -51.7490,\n",
      "          8.1371,  -5.0000, -50.2216,   7.1371,  -5.0000, -48.8942,   6.1371,\n",
      "         -5.0000, -47.7668,   5.1371,  -5.0000, -46.8394,   4.1371,  -5.0000,\n",
      "        -46.1120,   3.1371,  -5.0000, -45.5846,   2.1371,  -5.0000, -45.2571,\n",
      "          1.1371,  -5.0000])\n",
      "decoder_prediction:  tensor([-55.4206,  10.9484,  -2.8966, -53.2799,  10.3464,  -2.9928, -51.2558,\n",
      "          9.7678,  -3.0839, -49.3432,   9.1805,  -3.0883, -47.6011,   8.5788,\n",
      "         -2.9712, -45.9192,   7.9795,  -2.7448, -44.3685,   7.4853,  -2.4393,\n",
      "        -42.9303,   7.1048,  -2.0544, -41.5668,   6.7703,  -1.6420, -40.1847,\n",
      "          6.4782,  -1.2823], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-48.1, -55.403841245569566, 9.0, 10.13705438254732]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  1\n",
      "reference_tensor:  tensor([-53.4764,   9.1371,  -5.0000, -51.7490,   8.1371,  -5.0000, -50.2216,\n",
      "          7.1371,  -5.0000, -48.8942,   6.1371,  -5.0000, -47.7668,   5.1371,\n",
      "         -5.0000, -46.8394,   4.1371,  -5.0000, -46.1120,   3.1371,  -5.0000,\n",
      "        -45.5846,   2.1371,  -5.0000, -45.2571,   1.1371,  -5.0000, -45.1297,\n",
      "          0.1371,  -5.0000])\n",
      "decoder_prediction:  tensor([-53.9020,   9.2106,  -5.4828, -52.1791,   8.1657,  -5.5221, -50.5899,\n",
      "          7.1192,  -5.4901, -49.2966,   6.0981,  -5.3687, -48.2517,   5.1047,\n",
      "         -5.0712, -47.2114,   4.0350,  -4.5498, -46.5221,   3.3172,  -4.0394,\n",
      "        -45.9651,   2.6985,  -3.3066, -45.4308,   2.1909,  -2.5781, -44.9074,\n",
      "          1.7794,  -1.9382], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-46.4, -53.476430369060104, 8.0, 9.13705438254732]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  2\n",
      "reference_tensor:  tensor([-51.7490,   8.1371,  -5.0000, -50.2216,   7.1371,  -5.0000, -48.8942,\n",
      "          6.1371,  -5.0000, -47.7668,   5.1371,  -5.0000, -46.8394,   4.1371,\n",
      "         -5.0000, -46.1120,   3.1371,  -5.0000, -45.5846,   2.1371,  -5.0000,\n",
      "        -45.2571,   1.1371,  -5.0000, -45.1297,   0.1371,  -5.0000, -45.1160,\n",
      "          0.0000,  -0.6853])\n",
      "decoder_prediction:  tensor([-51.9478,   8.1532,  -5.9314, -50.4613,   7.0185,  -5.8699, -49.1458,\n",
      "          5.8848,  -5.6751, -48.1198,   4.8553,  -5.3651, -47.2867,   3.8835,\n",
      "         -4.8512, -46.5077,   2.9879,  -4.1435, -46.0453,   2.3164,  -3.5040,\n",
      "        -45.6431,   1.7527,  -2.8006, -45.2870,   1.3574,  -2.1539, -45.0204,\n",
      "          1.0549,  -1.5672], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-44.9, -51.74901949255064, 7.0, 8.13705438254732]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  3\n",
      "reference_tensor:  tensor([-50.2216,   7.1371,  -5.0000, -48.8942,   6.1371,  -5.0000, -47.7668,\n",
      "          5.1371,  -5.0000, -46.8394,   4.1371,  -5.0000, -46.1120,   3.1371,\n",
      "         -5.0000, -45.5846,   2.1371,  -5.0000, -45.2571,   1.1371,  -5.0000,\n",
      "        -45.1297,   0.1371,  -5.0000, -45.1160,   0.0000,  -0.6853, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-50.2636,   7.0885,  -5.9476, -48.9897,   5.9521,  -5.7895, -47.9060,\n",
      "          4.8388,  -5.4786, -47.0805,   3.8638,  -5.0417, -46.4168,   2.9693,\n",
      "         -4.4128, -45.8389,   2.2256,  -3.6409, -45.5162,   1.6288,  -2.9561,\n",
      "        -45.2264,   1.1460,  -2.3058, -44.9955,   0.8370,  -1.7398, -44.8718,\n",
      "          0.6111,  -1.2309], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-43.6, -50.22160861604117, 6.0, 7.137054382547319]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  4\n",
      "reference_tensor:  tensor([-48.8942,   6.1371,  -5.0000, -47.7668,   5.1371,  -5.0000, -46.8394,\n",
      "          4.1371,  -5.0000, -46.1120,   3.1371,  -5.0000, -45.5846,   2.1371,\n",
      "         -5.0000, -45.2571,   1.1371,  -5.0000, -45.1297,   0.1371,  -5.0000,\n",
      "        -45.1160,   0.0000,  -0.6853, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-48.8426,   6.0479,  -5.7951, -47.7713,   4.9449,  -5.5498, -46.8988,\n",
      "          3.8860,  -5.1475, -46.2509,   2.9876,  -4.6177, -45.7375,   2.1850,\n",
      "         -3.9157, -45.3295,   1.5832,  -3.1196, -45.1200,   1.0665,  -2.4241,\n",
      "        -44.9229,   0.6661,  -1.8374, -44.7922,   0.4346,  -1.3533, -44.7742,\n",
      "          0.2746,  -0.9246], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-42.5, -48.89419773953171, 5.0, 6.137054382547319]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  5\n",
      "reference_tensor:  tensor([-47.7668,   5.1371,  -5.0000, -46.8394,   4.1371,  -5.0000, -46.1120,\n",
      "          3.1371,  -5.0000, -45.5846,   2.1371,  -5.0000, -45.2571,   1.1371,\n",
      "         -5.0000, -45.1297,   0.1371,  -5.0000, -45.1160,   0.0000,  -0.6853,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7678e+01,  5.0414e+00, -5.5749e+00, -4.6800e+01,  3.9863e+00,\n",
      "        -5.2479e+00, -4.6125e+01,  2.9954e+00, -4.7660e+00, -4.5641e+01,\n",
      "         2.1813e+00, -4.1597e+00, -4.5266e+01,  1.4753e+00, -3.4044e+00,\n",
      "        -4.5011e+01,  1.0071e+00, -2.6024e+00, -4.4900e+01,  5.7172e-01,\n",
      "        -1.9116e+00, -4.4785e+01,  2.5235e-01, -1.3914e+00, -4.4741e+01,\n",
      "         9.2447e-02, -9.8790e-01, -4.4810e+01, -8.0668e-03, -6.3870e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-41.6, -47.76678686302225, 4.0, 5.137054382547319]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  6\n",
      "reference_tensor:  tensor([-46.8394,   4.1371,  -5.0000, -46.1120,   3.1371,  -5.0000, -45.5846,\n",
      "          2.1371,  -5.0000, -45.2571,   1.1371,  -5.0000, -45.1297,   0.1371,\n",
      "         -5.0000, -45.1160,   0.0000,  -0.6853, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-46.7849,   4.0915,  -5.2770, -46.0867,   3.1007,  -4.8763, -45.5892,\n",
      "          2.1929,  -4.3308, -45.2489,   1.4710,  -3.6686, -44.9968,   0.8653,\n",
      "         -2.8846, -44.8706,   0.5192,  -2.0982, -44.8402,   0.1648,  -1.4303,\n",
      "        -44.7941,  -0.0763,  -0.9790, -44.8199,  -0.1726,  -0.6532, -44.9511,\n",
      "         -0.2221,  -0.3815], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.9, -46.839375986512785, 3.0, 4.137054382547319]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  7\n",
      "reference_tensor:  tensor([-46.1120,   3.1371,  -5.0000, -45.5846,   2.1371,  -5.0000, -45.2571,\n",
      "          1.1371,  -5.0000, -45.1297,   0.1371,  -5.0000, -45.1160,   0.0000,\n",
      "         -0.6853, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.5958e+01,  2.6928e+00, -4.7956e+00, -4.5523e+01,  1.8073e+00,\n",
      "        -4.2858e+00, -4.5281e+01,  1.0330e+00, -3.6500e+00, -4.5147e+01,\n",
      "         4.5355e-01, -2.9127e+00, -4.5071e+01,  1.7046e-03, -2.0983e+00,\n",
      "        -4.5127e+01, -1.6913e-01, -1.3476e+00, -4.5207e+01, -4.0010e-01,\n",
      "        -7.2478e-01, -4.5257e+01, -5.2465e-01, -3.7768e-01, -4.5378e+01,\n",
      "        -5.3091e-01, -1.6662e-01, -4.5590e+01, -5.0888e-01, -1.1270e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.4, -46.111965110003325, 2.0, 3.137054382547319]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  8\n",
      "reference_tensor:  tensor([-45.5846,   2.1371,  -5.0000, -45.2571,   1.1371,  -5.0000, -45.1297,\n",
      "          0.1371,  -5.0000, -45.1160,   0.0000,  -0.6853, -45.1160,   0.0000,\n",
      "          0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.5390e+01,  1.6062e+00, -3.7711e+00, -4.5139e+01,  9.3487e-01,\n",
      "        -3.2094e+00, -4.5040e+01,  3.9272e-01, -2.5919e+00, -4.4998e+01,\n",
      "         1.3185e-02, -1.9185e+00, -4.5001e+01, -2.5943e-01, -1.2289e+00,\n",
      "        -4.5098e+01, -3.1468e-01, -6.4954e-01, -4.5177e+01, -4.2605e-01,\n",
      "        -1.8581e-01, -4.5237e+01, -4.4889e-01,  3.4917e-02, -4.5349e+01,\n",
      "        -4.0751e-01,  1.4372e-01, -4.5498e+01, -3.6259e-01,  1.9503e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.1, -45.58455423349386, 1.0, 2.137054382547319]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  9\n",
      "reference_tensor:  tensor([-45.2571,   1.1371,  -5.0000, -45.1297,   0.1371,  -5.0000, -45.1160,\n",
      "          0.0000,  -0.6853, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,\n",
      "          0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-45.1941,   1.4071,  -3.8923, -44.9861,   0.7120,  -3.3058, -44.9406,\n",
      "          0.1511,  -2.6499, -44.9475,  -0.2343,  -1.9301, -44.9927,  -0.5026,\n",
      "         -1.1926, -45.1451,  -0.5265,  -0.5762, -45.2653,  -0.6275,  -0.0823,\n",
      "        -45.3581,  -0.6371,   0.1368, -45.5080,  -0.5762,   0.2331, -45.7050,\n",
      "         -0.5114,   0.2718], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -45.25714335698439, 0.0, 1.1370543825473192]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [0.0, -5.0]\n",
      "time_step:  10\n",
      "reference_tensor:  tensor([-45.1297,   0.1371,  -5.0000, -45.1160,   0.0000,  -0.6853, -45.1160,\n",
      "          0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,\n",
      "          0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.5290e+01,  8.4589e-01, -2.1124e+00, -4.5148e+01,  5.8733e-01,\n",
      "        -1.6495e+00, -4.5006e+01,  3.9233e-01, -1.1560e+00, -4.4955e+01,\n",
      "         2.1583e-01, -7.3031e-01, -4.4916e+01,  1.8818e-01, -4.5839e-01,\n",
      "        -4.4884e+01,  3.8951e-02, -2.5389e-01, -4.4837e+01,  1.3336e-01,\n",
      "        -1.5339e-01, -4.4851e+01,  1.3009e-01, -2.2500e-02, -4.4776e+01,\n",
      "         7.9493e-02,  4.5965e-02, -4.4705e+01,  9.1376e-02,  4.0143e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -45.12973248047493, 0.0, 0.13705438254731916]\n",
      "action_list [0.0, -5.0]\n",
      "new_action_list [0.0, -0.6852719127365958]\n",
      "time_step:  11\n",
      "reference_tensor:  tensor([-45.1160,   0.0000,  -0.6853, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,\n",
      "          0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-45.3487,   0.1975,  -1.0013, -45.3007,   0.1698,  -0.5309, -45.2003,\n",
      "          0.2139,  -0.1147, -45.1506,   0.2257,   0.1797, -45.1139,   0.3524,\n",
      "          0.2616, -45.0279,   0.2541,   0.2512, -44.9130,   0.4400,   0.1593,\n",
      "        -44.8820,   0.5063,   0.1800, -44.7366,   0.4655,   0.1778, -44.5282,\n",
      "          0.4650,   0.0985], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -45.116027042220196, 0.0, 0.0]\n",
      "action_list [0.0, -0.6852719127365958]\n",
      "new_action_list [0.0, 0.0]\n",
      "time_step:  12\n",
      "reference_tensor:  tensor([-45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,\n",
      "          0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.5311e+01,  6.0650e-02, -1.1100e+00, -4.5293e+01,  1.1762e-02,\n",
      "        -6.2066e-01, -4.5231e+01,  3.8533e-02, -1.7413e-01, -4.5217e+01,\n",
      "         4.2997e-02,  1.5709e-01, -4.5212e+01,  1.7081e-01,  2.7725e-01,\n",
      "        -4.5167e+01,  9.4271e-02,  2.9728e-01, -4.5084e+01,  2.8681e-01,\n",
      "         2.3028e-01, -4.5078e+01,  3.6201e-01,  2.5175e-01, -4.4961e+01,\n",
      "         3.3503e-01,  2.4144e-01, -4.4790e+01,  3.4909e-01,  1.5383e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -45.116027042220196, 0.0, 0.0]\n",
      "action_list [0.0, 0.0]\n",
      "new_action_list [0.0, 0.0]\n",
      "time_step:  13\n",
      "reference_tensor:  tensor([-45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,\n",
      "          0.0000, -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000,\n",
      "        -45.1160,   0.0000,   0.0000, -45.1160,   0.0000,   0.0000, -45.1160,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-45.3260,   0.0856,  -0.9991, -45.3000,   0.0591,  -0.5177, -45.2229,\n",
      "          0.1071,  -0.0891, -45.1933,   0.1254,   0.2182, -45.1737,   0.2614,\n",
      "          0.3106, -45.1079,   0.1780,   0.3050, -45.0062,   0.3726,   0.2161,\n",
      "        -44.9866,   0.4478,   0.2311, -44.8533,   0.4152,   0.2204, -44.6579,\n",
      "          0.4220,   0.1324], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-50.0, -51.83172737499547, 10.0, 6.36189085359101]\n",
      "action_list [0, 0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  0\n",
      "reference_tensor:  tensor([-50.6593,   5.3619,  -5.0000, -49.6870,   4.3619,  -5.0000, -48.9146,\n",
      "          3.3619,  -5.0000, -48.3422,   2.3619,  -5.0000, -47.9698,   1.3619,\n",
      "         -5.0000, -47.7975,   0.3619,  -5.0000, -47.7613,   0.0000,  -1.8095,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-51.2637,   6.2206,  -1.8794, -50.0540,   5.8845,  -1.7378, -48.8855,\n",
      "          5.5832,  -1.6813, -47.7983,   5.2977,  -1.6442, -46.8178,   4.9770,\n",
      "         -1.5698, -45.7983,   4.6157,  -1.4515, -44.9231,   4.3550,  -1.3480,\n",
      "        -44.0937,   4.1528,  -1.1589, -43.2844,   3.9724,  -0.9457, -42.4379,\n",
      "          3.7922,  -0.7520], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-48.1, -50.65934920427726, 9.0, 5.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  1\n",
      "reference_tensor:  tensor([-49.6870,   4.3619,  -5.0000, -48.9146,   3.3619,  -5.0000, -48.3422,\n",
      "          2.3619,  -5.0000, -47.9698,   1.3619,  -5.0000, -47.7975,   0.3619,\n",
      "         -5.0000, -47.7613,   0.0000,  -1.8095, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.9546e+01,  3.9158e+00, -5.4055e+00, -4.8882e+01,  2.9110e+00,\n",
      "        -4.9651e+00, -4.8421e+01,  1.9989e+00, -4.3689e+00, -4.8117e+01,\n",
      "         1.2731e+00, -3.6552e+00, -4.7899e+01,  6.8314e-01, -2.8376e+00,\n",
      "        -4.7816e+01,  3.4675e-01, -2.0337e+00, -4.7809e+01,  1.6402e-02,\n",
      "        -1.3542e+00, -4.7794e+01, -2.0982e-01, -9.0140e-01, -4.7845e+01,\n",
      "        -3.0148e-01, -5.8327e-01, -4.8000e+01, -3.4119e-01, -3.3026e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-46.4, -49.68697103355906, 8.0, 4.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  2\n",
      "reference_tensor:  tensor([-48.9146,   3.3619,  -5.0000, -48.3422,   2.3619,  -5.0000, -47.9698,\n",
      "          1.3619,  -5.0000, -47.7975,   0.3619,  -5.0000, -47.7613,   0.0000,\n",
      "         -1.8095, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-48.7797,   3.0592,  -5.1262, -48.2775,   2.1148,  -4.6197, -47.9758,\n",
      "          1.2799,  -3.9675, -47.8006,   0.6388,  -3.2057, -47.6924,   0.1403,\n",
      "         -2.3648, -47.7241,  -0.0868,  -1.5773, -47.7882,  -0.3435,  -0.9210,\n",
      "        -47.8344,  -0.4991,  -0.5310, -47.9463,  -0.5338,  -0.2831, -48.1553,\n",
      "         -0.5280,  -0.1000], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-44.9, -48.91459286284086, 7.0, 3.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  3\n",
      "reference_tensor:  tensor([-48.3422,   2.3619,  -5.0000, -47.9698,   1.3619,  -5.0000, -47.7975,\n",
      "          0.3619,  -5.0000, -47.7613,   0.0000,  -1.8095, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.8146e+01,  1.9620e+00, -4.4510e+00, -4.7840e+01,  1.1607e+00,\n",
      "        -3.8742e+00, -4.7714e+01,  4.8907e-01, -3.1917e+00, -4.7669e+01,\n",
      "         5.2673e-04, -2.4270e+00, -4.7673e+01, -3.5011e-01, -1.6300e+00,\n",
      "        -4.7802e+01, -4.4904e-01, -9.3604e-01, -4.7913e+01, -5.9821e-01,\n",
      "        -3.7174e-01, -4.8005e+01, -6.5731e-01, -8.4275e-02, -4.8154e+01,\n",
      "        -6.3145e-01,  6.7613e-02, -4.8369e+01, -5.8446e-01,  1.5326e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-43.6, -48.34221469212266, 6.0, 2.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  4\n",
      "reference_tensor:  tensor([-47.9698,   1.3619,  -5.0000, -47.7975,   0.3619,  -5.0000, -47.7613,\n",
      "          0.0000,  -1.8095, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7801e+01,  1.2100e+00, -3.4797e+00, -4.7616e+01,  6.1047e-01,\n",
      "        -2.8802e+00, -4.7566e+01,  1.5138e-01, -2.2460e+00, -4.7557e+01,\n",
      "        -1.6280e-01, -1.5747e+00, -4.7592e+01, -3.6527e-01, -9.2399e-01,\n",
      "        -4.7708e+01, -3.9265e-01, -4.0669e-01, -4.7785e+01, -4.4940e-01,\n",
      "        -2.5983e-03, -4.7856e+01, -4.3360e-01,  1.7911e-01, -4.7965e+01,\n",
      "        -3.8384e-01,  2.5497e-01, -4.8086e+01, -3.3424e-01,  2.6308e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-42.5, -47.96983652140446, 5.0, 1.3618908535910101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  5\n",
      "reference_tensor:  tensor([-47.7975,   0.3619,  -5.0000, -47.7613,   0.0000,  -1.8095, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7678e+01,  5.7326e-01, -2.3910e+00, -4.7586e+01,  1.9920e-01,\n",
      "        -1.7849e+00, -4.7578e+01, -2.6564e-02, -1.2271e+00, -4.7571e+01,\n",
      "        -1.5639e-01, -6.8479e-01, -4.7610e+01, -2.0830e-01, -2.1922e-01,\n",
      "        -4.7673e+01, -1.8439e-01,  8.8753e-02, -4.7684e+01, -1.5242e-01,\n",
      "         3.0554e-01, -4.7712e+01, -6.8474e-02,  3.7918e-01, -4.7752e+01,\n",
      "        -8.2195e-03,  3.8543e-01, -4.7740e+01,  2.9798e-02,  3.2191e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-41.6, -47.797458350686256, 4.0, 0.36189085359101014]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -1.8094542679550507]\n",
      "time_step:  6\n",
      "reference_tensor:  tensor([-47.7613,   0.0000,  -1.8095, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7728e+01, -2.4166e-02, -1.2992e+00, -4.7721e+01, -1.7172e-01,\n",
      "        -6.8959e-01, -4.7745e+01, -1.6376e-01, -2.1231e-01, -4.7732e+01,\n",
      "        -1.1072e-01,  1.9626e-01, -4.7767e+01, -1.4173e-02,  4.7130e-01,\n",
      "        -4.7771e+01,  5.4649e-02,  5.6623e-01, -4.7709e+01,  1.7325e-01,\n",
      "         5.9282e-01, -4.7688e+01,  3.2254e-01,  5.6024e-01, -4.7656e+01,\n",
      "         3.8950e-01,  4.9991e-01, -4.7505e+01,  4.1265e-01,  3.6727e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.9, -47.76126926532715, 3.0, 0.0]\n",
      "action_list [-5.0, -1.8094542679550507]\n",
      "new_action_list [-5.0, 0.0]\n",
      "time_step:  7\n",
      "reference_tensor:  tensor([-47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7767e+01, -2.2642e-01, -1.0574e+00, -4.7793e+01, -3.2320e-01,\n",
      "        -4.3992e-01, -4.7838e+01, -2.6112e-01,  2.7691e-02, -4.7836e+01,\n",
      "        -1.6368e-01,  4.1516e-01, -4.7882e+01, -2.8383e-02,  6.5470e-01,\n",
      "        -4.7884e+01,  5.9504e-02,  7.0541e-01, -4.7816e+01,  2.0298e-01,\n",
      "         6.9182e-01, -4.7791e+01,  3.7229e-01,  6.3220e-01, -4.7750e+01,\n",
      "         4.4569e-01,  5.5195e-01, -4.7576e+01,  4.7009e-01,  3.9841e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.4, -47.76126926532715, 2.0, 0.0]\n",
      "action_list [-5.0, 0.0]\n",
      "new_action_list [-5.0, 0.0]\n",
      "time_step:  8\n",
      "reference_tensor:  tensor([-47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7750e+01, -1.9673e-01, -1.0843e+00, -4.7771e+01, -2.9929e-01,\n",
      "        -4.6846e-01, -4.7813e+01, -2.4349e-01, -6.1551e-04, -4.7808e+01,\n",
      "        -1.5142e-01,  3.8840e-01, -4.7851e+01, -2.1035e-02,  6.3125e-01,\n",
      "        -4.7853e+01,  6.3906e-02,  6.8656e-01, -4.7784e+01,  2.0399e-01,\n",
      "         6.7736e-01, -4.7759e+01,  3.7053e-01,  6.2109e-01, -4.7718e+01,\n",
      "         4.4271e-01,  5.4358e-01, -4.7546e+01,  4.6651e-01,  3.9289e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-50.0, -51.83172737499547, 10.0, 6.36189085359101]\n",
      "action_list [0, 0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  0\n",
      "reference_tensor:  tensor([-50.6593,   5.3619,  -5.0000, -49.6870,   4.3619,  -5.0000, -48.9146,\n",
      "          3.3619,  -5.0000, -48.3422,   2.3619,  -5.0000, -47.9698,   1.3619,\n",
      "         -5.0000, -47.7975,   0.3619,  -5.0000, -47.7613,   0.0000,  -1.8095,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-51.2637,   6.2206,  -1.8794, -50.0540,   5.8845,  -1.7378, -48.8855,\n",
      "          5.5832,  -1.6813, -47.7983,   5.2977,  -1.6442, -46.8178,   4.9770,\n",
      "         -1.5698, -45.7983,   4.6157,  -1.4515, -44.9231,   4.3550,  -1.3480,\n",
      "        -44.0937,   4.1528,  -1.1589, -43.2844,   3.9724,  -0.9457, -42.4379,\n",
      "          3.7922,  -0.7520], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-48.1, -50.65934920427726, 9.0, 5.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  1\n",
      "reference_tensor:  tensor([-49.6870,   4.3619,  -5.0000, -48.9146,   3.3619,  -5.0000, -48.3422,\n",
      "          2.3619,  -5.0000, -47.9698,   1.3619,  -5.0000, -47.7975,   0.3619,\n",
      "         -5.0000, -47.7613,   0.0000,  -1.8095, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.9546e+01,  3.9158e+00, -5.4055e+00, -4.8882e+01,  2.9110e+00,\n",
      "        -4.9651e+00, -4.8421e+01,  1.9989e+00, -4.3689e+00, -4.8117e+01,\n",
      "         1.2731e+00, -3.6552e+00, -4.7899e+01,  6.8314e-01, -2.8376e+00,\n",
      "        -4.7816e+01,  3.4675e-01, -2.0337e+00, -4.7809e+01,  1.6402e-02,\n",
      "        -1.3542e+00, -4.7794e+01, -2.0982e-01, -9.0140e-01, -4.7845e+01,\n",
      "        -3.0148e-01, -5.8327e-01, -4.8000e+01, -3.4119e-01, -3.3026e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-46.4, -49.68697103355906, 8.0, 4.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  2\n",
      "reference_tensor:  tensor([-48.9146,   3.3619,  -5.0000, -48.3422,   2.3619,  -5.0000, -47.9698,\n",
      "          1.3619,  -5.0000, -47.7975,   0.3619,  -5.0000, -47.7613,   0.0000,\n",
      "         -1.8095, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-48.7797,   3.0592,  -5.1262, -48.2775,   2.1148,  -4.6197, -47.9758,\n",
      "          1.2799,  -3.9675, -47.8006,   0.6388,  -3.2057, -47.6924,   0.1403,\n",
      "         -2.3648, -47.7241,  -0.0868,  -1.5773, -47.7882,  -0.3435,  -0.9210,\n",
      "        -47.8344,  -0.4991,  -0.5310, -47.9463,  -0.5338,  -0.2831, -48.1553,\n",
      "         -0.5280,  -0.1000], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-44.9, -48.91459286284086, 7.0, 3.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  3\n",
      "reference_tensor:  tensor([-48.3422,   2.3619,  -5.0000, -47.9698,   1.3619,  -5.0000, -47.7975,\n",
      "          0.3619,  -5.0000, -47.7613,   0.0000,  -1.8095, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.8146e+01,  1.9620e+00, -4.4510e+00, -4.7840e+01,  1.1607e+00,\n",
      "        -3.8742e+00, -4.7714e+01,  4.8907e-01, -3.1917e+00, -4.7669e+01,\n",
      "         5.2673e-04, -2.4270e+00, -4.7673e+01, -3.5011e-01, -1.6300e+00,\n",
      "        -4.7802e+01, -4.4904e-01, -9.3604e-01, -4.7913e+01, -5.9821e-01,\n",
      "        -3.7174e-01, -4.8005e+01, -6.5731e-01, -8.4275e-02, -4.8154e+01,\n",
      "        -6.3145e-01,  6.7613e-02, -4.8369e+01, -5.8446e-01,  1.5326e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-43.6, -48.34221469212266, 6.0, 2.36189085359101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  4\n",
      "reference_tensor:  tensor([-47.9698,   1.3619,  -5.0000, -47.7975,   0.3619,  -5.0000, -47.7613,\n",
      "          0.0000,  -1.8095, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7801e+01,  1.2100e+00, -3.4797e+00, -4.7616e+01,  6.1047e-01,\n",
      "        -2.8802e+00, -4.7566e+01,  1.5138e-01, -2.2460e+00, -4.7557e+01,\n",
      "        -1.6280e-01, -1.5747e+00, -4.7592e+01, -3.6527e-01, -9.2399e-01,\n",
      "        -4.7708e+01, -3.9265e-01, -4.0669e-01, -4.7785e+01, -4.4940e-01,\n",
      "        -2.5983e-03, -4.7856e+01, -4.3360e-01,  1.7911e-01, -4.7965e+01,\n",
      "        -3.8384e-01,  2.5497e-01, -4.8086e+01, -3.3424e-01,  2.6308e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-42.5, -47.96983652140446, 5.0, 1.3618908535910101]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -5.0]\n",
      "time_step:  5\n",
      "reference_tensor:  tensor([-47.7975,   0.3619,  -5.0000, -47.7613,   0.0000,  -1.8095, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7678e+01,  5.7326e-01, -2.3910e+00, -4.7586e+01,  1.9920e-01,\n",
      "        -1.7849e+00, -4.7578e+01, -2.6564e-02, -1.2271e+00, -4.7571e+01,\n",
      "        -1.5639e-01, -6.8479e-01, -4.7610e+01, -2.0830e-01, -2.1922e-01,\n",
      "        -4.7673e+01, -1.8439e-01,  8.8753e-02, -4.7684e+01, -1.5242e-01,\n",
      "         3.0554e-01, -4.7712e+01, -6.8474e-02,  3.7918e-01, -4.7752e+01,\n",
      "        -8.2195e-03,  3.8543e-01, -4.7740e+01,  2.9798e-02,  3.2191e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-41.6, -47.797458350686256, 4.0, 0.36189085359101014]\n",
      "action_list [-5.0, -5.0]\n",
      "new_action_list [-5.0, -1.8094542679550507]\n",
      "time_step:  6\n",
      "reference_tensor:  tensor([-47.7613,   0.0000,  -1.8095, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7728e+01, -2.4166e-02, -1.2992e+00, -4.7721e+01, -1.7172e-01,\n",
      "        -6.8959e-01, -4.7745e+01, -1.6376e-01, -2.1231e-01, -4.7732e+01,\n",
      "        -1.1072e-01,  1.9626e-01, -4.7767e+01, -1.4173e-02,  4.7130e-01,\n",
      "        -4.7771e+01,  5.4649e-02,  5.6623e-01, -4.7709e+01,  1.7325e-01,\n",
      "         5.9282e-01, -4.7688e+01,  3.2254e-01,  5.6024e-01, -4.7656e+01,\n",
      "         3.8950e-01,  4.9991e-01, -4.7505e+01,  4.1265e-01,  3.6727e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.9, -47.76126926532715, 3.0, 0.0]\n",
      "action_list [-5.0, -1.8094542679550507]\n",
      "new_action_list [-5.0, 0.0]\n",
      "time_step:  7\n",
      "reference_tensor:  tensor([-47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7767e+01, -2.2642e-01, -1.0574e+00, -4.7793e+01, -3.2320e-01,\n",
      "        -4.3992e-01, -4.7838e+01, -2.6112e-01,  2.7691e-02, -4.7836e+01,\n",
      "        -1.6368e-01,  4.1516e-01, -4.7882e+01, -2.8383e-02,  6.5470e-01,\n",
      "        -4.7884e+01,  5.9504e-02,  7.0541e-01, -4.7816e+01,  2.0298e-01,\n",
      "         6.9182e-01, -4.7791e+01,  3.7229e-01,  6.3220e-01, -4.7750e+01,\n",
      "         4.4569e-01,  5.5195e-01, -4.7576e+01,  4.7009e-01,  3.9841e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.4, -47.76126926532715, 2.0, 0.0]\n",
      "action_list [-5.0, 0.0]\n",
      "new_action_list [-5.0, 0.0]\n",
      "time_step:  8\n",
      "reference_tensor:  tensor([-47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,\n",
      "          0.0000, -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000,\n",
      "        -47.7613,   0.0000,   0.0000, -47.7613,   0.0000,   0.0000, -47.7613,\n",
      "          0.0000,   0.0000])\n",
      "decoder_prediction:  tensor([-4.7750e+01, -1.9673e-01, -1.0843e+00, -4.7771e+01, -2.9929e-01,\n",
      "        -4.6846e-01, -4.7813e+01, -2.4349e-01, -6.1551e-04, -4.7808e+01,\n",
      "        -1.5142e-01,  3.8840e-01, -4.7851e+01, -2.1035e-02,  6.3125e-01,\n",
      "        -4.7853e+01,  6.3906e-02,  6.8656e-01, -4.7784e+01,  2.0399e-01,\n",
      "         6.7736e-01, -4.7759e+01,  3.7053e-01,  6.2109e-01, -4.7718e+01,\n",
      "         4.4271e-01,  5.4358e-01, -4.7546e+01,  4.6651e-01,  3.9289e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the network\n",
    "\n",
    "####### Load the neural network weights from saved models #######\n",
    "\n",
    "loaded_network=NN_structure(n_epochs,min_timesteps,n_rollout,n_skips_per_rollout,n_test,n_input,n_output,n_state_enc,learning_rate,gen_model,pred_model,device)\n",
    "loaded_network.load_model_weights(\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included\")\n",
    "\n",
    "\n",
    "#test_keys=[keys_for_testing[15]]\n",
    "\n",
    "test_results=loaded_network.test(763)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
