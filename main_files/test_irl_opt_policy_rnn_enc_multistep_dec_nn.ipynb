{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy.linalg as LA\n",
    "import random\n",
    "import pandas as pd\n",
    "from numpy import inf\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "import pyprind\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('../data_irl_model/Feb23_data_exploratory_policy.json')\n",
    "f = open('../data_irl_model/Feb22_dataSVO.json')\n",
    "data_irl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keys=list(data_irl.keys())\n",
    "data_keys.sort()\n",
    "\n",
    "keys_for_training=[]\n",
    "keys_for_testing=[]\n",
    "\n",
    "index=0\n",
    "for vehicle in data_keys:\n",
    "    if index%10==0:\n",
    "        keys_for_testing.append(vehicle)\n",
    "        index+=1\n",
    "    else:\n",
    "        keys_for_training.append(vehicle)\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  [-50.0, -48.00000959491307, -46.000038513319524, -44.000087269879714, -42.000156438656006, -40.00024642268436, -38.00035769377065, -36.00049081444543, -34.00064644271893, -32.00082533931872, -30.00102840504124, -28.00125668872575, -26.00151120767363, -24.001792382791493, -22.002099833316123, -20.002432376013743, -18.002787437319792, -16.003160131001316, -14.003541860606148, -12.003918337158034, -10.004267320991964, -8.004557419881444, -6.004750413867271, -3.9448847480055775, -1.765019082143887, 0.5348465837178011]\n",
      "1:  [-64.01737173704754, -62.83531527736229, -61.533258817677044, -60.1112023579918, -58.56914589830655, -56.907089438621306, -55.12503297893606, -53.222976519250814, -51.20092005956557, -49.05886359988032, -46.79680714019507, -44.435783573886155, -42.03579318943008, -39.63580342381655, -37.23581436583025, -34.83582611992979, -32.435838815383825, -30.035852614743888, -27.635867726241045, -25.23588442248834, -22.83590306972686, -20.435924175542993, -18.035948470786764, -15.635977059163423, -13.236011922538268, -10.836056718052575, -8.436118267962158, -6.036206772818808, -3.63630751453519, -1.2363667387964767]\n",
      "num_timesteps:  20\n"
     ]
    }
   ],
   "source": [
    "key=keys_for_training[97]\n",
    "key=str(key)                \n",
    "############# Create the data for the training locally- we are restricting the number of timesteps to num_timesteps######\n",
    "negative_vals=[]\n",
    "for i in [0,1]:\n",
    "    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "num_timesteps=min(50,len(negative_vals[0]),len(negative_vals[1]))\n",
    "\n",
    "print(\"0: \", negative_vals[0])\n",
    "print(\"1: \", negative_vals[1])\n",
    "\n",
    "print(\"num_timesteps: \", num_timesteps)\n",
    "\n",
    "key=keys_for_training[159]\n",
    "\n",
    "key=str(key)  \n",
    "\n",
    "negative_vals=[]\n",
    "\n",
    "for i in [0,1]:\n",
    "    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "\n",
    "num_timesteps=min(50,len(negative_vals[0]),len(negative_vals[1]))\n",
    "\n",
    "index_before_zero=data_irl[key][1].index(negative_vals[1][len(negative_vals[1])-1])\n",
    "\n",
    "print(index_before_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################################ AIS_gen ################################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class GenerateAis1(nn.Module):\n",
    "\n",
    "    #def __init__(self,n_input,n_state,n_psi2_in=64,n_psi2_out=128):\n",
    "    def __init__(self,n_input,n_state,n_psi2_in=8,n_psi2_out=16):\n",
    "        super(GenerateAis1,self).__init__()\n",
    "        self.PSI_layer1=nn.Linear(n_input,n_psi2_in)     # Use RELU after\n",
    "        self.PSI_layer2=nn.Linear(n_psi2_in,n_psi2_out)      # Use RELU after\n",
    "        self.PSI_layer3=nn.GRUCell(n_psi2_out,n_state)       # This is the Gated layer\n",
    "\n",
    "    def forward(self,x,h):\n",
    "        #x=torch.transpose(x,0,1)\n",
    "        #h=torch.transpose(h,0,1)\n",
    "        x=torch.relu(self.PSI_layer1(x))\n",
    "        x=torch.relu(self.PSI_layer2(x))\n",
    "        h=self.PSI_layer3(x,h)\n",
    "        return h     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################################ AIS_pred ###############################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class PredictAis1(nn.Module):\n",
    "    \n",
    "    #def __init__(self,n_output,n_state,n_phi2_in=16,n_phi2_out=8):\n",
    "    def __init__(self,n_output,n_decoder_in,n_phi2_in=6,n_phi2_out=8):\n",
    "        super(PredictAis1,self).__init__()\n",
    "        self.PHI_layer1=nn.Linear(n_decoder_in,n_phi2_in)  # Use RELU after\n",
    "        self.PHI_layer2=nn.Linear(n_phi2_in,n_phi2_out)     # Use RELU after\n",
    "        self.PHI_layer3=nn.Linear(n_phi2_out,n_output)         # mean vector of a unit-variance multivariate Gaussian distribution, samples from which are used to predict the next observation\n",
    "\n",
    "    # x here is the hidden state and the current action that is chosen \n",
    "    # to predict the next observations for the horizon\n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.PHI_layer1(x))\n",
    "        x=torch.relu(self.PHI_layer2(x))\n",
    "        output=self.PHI_layer3(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_structure(object):\n",
    "    def __init__(self,n_epochs,min_timesteps,n_rollout,n_skips_per_rollout,n_test,n_input,n_output,n_state_enc,learning_rate,ais_gen_model,ais_pred_model,device):\n",
    "        self.n_epochs=n_epochs\n",
    "        self.min_timesteps=min_timesteps\n",
    "        self.rollout=n_rollout\n",
    "        self.n_skips=n_skips_per_rollout\n",
    "        self.n_test=n_test\n",
    "        self.n_input=n_input\n",
    "        self.n_output=n_output\n",
    "        self.n_state_enc=n_state_enc    # Hidden state size in RNN\n",
    "        self.learning_rate=learning_rate                \n",
    "        self.device=device\n",
    "        self.ais_gen_model=ais_gen_model\n",
    "        self.ais_pred_model=ais_pred_model\n",
    "\n",
    "        self.n_psi2_in=8\n",
    "        self.n_psi2_out=16\n",
    "        self.n_phi2_in=2\n",
    "        self.n_phi2_out=4\n",
    "        self.n_psi1_out=8\n",
    "        \n",
    "        if ais_gen_model==1:\n",
    "            self.gen_model=GenerateAis1(self.n_input,self.n_state_enc).to(self.device)      \n",
    "        \n",
    "        #if ais_gen_model==2: \n",
    "            #self.gen_model=GenerateAis2(self.n_input,self.n_state_enc,self.n_psi1_out).to(self.device)        \n",
    "            #self.gen_model=GenerateAis2_LSTM(self.n_input,self.n_state_enc,self.n_psi1_out).to(self.device)\n",
    "            #self.gen_model=GenerateAis_LSTMShallow(self.n_input,self.n_state_enc).to(self.device)  \n",
    "\n",
    "        if ais_pred_model==1:\n",
    "            self.pred_model=PredictAis1(self.n_output,self.n_state_enc+1).to(self.device) # self.n_state_enc+1 implies ais_t and the (action of cav)_t\n",
    "        \n",
    "        #if ais_pred_model==2:\n",
    "            #self.pred_model=PredictAis2(self.n_output,self.n_state_enc+1,self.n_state_dec).to(self.device)\n",
    "            #self.pred_model=PredictAis2_LSTM(self.n_output,self.n_state_enc+1,self.n_state_dec).to(self.device)\n",
    "            #self.pred_model=PredictAis_LSTMShallow(self.n_state_enc+1,self.n_state_dec).to(self.device)\n",
    "\n",
    "    def save_model_weights(self,text=\"(:*_*:)\"):\n",
    "        #name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "        #torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        \n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        if self.ais_pred_model==1:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "\n",
    "        if self.ais_pred_model==2:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "\n",
    "        torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "\n",
    "        return \"saved\"\n",
    "    \n",
    "    def load_model_weights(self,text=\"(:*_*:)\"):\n",
    "        #name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "        #torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        #self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        #self.gen_model.eval()\n",
    "\n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        \n",
    "        if self.ais_pred_model==1:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "\n",
    "        if self.ais_pred_model==2:\n",
    "            name_pred_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "            name_gen_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "        \n",
    "        #torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "        self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        self.gen_model.eval()\n",
    "\n",
    "        self.pred_model.load_state_dict(torch.load(name_pred_path))\n",
    "        self.pred_model.eval()\n",
    "\n",
    "        print(\"names of files-Encoder\",name_gen_path,\"\\n\")\n",
    "        print(\"names of files-Decoder\",name_pred_path,\"\\n\")\n",
    "\n",
    "        return \"loaded\"\n",
    "    \n",
    "\n",
    "    def train(self,load_previous_weights=\"False\"):\n",
    "        '''\n",
    "        print(\"LOading previous weights\")\n",
    "        # Load previous weights\n",
    "        #if load_previous_weights==\"True\":\n",
    "        print(\"Got into the loop!\")\n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        text_load=\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included\"\n",
    "        name_pred_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(88)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text_load+\".pth\"\n",
    "        name_gen_path=\"../trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(88)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text_load+\".pth\"\n",
    "\n",
    "        self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        self.gen_model.eval()\n",
    "\n",
    "        self.pred_model.load_state_dict(torch.load(name_pred_path))\n",
    "        self.pred_model.eval()      \n",
    "\n",
    "        print(\"Loaded trained weights\")     \n",
    "        '''\n",
    "        train_bar=pyprind.ProgBar(self.n_epochs)\n",
    "        self.optimizer = torch.optim.Adam(list(self.gen_model.parameters()) + list(self.pred_model.parameters()), lr=self.learning_rate, amsgrad=True)\n",
    "\n",
    "        time_step_loss=0\n",
    "        for epoch in range(self.n_epochs):\n",
    "\n",
    "            train_bar.update()\n",
    "            keys_training=sample(keys_for_training,len(keys_for_training)) #shuffle the keys\n",
    "            #train_bar=pyprind.ProgBar(len(keys_for_training))\n",
    "            epoch_loss=0\n",
    "            for key in keys_training:\n",
    "                #for key in keys_for_testing[0]:\n",
    "                #train_bar.update()\n",
    "                key=str(key) \n",
    "                #print(key)                               \n",
    "                ############# Create the data for the training locally- we are restricting the number of timesteps to num_timesteps ######\n",
    "                negative_vals=[]\n",
    "                for i in [0,1]:\n",
    "                    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "                num_timesteps=min(self.min_timesteps,len(negative_vals[0]),len(negative_vals[1]))\n",
    "                index_before_zero=data_irl[key][1].index(negative_vals[1][len(negative_vals[1])-1])\n",
    "                #print(\"index_before_zero: \", index_before_zero)\n",
    "                #num_timesteps=20\n",
    "                indices_to_train=[]\n",
    "                if index_before_zero-num_timesteps>=0:\n",
    "                    indices_to_train=range(index_before_zero-num_timesteps,index_before_zero+1)\n",
    "                else:\n",
    "                    indices_to_train=range(0,index_before_zero+2)\n",
    "                #print(\"ndices_to_train: \", indices_to_train)\n",
    "                #######################################\n",
    "\n",
    "                #### IMPORTANT Cropping the indices as per availability of data - \n",
    "                # What if index_before_zero == length of the list and we are looking \n",
    "                # to predict data that is in existent\n",
    "\n",
    "                '''\n",
    "                ## No skip between predictions\n",
    "                indices_to_train_cropped=[]\n",
    "                if index_before_zero in [len(data_irl[key][1])-1,len(data_irl[key][1])-2,len(data_irl[key][1])-3]:\n",
    "                    indices_to_train_cropped=indices_to_train[0:-1*self.rollout]\n",
    "                else:\n",
    "                    indices_to_train_cropped=indices_to_train\n",
    "                '''\n",
    "                \n",
    "                ## Use this when we want to skip between predictions\n",
    "                ## Skip indicates the predicitons are for t+n_skips,t+2*n_skips,t+3*n_skips,...\n",
    "                indices_to_train_cropped=[]\n",
    "                if index_before_zero in range(len(data_irl[key][1])-1,len(data_irl[key][1])-self.rollout*(self.n_skips+1),-1):\n",
    "                    indices_to_train_cropped=indices_to_train[0:-self.rollout*(self.n_skips+1)]\n",
    "                else:\n",
    "                    indices_to_train_cropped=indices_to_train\n",
    "\n",
    "                # Ais initialization\n",
    "                ais_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device)\n",
    "                state_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device) # Only if we use a LSTM\n",
    "                action_list=[0,0] ## initialize the action list differently - but we can try giving it the actual values to iterate                \n",
    "\n",
    "                time_step_loss=0\n",
    "\n",
    "                # Initialize the origin offset only for position\n",
    "                #origin_offset_CAV=data_irl[key][0][indices_to_train[0]]\n",
    "                #origin_offset_HDV=data_irl[key][1][indices_to_train[0]]\n",
    "                origin_offset_CAV=0    \n",
    "                origin_offset_HDV=0\n",
    "\n",
    "                for time_step in indices_to_train_cropped:\n",
    "\n",
    "                    observation_list=[]\n",
    "                    for i in range(len(data_irl[key])-2): # exclude the last two columns (actions/inputs)\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if i==0:\n",
    "                            temp=temp-origin_offset_CAV\n",
    "                        elif i==1:\n",
    "                            temp=temp-origin_offset_HDV\n",
    "                        if temp!= None:\n",
    "                            observation_list.append(temp)\n",
    "                    input_list=[]\n",
    "                    input_list.extend(observation_list)\n",
    "                    input_list.extend(action_list)\n",
    "                    input_tensor=torch.tensor(input_list,dtype=torch.float).to(self.device)                    \n",
    "\n",
    "                    # Update action list for the next time step \n",
    "                    for i in [4,5]:\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if temp!= None:\n",
    "                            action_list[i-4]=temp\n",
    "                        else:\n",
    "                            action_list[i-4]=0\n",
    "\n",
    "                    '''\n",
    "                    ### For no skip between predictions\n",
    "                    reference_list=[]\n",
    "                    for k in range(self.rollout):\n",
    "                        for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                            if i==1:# min is self.rollout\n",
    "                                #rint(\"key\",key)\n",
    "                                #print(\"i\",i)\n",
    "                                #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                            \n",
    "                            elif i==3:\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                            elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                reference_list.append(data_irl[key][i][time_step+k])\n",
    "                            \n",
    "                            else:\n",
    "                                reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                    '''\n",
    "\n",
    "                    \n",
    "                    ### Skip between predictions\n",
    "                    reference_list=[]\n",
    "                    if (time_step+self.rollout*(self.n_skips+1))>=len(data_irl[key][i]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        for k in range(self.n_skips,self.rollout*(self.n_skips+1),self.n_skips+1):\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is self.rollout\n",
    "                                    #rint(\"key\",key)\n",
    "                                    #print(\"i\",i)\n",
    "                                    #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                                           \n",
    "\n",
    "                    '''\n",
    "                    # This is to be as 3* as long as the number of rollouts - 3 for each rollout\n",
    "                    internal_rollout=min(self.rollout,len(data_irl[key][0])-time_step-2)\n",
    "                    \n",
    "\n",
    "                    reference_list=[]\n",
    "\n",
    "                    if internal_rollout==self.rollout:\n",
    "                        for k in range(self.rollout):\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is self.rollout\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "                            \n",
    "                    else:\n",
    "                        for k in range(internal_rollout):\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is not self.rollout\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "                                    \n",
    "                        for k in range(internal_rollout,self.rollout):\n",
    "                            for i in [1,3,5]:\n",
    "                                reference_list.append(0)\n",
    "                    '''\n",
    "\n",
    "\n",
    "                    reference_tensor=torch.tensor(reference_list,dtype=torch.float).to(self.device)\n",
    "                    ais_rollout_enc=self.gen_model(input_tensor,ais_rollout_enc)\n",
    "                    # Adding the (action of CAV)_t as an inpug to the decoder\n",
    "                    decoder_input=torch.cat((ais_rollout_enc,torch.tensor([action_list[0]],dtype=torch.float).to(self.device)),dim=0)\n",
    "\n",
    "                    decoder_prediction=self.pred_model(decoder_input)\n",
    "\n",
    "                    ## Mulitvariate normal distribution loss\n",
    "                    #time_step_loss+=torch.distributions.MultivariateNormal(decoder_prediction,torch.eye(self.n_output).to(self.device)).log_prob(reference_tensor)\n",
    "                    ## MSE loss\n",
    "                    time_step_loss+=torch.nn.functional.mse_loss(decoder_prediction,reference_tensor)                    \n",
    "                    #print(\"time_step_loss: \",time_step_loss)\n",
    "                    #print(\"reference_tensor: \",reference_tensor)\n",
    "                    #print(\"decoder_prediction: \",decoder_prediction,\"\\n\")\n",
    "                    \n",
    "                    \n",
    "               \n",
    "                epoch_loss+=time_step_loss\n",
    "                self.optimizer.zero_grad()\n",
    "                time_step_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                ## Printing the gradients\n",
    "                '''\n",
    "                print(\"Printing the gradients-encoder\")\n",
    "                print(self.gen_model.PSI_layer3.weight_ih.grad)\n",
    "                print(self.gen_model.PSI_layer3.weight_hh.grad)\n",
    "                print(self.gen_model.PSI_layer3.bias_ih.grad)\n",
    "                print(self.gen_model.PSI_layer3.bias_hh.grad)\n",
    "\n",
    "                print(\"Printing the gradients-decoder\")                \n",
    "                print(self.pred_model.PHI_layer1.weight.grad)\n",
    "                print(self.pred_model.PHI_layer2.weight.grad)\n",
    "                print(self.pred_model.PHI_layer3.weight.grad)           \n",
    "                '''\n",
    "                \n",
    "            print(\"epoch_loss is \",epoch_loss,\"\\n\")                \n",
    "            print(\"saving model weights for epoch \",epoch)\n",
    "            #status=self.save_model_weights(\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_Multivarloss\")\n",
    "            status=self.save_model_weights(\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included_for_results\")\n",
    "\n",
    "    def test(self,test_key):\n",
    "            test_results=[]\n",
    "            time_step_loss=0\n",
    "            keys_testing=keys_for_testing[test_key]# sample(keys_for_training,len(keys_for_training)) #shuffle the keys\n",
    "            #train_bar=pyprind.ProgBar(len(keys_for_training))\n",
    "            epoch_loss=0\n",
    "            for key in keys_testing:\n",
    "                #for key in keys_for_testing[0]:\n",
    "                #train_bar.update()\n",
    "                key=str(key) \n",
    "                #print(key)                               \n",
    "                ############# Create the data for the training locally- we are restricting the number of timesteps to num_timesteps ######\n",
    "                negative_vals=[]\n",
    "                for i in [0,1]:\n",
    "                    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "                num_timesteps=min(self.min_timesteps,len(negative_vals[0]),len(negative_vals[1]))\n",
    "                index_before_zero=data_irl[key][1].index(negative_vals[1][len(negative_vals[1])-1])\n",
    "                #print(\"index_before_zero: \", index_before_zero)\n",
    "                #num_timesteps=20\n",
    "                indices_to_test=[]\n",
    "                if index_before_zero-num_timesteps>=0:\n",
    "                    indices_to_test=range(index_before_zero-num_timesteps,index_before_zero+1)\n",
    "                else:\n",
    "                    indices_to_test=range(0,index_before_zero+2)\n",
    "                #print(\"ndices_to_train: \", indices_to_train)\n",
    "                #######################################\n",
    "\n",
    "                #### IMPORTANT Cropping the indices as per availability of data - \n",
    "                # What if index_before_zero == length of the list and we are looking \n",
    "                # to predict data that is in existent\n",
    "\n",
    "                '''\n",
    "                ## No skip between predictions\n",
    "                indices_to_train_cropped=[]\n",
    "                if index_before_zero in [len(data_irl[key][1])-1,len(data_irl[key][1])-2,len(data_irl[key][1])-3]:\n",
    "                    indices_to_train_cropped=indices_to_train[0:-1*self.rollout]\n",
    "                else:\n",
    "                    indices_to_train_cropped=indices_to_train\n",
    "                '''\n",
    "                \n",
    "                ## Use this when we want to skip between predictions\n",
    "                ## Skip indicates the predicitons are for t+n_skips,t+2*n_skips,t+3*n_skips,...\n",
    "                indices_to_test_cropped=[]\n",
    "                if index_before_zero in range(len(data_irl[key][1])-1,len(data_irl[key][1])-self.rollout*(self.n_skips+1),-1):\n",
    "                    indices_to_test_cropped=indices_to_test[0:-self.rollout*(self.n_skips+1)]\n",
    "                else:\n",
    "                    indices_to_test_cropped=indices_to_test\n",
    "\n",
    "                # Ais initialization\n",
    "                ais_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device)\n",
    "                state_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device) # Only if we use a LSTM\n",
    "                action_list=[0,0] ## initialize the action list differently - but we can try giving it the actual values to iterate                \n",
    "\n",
    "                time_step_loss=0\n",
    "\n",
    "                # Initialize the origin offset only for position\n",
    "                #origin_offset_CAV=data_irl[key][0][indices_to_train[0]]\n",
    "                #origin_offset_HDV=data_irl[key][1][indices_to_train[0]]\n",
    "                \n",
    "                # For now we are not doing origin offset \n",
    "                origin_offset_CAV=0    \n",
    "                origin_offset_HDV=0\n",
    "\n",
    "                for time_step in indices_to_test_cropped:\n",
    "\n",
    "                    observation_list=[]\n",
    "                    for i in range(len(data_irl[key])-2): # exclude the last two columns (actions/inputs)\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if i==0:\n",
    "                            temp=temp-origin_offset_CAV\n",
    "                        elif i==1:\n",
    "                            temp=temp-origin_offset_HDV\n",
    "                        if temp!= None:\n",
    "                            observation_list.append(temp)\n",
    "                    input_list=[]\n",
    "                    input_list.extend(observation_list)\n",
    "                    input_list.extend(action_list)\n",
    "                    input_tensor=torch.tensor(input_list,dtype=torch.float).to(self.device) \n",
    "\n",
    "                    print(\"observation_list\",observation_list)                   \n",
    "                    print(\"action_list\",action_list)                   \n",
    "\n",
    "\n",
    "                    # Update action list for the next time step \n",
    "                    for i in [4,5]:\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if temp!= None:\n",
    "                            action_list[i-4]=temp\n",
    "                        else:\n",
    "                            action_list[i-4]=0\n",
    "                    \n",
    "                    print(\"new_action_list\",action_list) \n",
    "\n",
    "                    '''\n",
    "                    ### For no skip between predictions\n",
    "                    reference_list=[]\n",
    "                    for k in range(self.rollout):\n",
    "                        for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                            if i==1:# min is self.rollout\n",
    "                                #rint(\"key\",key)\n",
    "                                #print(\"i\",i)\n",
    "                                #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                            \n",
    "                            elif i==3:\n",
    "                                reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                            elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                reference_list.append(data_irl[key][i][time_step+k])\n",
    "                            \n",
    "                            else:\n",
    "                                reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                    '''\n",
    "\n",
    "                    \n",
    "                    ### Skip between predictions\n",
    "                    reference_list=[]\n",
    "                    if (time_step+self.rollout*(self.n_skips+1))>=len(data_irl[key][i]):\n",
    "                        continue\n",
    "                    else:\n",
    "                        for k in range(self.n_skips,self.rollout*(self.n_skips+1),self.n_skips+1):\n",
    "                            #print(range(self.n_skips,self.rollout*(self.n_skips+1),self.n_skips+1))\n",
    "                            #print(\"k\",k,\"\\n\")\n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i==1:# min is self.rollout\n",
    "                                    #rint(\"key\",key)\n",
    "                                    #print(\"i\",i)\n",
    "                                    #print(\"time_step+k+1\",time_step+k+1)\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1]-origin_offset_HDV)\n",
    "                                \n",
    "                                elif i==3:\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                \n",
    "                                else:\n",
    "                                    reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "\n",
    "                    reference_tensor=torch.tensor(reference_list,dtype=torch.float).to(self.device)\n",
    "                    \n",
    "                    temp=[]\n",
    "                    temp.append(reference_tensor.detach().cpu().numpy().tolist())\n",
    "\n",
    "                    ais_rollout_enc=self.gen_model(input_tensor,ais_rollout_enc)\n",
    "                    # Adding the (action of CAV)_t as an inpug to the decoder\n",
    "                    decoder_input=torch.cat((ais_rollout_enc,torch.tensor([action_list[0]],dtype=torch.float).to(self.device)),dim=0)\n",
    "\n",
    "                    decoder_prediction=self.pred_model(decoder_input)\n",
    "\n",
    "                    ## Mulitvariate normal distribution loss\n",
    "                    #time_step_loss+=torch.distributions.MultivariateNormal(decoder_prediction,torch.eye(self.n_output).to(self.device)).log_prob(reference_tensor)\n",
    "                    ## MSE loss\n",
    "                    time_step_loss+=torch.nn.functional.mse_loss(decoder_prediction,reference_tensor)                    \n",
    "                    #print(\"time_step_loss: \",time_step_loss)\n",
    "                    print(\"time_step: \",time_step)\n",
    "                    print(\"reference_tensor: \",reference_tensor)\n",
    "                    print(\"decoder_prediction: \",decoder_prediction,\"\\n\")\n",
    "\n",
    "                    temp.append(decoder_prediction.detach().cpu().numpy().tolist())\n",
    "                    test_results.append(temp)\n",
    "                \n",
    "            return test_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Parameters #######\n",
    "n_epochs=200\n",
    "min_timesteps=50\n",
    "n_rollout=10\n",
    "n_skips_per_rollout=0\n",
    "n_test=1\n",
    "n_input=6\n",
    "n_output=n_rollout*3 # 3 for each of the next n_rollout time steps\n",
    "n_state_enc=4\n",
    "learning_rate=0.0003\n",
    "gen_model=1\n",
    "pred_model=1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started\n",
      "epoch_loss is  tensor(7300114.5000, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  0\n",
      "epoch_loss is  tensor(551406.9375, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  1\n",
      "epoch_loss is  tensor(288874.4062, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  2\n",
      "epoch_loss is  tensor(191810.1719, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  3\n",
      "epoch_loss is  tensor(149198.4062, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#                             ] 100% | ETA: 06:29:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(127342.8359, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  5\n",
      "epoch_loss is  tensor(113850.7109, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  6\n",
      "epoch_loss is  tensor(100355.0938, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  7\n",
      "epoch_loss is  tensor(88766.5547, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  8\n",
      "epoch_loss is  tensor(82618.7109, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  9\n",
      "epoch_loss is  tensor(78750.8125, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  10\n",
      "epoch_loss is  tensor(72491.6562, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##                            ] 100% | ETA: 07:03:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(70302.6484, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  12\n",
      "epoch_loss is  tensor(68355.5312, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  13\n",
      "epoch_loss is  tensor(61338.7422, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  14\n",
      "epoch_loss is  tensor(67490.4375, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  15\n",
      "epoch_loss is  tensor(58293.2617, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  16\n",
      "epoch_loss is  tensor(58987.0742, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [###                           ] 100% | ETA: 07:00:32"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(55649.4023, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  18\n",
      "epoch_loss is  tensor(55047.2344, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  19\n",
      "epoch_loss is  tensor(52464.0977, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  20\n",
      "epoch_loss is  tensor(52516.5391, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  21\n",
      "epoch_loss is  tensor(51808.4492, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  22\n",
      "epoch_loss is  tensor(55523.3398, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  23\n",
      "epoch_loss is  tensor(50620.3008, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [####                          ] 100% | ETA: 06:51:28"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(51218.6250, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  25\n",
      "epoch_loss is  tensor(50828.7578, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  26\n",
      "epoch_loss is  tensor(52823.4336, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  27\n",
      "epoch_loss is  tensor(51171.7109, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  28\n",
      "epoch_loss is  tensor(51081.0742, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  29\n",
      "epoch_loss is  tensor(48662.1758, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  30\n",
      "epoch_loss is  tensor(48375.1875, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#####                         ] 100% | ETA: 06:40:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(46770.0273, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  32\n",
      "epoch_loss is  tensor(47181.4023, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  33\n",
      "epoch_loss is  tensor(48575.8906, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  34\n",
      "epoch_loss is  tensor(51077.7070, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  35\n",
      "epoch_loss is  tensor(47590.5781, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  36\n",
      "epoch_loss is  tensor(46436.4883, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [######                        ] 100% | ETA: 06:28:53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(45107.9531, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  38\n",
      "epoch_loss is  tensor(46467.7383, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  39\n",
      "epoch_loss is  tensor(46583.9219, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  40\n",
      "epoch_loss is  tensor(45398.7773, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  41\n",
      "epoch_loss is  tensor(44814.8438, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  42\n",
      "epoch_loss is  tensor(44878.0430, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  43\n",
      "epoch_loss is  tensor(44451.8594, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#######                       ] 100% | ETA: 06:14:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(44264.0586, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  45\n",
      "epoch_loss is  tensor(44367.3516, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  46\n",
      "epoch_loss is  tensor(44340.3164, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  47\n",
      "epoch_loss is  tensor(43978.6602, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  48\n",
      "epoch_loss is  tensor(43217.7383, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  49\n",
      "epoch_loss is  tensor(43393.0078, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  50\n",
      "epoch_loss is  tensor(42951.8359, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [########                      ] 100% | ETA: 05:58:48"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(43881.9648, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  52\n",
      "epoch_loss is  tensor(43892.4922, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  53\n",
      "epoch_loss is  tensor(42609.3672, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  54\n",
      "epoch_loss is  tensor(43572.5469, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  55\n",
      "epoch_loss is  tensor(42179.7305, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  56\n",
      "epoch_loss is  tensor(41886.8828, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#########                     ] 100% | ETA: 05:45:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(41564.9453, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  58\n",
      "epoch_loss is  tensor(42328.6719, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  59\n",
      "epoch_loss is  tensor(41798.2422, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  60\n",
      "epoch_loss is  tensor(40859.0391, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  61\n",
      "epoch_loss is  tensor(41550.1406, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  62\n",
      "epoch_loss is  tensor(41374.7539, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  63\n",
      "epoch_loss is  tensor(40765.6562, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##########                    ] 100% | ETA: 05:29:50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(44955.8086, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  65\n",
      "epoch_loss is  tensor(40480.3047, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  66\n",
      "epoch_loss is  tensor(39936.6406, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  67\n",
      "epoch_loss is  tensor(39922.5430, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  68\n",
      "epoch_loss is  tensor(40243.1484, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  69\n",
      "epoch_loss is  tensor(40559.7891, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  70\n",
      "epoch_loss is  tensor(40573.9375, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [###########                   ] 100% | ETA: 05:13:25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(39924.1758, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  72\n",
      "epoch_loss is  tensor(47991.8672, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  73\n",
      "epoch_loss is  tensor(39308.2930, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  74\n",
      "epoch_loss is  tensor(39296.8672, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  75\n",
      "epoch_loss is  tensor(39292.0039, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  76\n",
      "epoch_loss is  tensor(38990.2031, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [############                  ] 100% | ETA: 04:59:17"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(38732.5273, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  78\n",
      "epoch_loss is  tensor(38703.5742, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  79\n",
      "epoch_loss is  tensor(38714.9141, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  80\n",
      "epoch_loss is  tensor(37633.4336, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  81\n",
      "epoch_loss is  tensor(38880.6523, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  82\n",
      "epoch_loss is  tensor(37593.0156, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  83\n",
      "epoch_loss is  tensor(38044.7734, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#############                 ] 100% | ETA: 04:42:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(38221.2617, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  85\n",
      "epoch_loss is  tensor(37926.6172, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  86\n",
      "epoch_loss is  tensor(37096.0508, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  87\n",
      "epoch_loss is  tensor(38015.8906, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  88\n",
      "epoch_loss is  tensor(37422.0977, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  89\n",
      "epoch_loss is  tensor(38020.1484, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  90\n",
      "epoch_loss is  tensor(37440.0039, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############                ] 100% | ETA: 04:26:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(36749.1094, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  92\n",
      "epoch_loss is  tensor(38152.0156, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  93\n",
      "epoch_loss is  tensor(37370.3008, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  94\n",
      "epoch_loss is  tensor(37219.5430, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  95\n",
      "epoch_loss is  tensor(35907.4180, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  96\n",
      "epoch_loss is  tensor(37042.8359, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [###############               ] 100% | ETA: 04:11:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(37730.9062, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  98\n",
      "epoch_loss is  tensor(35909.7344, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  99\n",
      "epoch_loss is  tensor(36952.8086, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  100\n",
      "epoch_loss is  tensor(36403.9492, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  101\n",
      "epoch_loss is  tensor(36431.4609, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  102\n",
      "epoch_loss is  tensor(36742.5977, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  103\n",
      "epoch_loss is  tensor(35459.0977, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [################              ] 100% | ETA: 03:55:15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(36113.0664, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  105\n",
      "epoch_loss is  tensor(36284.1484, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  106\n",
      "epoch_loss is  tensor(35453.1562, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  107\n",
      "epoch_loss is  tensor(35509.1133, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  108\n",
      "epoch_loss is  tensor(34758.4844, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  109\n",
      "epoch_loss is  tensor(36785.9805, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  110\n",
      "epoch_loss is  tensor(35165.3750, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#################             ] 100% | ETA: 03:38:02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(34457.3242, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  112\n",
      "epoch_loss is  tensor(34844.0859, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  113\n",
      "epoch_loss is  tensor(34092.0938, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  114\n",
      "epoch_loss is  tensor(34573.6250, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  115\n",
      "epoch_loss is  tensor(35242.0859, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  116\n",
      "epoch_loss is  tensor(33949.1914, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##################            ] 100% | ETA: 03:23:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(34023.3047, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  118\n",
      "epoch_loss is  tensor(34297.5977, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  119\n",
      "epoch_loss is  tensor(34876.1055, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  120\n",
      "epoch_loss is  tensor(33717.4805, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  121\n",
      "epoch_loss is  tensor(33816.9688, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  122\n",
      "epoch_loss is  tensor(34478.4844, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  123\n",
      "epoch_loss is  tensor(33531.8594, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [###################           ] 100% | ETA: 03:05:49"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(34233.8672, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  125\n",
      "epoch_loss is  tensor(33171.3750, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  126\n",
      "epoch_loss is  tensor(33466.5547, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  127\n",
      "epoch_loss is  tensor(34019.9961, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  128\n",
      "epoch_loss is  tensor(32793.3750, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  129\n",
      "epoch_loss is  tensor(32696.2344, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  130\n",
      "epoch_loss is  tensor(33235.3242, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [####################          ] 100% | ETA: 02:48:21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(32600.1973, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  132\n",
      "epoch_loss is  tensor(32749.2500, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  133\n",
      "epoch_loss is  tensor(39641.7812, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  134\n",
      "epoch_loss is  tensor(32921.9180, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  135\n",
      "epoch_loss is  tensor(32143.0215, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  136\n",
      "epoch_loss is  tensor(32041.8750, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#####################         ] 100% | ETA: 02:33:16"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(32519.5742, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  138\n",
      "epoch_loss is  tensor(31807.3203, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  139\n",
      "epoch_loss is  tensor(32174.0996, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  140\n",
      "epoch_loss is  tensor(31516.4980, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  141\n",
      "epoch_loss is  tensor(34515.9609, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  142\n",
      "epoch_loss is  tensor(31538.0098, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  143\n",
      "epoch_loss is  tensor(31555.2285, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [######################        ] 100% | ETA: 02:15:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(31615.6387, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  145\n",
      "epoch_loss is  tensor(31898.0879, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  146\n",
      "epoch_loss is  tensor(31484.3086, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  147\n",
      "epoch_loss is  tensor(31172.2988, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  148\n",
      "epoch_loss is  tensor(31909.1582, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  149\n",
      "epoch_loss is  tensor(30927.2168, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  150\n",
      "epoch_loss is  tensor(31138.0098, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#######################       ] 100% | ETA: 01:57:55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(31224.8223, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  152\n",
      "epoch_loss is  tensor(31084.9395, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  153\n",
      "epoch_loss is  tensor(34969.4219, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  154\n",
      "epoch_loss is  tensor(30878.4102, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  155\n",
      "epoch_loss is  tensor(32173.7344, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  156\n",
      "epoch_loss is  tensor(31201.2617, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [########################      ] 100% | ETA: 01:42:39"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(31067.3711, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  158\n",
      "epoch_loss is  tensor(30349.2871, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  159\n",
      "epoch_loss is  tensor(31031.9453, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  160\n",
      "epoch_loss is  tensor(30457.8555, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  161\n",
      "epoch_loss is  tensor(31059.3184, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  162\n",
      "epoch_loss is  tensor(29995.0801, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  163\n",
      "epoch_loss is  tensor(30218.5234, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#########################     ] 100% | ETA: 01:24:46"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(30376.3066, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  165\n",
      "epoch_loss is  tensor(30523.2051, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  166\n",
      "epoch_loss is  tensor(30091.7734, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  167\n",
      "epoch_loss is  tensor(30786.8789, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  168\n",
      "epoch_loss is  tensor(30822.8008, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  169\n",
      "epoch_loss is  tensor(29933.2246, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  170\n",
      "epoch_loss is  tensor(30271.8223, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##########################    ] 100% | ETA: 01:06:53"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(29943.5273, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  172\n",
      "epoch_loss is  tensor(29800.9688, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  173\n",
      "epoch_loss is  tensor(29731.2344, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  174\n",
      "epoch_loss is  tensor(31024.4746, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  175\n",
      "epoch_loss is  tensor(30047.5371, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  176\n",
      "epoch_loss is  tensor(30793.9512, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [###########################   ] 100% | ETA: 00:51:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(29496.8535, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  178\n",
      "epoch_loss is  tensor(29945.5664, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  179\n",
      "epoch_loss is  tensor(29304.5391, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  180\n",
      "epoch_loss is  tensor(29410.0234, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  181\n",
      "epoch_loss is  tensor(29759.4785, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  182\n",
      "epoch_loss is  tensor(29262.4219, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  183\n",
      "epoch_loss is  tensor(29981.5723, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [############################  ] 100% | ETA: 00:33:30"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(29564.4160, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  185\n",
      "epoch_loss is  tensor(30353.0078, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  186\n",
      "epoch_loss is  tensor(29630.7637, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  187\n",
      "epoch_loss is  tensor(29166.2148, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  188\n",
      "epoch_loss is  tensor(29739.6875, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  189\n",
      "epoch_loss is  tensor(29205.2832, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  190\n",
      "epoch_loss is  tensor(29150.8535, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [############################# ] 100% | ETA: 00:15:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(28809.8848, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  192\n",
      "epoch_loss is  tensor(28865.3398, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  193\n",
      "epoch_loss is  tensor(29167.5957, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  194\n",
      "epoch_loss is  tensor(28544.7559, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  195\n",
      "epoch_loss is  tensor(30144.4004, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  196\n",
      "epoch_loss is  tensor(28713.8184, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(28674.9336, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 08:37:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss is  tensor(28844.9023, grad_fn=<AddBackward0>) \n",
      "\n",
      "saving model weights for epoch  199\n"
     ]
    }
   ],
   "source": [
    "####### Initialise the neural network #######\n",
    "\n",
    "network=NN_structure(n_epochs,min_timesteps,n_rollout,n_skips_per_rollout,n_test,n_input,n_output,n_state_enc,learning_rate,gen_model,pred_model,device)\n",
    "\n",
    "print(\"Training has started\")\n",
    "network.train(load_previous_weights=True)\n",
    "\n",
    "## try with shifted origin\n",
    "## try shifted origin with both 1 and 0.1 standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names of files-Encoder ../trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen1_816_pred1_24_epochs200_learning_rate0.0003_hidden_states4encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included_for_results.pth \n",
      "\n",
      "names of files-Decoder ../trained_models/IRL_based_models/IRL_SVOpolicy_ais_pred1_24_gen1_816_epochs200_learning_rate0.0003_hidden_states4encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included_for_results.pth \n",
      "\n",
      "observation_list [149.65217406609435, -27.201712802146275, 12.000000009891926, 3.6500490830426777]\n",
      "action_list [0, 0]\n",
      "new_action_list [-6.960498527352878e-12, 0.6791419911753701]\n",
      "time_step:  87\n",
      "reference_tensor:  tensor([-26.4581,   3.7859,   0.6791, -25.6874,   3.9213,   0.6771, -24.8897,\n",
      "          4.0562,   0.6747, -24.0650,   4.1906,   0.6719, -23.2135,   4.3244,\n",
      "          0.6689, -22.3353,   4.4575,   0.6655, -21.4305,   4.5899,   0.6619,\n",
      "        -20.4994,   4.7215,   0.6580, -19.5420,   4.8523,   0.6539, -18.5586,\n",
      "          4.9822,   0.6496])\n",
      "decoder_prediction:  tensor([-26.6538,   4.1121,   1.1416, -25.7356,   4.3984,   1.1030, -24.8174,\n",
      "          4.5297,   1.0643, -23.9938,   4.7198,   1.0186, -22.9464,   4.9024,\n",
      "          0.9795, -21.9838,   5.0384,   0.9171, -20.9942,   5.1871,   0.8490,\n",
      "        -19.9032,   5.2724,   0.8007, -18.8970,   5.4547,   0.7543, -17.7192,\n",
      "          5.5768,   0.6961], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [152.0521740680726, -26.458120145714233, 12.000000009890533, 3.7858774812777516]\n",
      "action_list [-6.960498527352878e-12, 0.6791419911753701]\n",
      "new_action_list [-7.0173205954743985e-12, 0.6770977556240035]\n",
      "time_step:  88\n",
      "reference_tensor:  tensor([-25.6874,   3.9213,   0.6771, -24.8897,   4.0562,   0.6747, -24.0650,\n",
      "          4.1906,   0.6719, -23.2135,   4.3244,   0.6689, -22.3353,   4.4575,\n",
      "          0.6655, -21.4305,   4.5899,   0.6619, -20.4994,   4.7215,   0.6580,\n",
      "        -19.5420,   4.8523,   0.6539, -18.5586,   4.9822,   0.6496, -17.5492,\n",
      "          5.1112,   0.6450])\n",
      "decoder_prediction:  tensor([-25.6303,   3.7845,   1.3131, -24.7678,   4.1269,   1.2666, -23.8959,\n",
      "          4.2620,   1.2261, -23.1420,   4.4801,   1.1755, -22.1167,   4.6933,\n",
      "          1.1373, -21.2059,   4.8464,   1.0619, -20.2663,   5.0127,   0.9786,\n",
      "        -19.2002,   5.0983,   0.9241, -18.2444,   5.3182,   0.8730, -17.0735,\n",
      "          5.4515,   0.8022], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [154.45217407005055, -25.687402694346204, 12.00000000988913, 3.9212970324025522]\n",
      "action_list [-7.0173205954743985e-12, 0.6770977556240035]\n",
      "new_action_list [-7.384819615865177e-12, 0.6746892702264428]\n",
      "time_step:  89\n",
      "reference_tensor:  tensor([-24.8897,   4.0562,   0.6747, -24.0650,   4.1906,   0.6719, -23.2135,\n",
      "          4.3244,   0.6689, -22.3353,   4.4575,   0.6655, -21.4305,   4.5899,\n",
      "          0.6619, -20.4994,   4.7215,   0.6580, -19.5420,   4.8523,   0.6539,\n",
      "        -18.5586,   4.9822,   0.6496, -17.5492,   5.1112,   0.6450, -16.5142,\n",
      "          5.2392,   0.6403])\n",
      "decoder_prediction:  tensor([-24.8896,   3.8151,   1.3568, -24.0172,   4.1735,   1.3074, -23.1335,\n",
      "          4.3070,   1.2669, -22.3761,   4.5328,   1.2155, -21.3313,   4.7533,\n",
      "          1.1785, -20.4133,   4.9103,   1.0997, -19.4643,   5.0804,   1.0126,\n",
      "        -18.3809,   5.1659,   0.9572, -17.4176,   5.3960,   0.9054, -16.2240,\n",
      "          5.5327,   0.8314], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [156.85217407202822, -24.889649502461165, 12.000000009887653, 4.05623488644784]\n",
      "action_list [-7.384819615865177e-12, 0.6746892702264428]\n",
      "new_action_list [-6.848431314689651e-12, 0.6719419063863888]\n",
      "time_step:  90\n",
      "reference_tensor:  tensor([-24.0650,   4.1906,   0.6719, -23.2135,   4.3244,   0.6689, -22.3353,\n",
      "          4.4575,   0.6655, -21.4305,   4.5899,   0.6619, -20.4994,   4.7215,\n",
      "          0.6580, -19.5420,   4.8523,   0.6539, -18.5586,   4.9822,   0.6496,\n",
      "        -17.5492,   5.1112,   0.6450, -16.5142,   5.2392,   0.6403, -15.4536,\n",
      "          5.3663,   0.6354])\n",
      "decoder_prediction:  tensor([-24.1851,   3.9561,   1.3470, -23.2824,   4.3144,   1.2974, -22.3703,\n",
      "          4.4437,   1.2583, -21.5869,   4.6691,   1.2084, -20.5123,   4.8879,\n",
      "          1.1734, -19.5706,   5.0434,   1.0951, -18.5949,   5.2120,   1.0091,\n",
      "        -17.4839,   5.2975,   0.9551, -16.4964,   5.5269,   0.9046, -15.2747,\n",
      "          5.6642,   0.8311], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [159.2521740740056, -24.064963687043868, 12.000000009886284, 4.190623267725118]\n",
      "action_list [-6.848431314689651e-12, 0.6719419063863888]\n",
      "new_action_list [-7.48807837215164e-12, 0.6688793148735015]\n",
      "time_step:  91\n",
      "reference_tensor:  tensor([-23.2135,   4.3244,   0.6689, -22.3353,   4.4575,   0.6655, -21.4305,\n",
      "          4.5899,   0.6619, -20.4994,   4.7215,   0.6580, -19.5420,   4.8523,\n",
      "          0.6539, -18.5586,   4.9822,   0.6496, -17.5492,   5.1112,   0.6450,\n",
      "        -16.5142,   5.2392,   0.6403, -15.4536,   5.3663,   0.6354, -14.3678,\n",
      "          5.4924,   0.6303])\n",
      "decoder_prediction:  tensor([-23.4383,   4.1342,   1.3093, -22.4983,   4.4845,   1.2611, -21.5532,\n",
      "          4.6080,   1.2247, -20.7363,   4.8289,   1.1777, -19.6302,   5.0416,\n",
      "          1.1454, -18.6601,   5.1931,   1.0699, -17.6527,   5.3575,   0.9874,\n",
      "        -16.5126,   5.4431,   0.9362, -15.4963,   5.6668,   0.8881, -14.2472,\n",
      "          5.8034,   0.8171], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [161.6521740759827, -23.213461447201375, 12.000000009884786, 4.324399130699819]\n",
      "action_list [-7.48807837215164e-12, 0.6688793148735015]\n",
      "new_action_list [-6.898623885413972e-12, 0.6655235636024158]\n",
      "time_step:  92\n",
      "reference_tensor:  tensor([-22.3353,   4.4575,   0.6655, -21.4305,   4.5899,   0.6619, -20.4994,\n",
      "          4.7215,   0.6580, -19.5420,   4.8523,   0.6539, -18.5586,   4.9822,\n",
      "          0.6496, -17.5492,   5.1112,   0.6450, -16.5142,   5.2392,   0.6403,\n",
      "        -15.4536,   5.3663,   0.6354, -14.3678,   5.4924,   0.6303, -13.2568,\n",
      "          5.6174,   0.6251])\n",
      "decoder_prediction:  tensor([-22.6232,   4.3212,   1.2547, -21.6440,   4.6590,   1.2091, -20.6656,\n",
      "          4.7756,   1.1763, -19.8136,   4.9897,   1.1333, -18.6774,   5.1939,\n",
      "          1.1045, -17.6789,   5.3401,   1.0332, -16.6392,   5.4987,   0.9557,\n",
      "        -15.4714,   5.5846,   0.9082, -14.4264,   5.7999,   0.8633, -13.1526,\n",
      "          5.9351,   0.7959], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [164.05217407795953, -22.335271149789364, 12.000000009883406, 4.457503843420302]\n",
      "action_list [-6.898623885413972e-12, 0.6655235636024158]\n",
      "new_action_list [-7.25236258340235e-12, 0.6618952628846696]\n",
      "time_step:  93\n",
      "reference_tensor:  tensor([-21.4305,   4.5899,   0.6619, -20.4994,   4.7215,   0.6580, -19.5420,\n",
      "          4.8523,   0.6539, -18.5586,   4.9822,   0.6496, -17.5492,   5.1112,\n",
      "          0.6450, -16.5142,   5.2392,   0.6403, -15.4536,   5.3663,   0.6354,\n",
      "        -14.3678,   5.4924,   0.6303, -13.2568,   5.6174,   0.6251, -12.1209,\n",
      "          5.7414,   0.6198])\n",
      "decoder_prediction:  tensor([-21.7408,   4.5059,   1.1890, -20.7228,   4.8284,   1.1471, -19.7124,\n",
      "          4.9372,   1.1186, -18.8258,   5.1432,   1.0804, -17.6620,   5.3374,\n",
      "          1.0557, -16.6367,   5.4774,   0.9896, -15.5660,   5.6295,   0.9181,\n",
      "        -14.3730,   5.7157,   0.8749, -13.3007,   5.9211,   0.8337, -12.0053,\n",
      "          6.0546,   0.7707], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [166.45217407993607, -21.430532475847613, 12.000000009881955, 4.589882895997236]\n",
      "action_list [-7.25236258340235e-12, 0.6618952628846696]\n",
      "new_action_list [3.734578356924576e-10, 0.6580136794117964]\n",
      "time_step:  94\n",
      "reference_tensor:  tensor([-20.4994,   4.7215,   0.6580, -19.5420,   4.8523,   0.6539, -18.5586,\n",
      "          4.9822,   0.6496, -17.5492,   5.1112,   0.6450, -16.5142,   5.2392,\n",
      "          0.6403, -15.4536,   5.3663,   0.6354, -14.3678,   5.4924,   0.6303,\n",
      "        -13.2568,   5.6174,   0.6251, -12.1209,   5.7414,   0.6198, -10.9604,\n",
      "          5.8642,   0.6143])\n",
      "decoder_prediction:  tensor([-20.8059,   4.6850,   1.1165, -19.7500,   4.9904,   1.0788, -18.7095,\n",
      "          5.0910,   1.0553, -17.7895,   5.2881,   1.0225, -16.6004,   5.4713,\n",
      "          1.0023, -15.5501,   5.6048,   0.9420, -14.4499,   5.7498,   0.8770,\n",
      "        -13.2341,   5.8363,   0.8386, -12.1364,   6.0310,   0.8015, -10.8221,\n",
      "          6.1626,   0.7433], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [168.85217408191994, -20.499395623059932, 12.000000009956647, 4.721485631879595]\n",
      "action_list [3.734578356924576e-10, 0.6580136794117964]\n",
      "new_action_list [-3.880979865210967e-10, 0.6538968400888838]\n",
      "time_step:  95\n",
      "reference_tensor:  tensor([-19.5420,   4.8523,   0.6539, -18.5586,   4.9822,   0.6496, -17.5492,\n",
      "          5.1112,   0.6450, -16.5142,   5.2392,   0.6403, -15.4536,   5.3663,\n",
      "          0.6354, -14.3678,   5.4924,   0.6303, -13.2568,   5.6174,   0.6251,\n",
      "        -12.1209,   5.7414,   0.6198, -10.9604,   5.8642,   0.6143,  -9.7753,\n",
      "          5.9860,   0.6087])\n",
      "decoder_prediction:  tensor([-19.8309,   4.8589,   1.0394, -18.7379,   5.1462,   1.0065, -17.6686,\n",
      "          5.2383,   0.9883, -16.7164,   5.4258,   0.9613, -15.5036,   5.5977,\n",
      "          0.9459, -14.4298,   5.7244,   0.8918, -13.3015,   5.8619,   0.8338,\n",
      "        -12.0646,   5.9489,   0.8004, -10.9429,   6.1323,   0.7678,  -9.6117,\n",
      "          6.2619,   0.7145], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [171.2521740839035, -19.542020559882232, 12.000000009879027, 4.852264999897372]\n",
      "action_list [-3.880979865210967e-10, 0.6538968400888838]\n",
      "new_action_list [-7.388083047542277e-12, 0.6495616267152334]\n",
      "time_step:  96\n",
      "reference_tensor:  tensor([-18.5586,   4.9822,   0.6496, -17.5492,   5.1112,   0.6450, -16.5142,\n",
      "          5.2392,   0.6403, -15.4536,   5.3663,   0.6354, -14.3678,   5.4924,\n",
      "          0.6303, -13.2568,   5.6174,   0.6251, -12.1209,   5.7414,   0.6198,\n",
      "        -10.9604,   5.8642,   0.6143,  -9.7753,   5.9860,   0.6087,  -8.5661,\n",
      "          6.1066,   0.6030])\n",
      "decoder_prediction:  tensor([-18.8249,   5.0296,   0.9595, -17.6954,   5.2982,   0.9316, -16.5983,\n",
      "          5.3815,   0.9190, -15.6144,   5.5591,   0.8980, -14.3792,   5.7193,\n",
      "          0.8877, -13.2828,   5.8389,   0.8401, -12.1271,   5.9688,   0.7893,\n",
      "        -10.8704,   6.0562,   0.7612,  -9.7255,   6.2281,   0.7331,  -8.3788,\n",
      "          6.3556,   0.6850], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [173.65217408587915, -18.558576327368456, 12.00000000987755, 4.982177325240419]\n",
      "action_list [-7.388083047542277e-12, 0.6495616267152334]\n",
      "new_action_list [-7.433851897228355e-12, 0.645023862401737]\n",
      "time_step:  97\n",
      "reference_tensor:  tensor([-17.5492,   5.1112,   0.6450, -16.5142,   5.2392,   0.6403, -15.4536,\n",
      "          5.3663,   0.6354, -14.3678,   5.4924,   0.6303, -13.2568,   5.6174,\n",
      "          0.6251, -12.1209,   5.7414,   0.6198, -10.9604,   5.8642,   0.6143,\n",
      "         -9.7753,   5.9860,   0.6087,  -8.5661,   6.1066,   0.6030,  -7.3328,\n",
      "          6.2260,   0.5972])\n",
      "decoder_prediction:  tensor([-17.7950,   5.1990,   0.8777, -16.6292,   5.4484,   0.8550, -15.5046,\n",
      "          5.5228,   0.8482, -14.4895,   5.6903,   0.8335, -13.2323,   5.8386,\n",
      "          0.8283, -12.1138,   5.9510,   0.7874, -10.9311,   6.0732,   0.7439,\n",
      "         -9.6550,   6.1610,   0.7212,  -8.4875,   6.3212,   0.6977,  -7.1258,\n",
      "          6.4466,   0.6550], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [176.05217408785452, -17.549240385072338, 12.000000009876063, 5.111182097720766]\n",
      "action_list [-7.433851897228355e-12, 0.645023862401737]\n",
      "new_action_list [-7.483315913497123e-12, 0.6402983905179228]\n",
      "time_step:  98\n",
      "reference_tensor:  tensor([-16.5142,   5.2392,   0.6403, -15.4536,   5.3663,   0.6354, -14.3678,\n",
      "          5.4924,   0.6303, -13.2568,   5.6174,   0.6251, -12.1209,   5.7414,\n",
      "          0.6198, -10.9604,   5.8642,   0.6143,  -9.7753,   5.9860,   0.6087,\n",
      "         -8.5661,   6.1066,   0.6030,  -7.3328,   6.2260,   0.5972,  -6.0758,\n",
      "          6.3443,   0.5914])\n",
      "decoder_prediction:  tensor([-16.7460,   5.3686,   0.7949, -15.5438,   5.5987,   0.7775, -14.3917,\n",
      "          5.6641,   0.7766, -13.3454,   5.8213,   0.7682, -12.0663,   5.9576,\n",
      "          0.7683, -10.9256,   6.0628,   0.7342,  -9.7161,   6.1772,   0.6981,\n",
      "         -8.4207,   6.2654,   0.6809,  -7.2306,   6.4138,   0.6621,  -5.8541,\n",
      "          6.5370,   0.6247], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [178.45217408982958, -16.51419799771783, 12.000000009874565, 5.23924177582435]\n",
      "action_list [-7.483315913497123e-12, 0.6402983905179228]\n",
      "new_action_list [-7.528792138502412e-12, 0.6353991468792884]\n",
      "time_step:  99\n",
      "reference_tensor:  tensor([-15.4536,   5.3663,   0.6354, -14.3678,   5.4924,   0.6303, -13.2568,\n",
      "          5.6174,   0.6251, -12.1209,   5.7414,   0.6198, -10.9604,   5.8642,\n",
      "          0.6143,  -9.7753,   5.9860,   0.6087,  -8.5661,   6.1066,   0.6030,\n",
      "         -7.3328,   6.2260,   0.5972,  -6.0758,   6.3443,   0.5914,  -4.7952,\n",
      "          6.4614,   0.5854])\n",
      "decoder_prediction:  tensor([-15.6808,   5.5396,   0.7116, -14.4419,   5.7502,   0.6997, -13.2622,\n",
      "          5.8065,   0.7047, -12.1843,   5.9533,   0.7027, -10.8832,   6.0776,\n",
      "          0.7080,  -9.7201,   6.1756,   0.6808,  -8.4835,   6.2822,   0.6522,\n",
      "         -7.1688,   6.3708,   0.6404,  -5.9558,   6.5074,   0.6265,  -4.5643,\n",
      "          6.6284,   0.5944], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [180.85217409180436, -15.453641659615371, 12.000000009873059, 5.366321605200208]\n",
      "action_list [-7.528792138502412e-12, 0.6353991468792884]\n",
      "new_action_list [-7.580329819121976e-12, 0.6303392258100587]\n",
      "time_step:  100\n",
      "reference_tensor:  tensor([-14.3678,   5.4924,   0.6303, -13.2568,   5.6174,   0.6251, -12.1209,\n",
      "          5.7414,   0.6198, -10.9604,   5.8642,   0.6143,  -9.7753,   5.9860,\n",
      "          0.6087,  -8.5661,   6.1066,   0.6030,  -7.3328,   6.2260,   0.5972,\n",
      "         -6.0758,   6.3443,   0.5914,  -4.7952,   6.4614,   0.5854,  -3.4913,\n",
      "          6.5773,   0.5794])\n",
      "decoder_prediction:  tensor([-14.6005,   5.7121,   0.6283, -13.3246,   5.9032,   0.6218, -12.1169,\n",
      "          5.9504,   0.6328, -11.0073,   6.0869,   0.6371,  -9.6838,   6.1992,\n",
      "          0.6478,  -8.4979,   6.2900,   0.6274,  -7.2339,   6.3888,   0.6063,\n",
      "         -5.8995,   6.4776,   0.6001,  -4.6634,   6.6026,   0.5909,  -3.2566,\n",
      "          6.7213,   0.5643], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [183.25217409377882, -14.367770554059128, 12.000000009871544, 5.49238945036222]\n",
      "action_list [-7.580329819121976e-12, 0.6303392258100587]\n",
      "new_action_list [-7.639064160333617e-12, 0.6251309406512672]\n",
      "time_step:  101\n",
      "reference_tensor:  tensor([-13.2568,   5.6174,   0.6251, -12.1209,   5.7414,   0.6198, -10.9604,\n",
      "          5.8642,   0.6143,  -9.7753,   5.9860,   0.6087,  -8.5661,   6.1066,\n",
      "          0.6030,  -7.3328,   6.2260,   0.5972,  -6.0758,   6.3443,   0.5914,\n",
      "         -4.7952,   6.4614,   0.5854,  -3.4913,   6.5773,   0.5794,  -2.1644,\n",
      "          6.6919,   0.5733])\n",
      "decoder_prediction:  tensor([-13.5039,   5.8858,   0.5453, -12.1909,   6.0575,   0.5443, -10.9549,\n",
      "          6.0958,   0.5611,  -9.8133,   6.2219,   0.5719,  -8.4672,   6.3223,\n",
      "          0.5878,  -7.2582,   6.4058,   0.5744,  -5.9666,   6.4969,   0.5607,\n",
      "         -4.6122,   6.5859,   0.5600,  -3.3527,   6.6993,   0.5556,  -1.9302,\n",
      "          6.8158,   0.5344], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [185.65217409575297, -13.256790045173659, 12.000000009870016, 5.617415638492473]\n",
      "action_list [-7.639064160333617e-12, 0.6251309406512672]\n",
      "new_action_list [-7.688333766528045e-12, 0.619785879225661]\n",
      "time_step:  102\n",
      "reference_tensor:  tensor([-12.1209,   5.7414,   0.6198, -10.9604,   5.8642,   0.6143,  -9.7753,\n",
      "          5.9860,   0.6087,  -8.5661,   6.1066,   0.6030,  -7.3328,   6.2260,\n",
      "          0.5972,  -6.0758,   6.3443,   0.5914,  -4.7952,   6.4614,   0.5854,\n",
      "         -3.4913,   6.5773,   0.5794,  -2.1644,   6.6919,   0.5733,  -0.8147,\n",
      "          6.8054,   0.5671])\n",
      "decoder_prediction:  tensor([-12.3878,   6.0598,   0.4627, -11.0376,   6.2122,   0.4672,  -9.7732,\n",
      "          6.2416,   0.4900,  -8.5996,   6.3573,   0.5072,  -7.2309,   6.4460,\n",
      "          0.5284,  -5.9984,   6.5223,   0.5219,  -4.6792,   6.6058,   0.5156,\n",
      "         -3.3046,   6.6949,   0.5203,  -2.0216,   6.7970,   0.5207,  -0.5832,\n",
      "          6.9111,   0.5049], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [188.0521740977268, -12.12091119989065, 12.000000009868478, 5.7413728143376055]\n",
      "action_list [-7.688333766528045e-12, 0.619785879225661]\n",
      "new_action_list [-7.738088905047153e-12, 0.6143149547192506]\n",
      "time_step:  103\n",
      "reference_tensor:  tensor([-10.9604,   5.8642,   0.6143,  -9.7753,   5.9860,   0.6087,  -8.5661,\n",
      "          6.1066,   0.6030,  -7.3328,   6.2260,   0.5972,  -6.0758,   6.3443,\n",
      "          0.5914,  -4.7952,   6.4614,   0.5854,  -3.4913,   6.5773,   0.5794,\n",
      "         -2.1644,   6.6919,   0.5733,  -0.8147,   6.8054,   0.5671,   0.5576,\n",
      "          6.9175,   0.5609])\n",
      "decoder_prediction:  tensor([-11.2461,   6.2327,   0.3805,  -9.8590,   6.3660,   0.3908,  -8.5664,\n",
      "          6.3867,   0.4194,  -7.3611,   6.4919,   0.4430,  -5.9698,   6.5691,\n",
      "          0.4696,  -4.7137,   6.6383,   0.4701,  -3.3672,   6.7143,   0.4711,\n",
      "         -1.9726,   6.8034,   0.4813,  -0.6661,   6.8944,   0.4865,   0.7881,\n",
      "          7.0062,   0.4760], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [190.45217409970036, -10.960350337928745, 12.00000000986693, 5.864235805281456]\n",
      "action_list [-7.738088905047153e-12, 0.6143149547192506]\n",
      "new_action_list [-7.798245603479141e-12, 0.6087284523933733]\n",
      "time_step:  104\n",
      "reference_tensor:  tensor([-9.7753,  5.9860,  0.6087, -8.5661,  6.1066,  0.6030, -7.3328,  6.2260,\n",
      "         0.5972, -6.0758,  6.3443,  0.5914, -4.7952,  6.4614,  0.5854, -3.4913,\n",
      "         6.5773,  0.5794, -2.1644,  6.6919,  0.5733, -0.8147,  6.8054,  0.5671,\n",
      "         0.5576,  6.9175,  0.5609,  1.9522,  7.0285,  0.5547])\n",
      "decoder_prediction:  tensor([-10.0696,   6.4030,   0.2988,  -8.6463,   6.5173,   0.3149,  -7.3258,\n",
      "          6.5293,   0.3494,  -6.0894,   6.6241,   0.3796,  -4.6761,   6.6899,\n",
      "          0.4114,  -3.3967,   6.7522,   0.4190,  -2.0233,   6.8209,   0.4273,\n",
      "         -0.6092,   6.9098,   0.4430,   0.7204,   6.9901,   0.4530,   2.1902,\n",
      "          7.0995,   0.4478], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [192.8521741016736, -9.775328607824584, 12.00000000986537, 5.9859814957601305]\n",
      "action_list [-7.798245603479141e-12, 0.6087284523933733]\n",
      "new_action_list [-7.852039846137295e-12, 0.6030360725002922]\n",
      "time_step:  105\n",
      "reference_tensor:  tensor([-8.5661,  6.1066,  0.6030, -7.3328,  6.2260,  0.5972, -6.0758,  6.3443,\n",
      "         0.5914, -4.7952,  6.4614,  0.5854, -3.4913,  6.5773,  0.5794, -2.1644,\n",
      "         6.6919,  0.5733, -0.8147,  6.8054,  0.5671,  0.5576,  6.9175,  0.5609,\n",
      "         1.9522,  7.0285,  0.5547,  3.3689,  7.1382,  0.5484])\n",
      "decoder_prediction:  tensor([-8.8453,  6.5687,  0.2174, -7.3867,  6.6642,  0.2395, -6.0393,  6.6677,\n",
      "         0.2800, -4.7728,  6.7520,  0.3168, -3.3384,  6.8068,  0.3541, -2.0361,\n",
      "         6.8622,  0.3689, -0.6369,  6.9239,  0.3843,  0.7960,  7.0122,  0.4056,\n",
      "         2.1479,  7.0824,  0.4204,  3.6326,  7.1893,  0.4205],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [195.25217410364652, -8.566071587222552, 12.0000000098638, 6.106588710260189]\n",
      "action_list [-7.852039846137295e-12, 0.6030360725002922]\n",
      "new_action_list [-7.909317919886834e-12, 0.5972469697389441]\n",
      "time_step:  106\n",
      "reference_tensor:  tensor([-7.3328,  6.2260,  0.5972, -6.0758,  6.3443,  0.5914, -4.7952,  6.4614,\n",
      "         0.5854, -3.4913,  6.5773,  0.5794, -2.1644,  6.6919,  0.5733, -0.8147,\n",
      "         6.8054,  0.5671,  0.5576,  6.9175,  0.5609,  1.9522,  7.0285,  0.5547,\n",
      "         3.3689,  7.1382,  0.5484,  4.8073,  7.2466,  0.5421])\n",
      "decoder_prediction:  tensor([-7.5560,  6.7279,  0.1360, -6.0634,  6.8047,  0.1645, -4.6903,  6.8000,\n",
      "         0.2112, -3.3951,  6.8736,  0.2548, -1.9410,  6.9177,  0.2975, -0.6165,\n",
      "         6.9663,  0.3197,  0.8071,  7.0212,  0.3423,  2.2576,  7.1088,  0.3691,\n",
      "         3.6307,  7.1693,  0.3889,  5.1293,  7.2737,  0.3943],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [197.65217410561914, -7.332808905775735, 12.000000009862218, 6.226038104207977]\n",
      "action_list [-7.909317919886834e-12, 0.5972469697389441]\n",
      "new_action_list [-7.962127215896503e-12, 0.591369789554986]\n",
      "time_step:  107\n",
      "reference_tensor:  tensor([-6.0758,  6.3443,  0.5914, -4.7952,  6.4614,  0.5854, -3.4913,  6.5773,\n",
      "         0.5794, -2.1644,  6.6919,  0.5733, -0.8147,  6.8054,  0.5671,  0.5576,\n",
      "         6.9175,  0.5609,  1.9522,  7.0285,  0.5547,  3.3689,  7.1382,  0.5484,\n",
      "         4.8073,  7.2466,  0.5421,  6.2674,  7.3537,  0.5357])\n",
      "decoder_prediction:  tensor([-6.1795,  6.8789,  0.0544, -4.6547,  6.9370,  0.0898, -3.2573,  6.9243,\n",
      "         0.1427, -1.9354,  6.9870,  0.1934, -0.4632,  7.0208,  0.2417,  0.8824,\n",
      "         7.0628,  0.2717,  2.3286,  7.1113,  0.3013,  3.7951,  7.1976,  0.3338,\n",
      "         5.1879,  7.2493,  0.3587,  6.6990,  7.3509,  0.3694],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [200.0521741075914, -6.075773889143036, 12.000000009860626, 6.344312062118974]\n",
      "action_list [-7.962127215896503e-12, 0.591369789554986]\n",
      "new_action_list [-8.029124969111645e-12, 0.5854127015602897]\n",
      "time_step:  108\n",
      "reference_tensor:  tensor([-4.7952,  6.4614,  0.5854, -3.4913,  6.5773,  0.5794, -2.1644,  6.6919,\n",
      "         0.5733, -0.8147,  6.8054,  0.5671,  0.5576,  6.9175,  0.5609,  1.9522,\n",
      "         7.0285,  0.5547,  3.3689,  7.1382,  0.5484,  4.8073,  7.2466,  0.5421,\n",
      "         6.2674,  7.3537,  0.5357,  7.7487,  7.4596,  0.5294])\n",
      "decoder_prediction:  tensor([-5.0194,  6.9549,  0.0976, -3.4804,  7.0256,  0.1331, -2.0608,  7.0178,\n",
      "         0.1832, -0.7289,  7.0842,  0.2337,  0.7677,  7.1265,  0.2823,  2.1389,\n",
      "         7.1717,  0.3108,  3.6008,  7.2282,  0.3362,  5.0917,  7.3086,  0.3684,\n",
      "         6.5045,  7.3745,  0.3910,  8.0459,  7.4773,  0.3998],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [202.45217410956337, -4.795203222688038, 12.00000000985902, 6.4613946024310325]\n",
      "action_list [-8.029124969111645e-12, 0.5854127015602897]\n",
      "new_action_list [-8.084523786376736e-12, 0.5793834303210968]\n",
      "time_step:  109\n",
      "reference_tensor:  tensor([-3.4913,  6.5773,  0.5794, -2.1644,  6.6919,  0.5733, -0.8147,  6.8054,\n",
      "         0.5671,  0.5576,  6.9175,  0.5609,  1.9522,  7.0285,  0.5547,  3.3689,\n",
      "         7.1382,  0.5484,  4.8073,  7.2466,  0.5421,  6.2674,  7.3537,  0.5357,\n",
      "         7.7487,  7.4596,  0.5294,  9.2511,  7.5642,  0.5230])\n",
      "decoder_prediction:  tensor([-3.7372,  7.0151,  0.1485, -2.1874,  7.1006,  0.1842, -0.7478,  7.0988,\n",
      "         0.2313,  0.5905,  7.1695,  0.2815,  2.1096,  7.2221,  0.3303,  3.5056,\n",
      "         7.2713,  0.3571,  4.9802,  7.3373,  0.3776,  6.4940,  7.4108,  0.4091,\n",
      "         7.9249,  7.4935,  0.4292,  9.4959,  7.5974,  0.4356],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [204.85217411153502, -3.4913366335954095, 12.000000009857404, 6.577271288495252]\n",
      "action_list [-8.084523786376736e-12, 0.5793834303210968]\n",
      "new_action_list [-8.146742293051074e-12, 0.5732892837408174]\n",
      "time_step:  110\n",
      "reference_tensor:  tensor([-2.1644,  6.6919,  0.5733, -0.8147,  6.8054,  0.5671,  0.5576,  6.9175,\n",
      "         0.5609,  1.9522,  7.0285,  0.5547,  3.3689,  7.1382,  0.5484,  4.8073,\n",
      "         7.2466,  0.5421,  6.2674,  7.3537,  0.5357,  7.7487,  7.4596,  0.5294,\n",
      "         9.2511,  7.5642,  0.5230, 10.7742,  7.6675,  0.5166])\n",
      "decoder_prediction:  tensor([-2.4009,  7.1495,  0.0608, -0.9074,  7.1948,  0.1177,  0.5262,  7.2127,\n",
      "         0.1772,  1.9470,  7.2543,  0.2157,  3.4128,  7.3175,  0.2646,  4.8827,\n",
      "         7.3767,  0.3041,  6.3667,  7.4370,  0.3396,  7.8651,  7.4809,  0.3540,\n",
      "         9.3694,  7.5775,  0.3754, 10.8927,  7.6400,  0.3825],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [207.25217411350633, -2.164416590221542, 12.000000009855775, 6.6919291452434155]\n",
      "action_list [-8.146742293051074e-12, 0.5732892837408174]\n",
      "new_action_list [-8.20767648042846e-12, 0.5671371792426131]\n",
      "time_step:  111\n",
      "reference_tensor:  tensor([-0.8147,  6.8054,  0.5671,  0.5576,  6.9175,  0.5609,  1.9522,  7.0285,\n",
      "         0.5547,  3.3689,  7.1382,  0.5484,  4.8073,  7.2466,  0.5421,  6.2674,\n",
      "         7.3537,  0.5357,  7.7487,  7.4596,  0.5294,  9.2511,  7.5642,  0.5230,\n",
      "        10.7742,  7.6675,  0.5166, 12.3179,  7.7695,  0.5101])\n",
      "decoder_prediction:  tensor([-0.9575,  7.3098, -0.0577,  0.4733,  7.3059,  0.0210,  1.8988,  7.3398,\n",
      "         0.0979,  3.4187,  7.3508,  0.1228,  4.8242,  7.4205,  0.1750,  6.3689,\n",
      "         7.4901,  0.2270,  7.8665,  7.5396,  0.2836,  9.3464,  7.5544,  0.2786,\n",
      "        10.9349,  7.6602,  0.3008, 12.3977,  7.6777,  0.3096],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [209.6521741154773, -0.8146880175880042, 12.000000009854134, 6.805356581091938]\n",
      "action_list [-8.20767648042846e-12, 0.5671371792426131]\n",
      "new_action_list [-8.268153473732904e-12, 0.5609336679381952]\n",
      "time_step:  112\n",
      "reference_tensor:  tensor([ 0.5576,  6.9175,  0.5609,  1.9522,  7.0285,  0.5547,  3.3689,  7.1382,\n",
      "         0.5484,  4.8073,  7.2466,  0.5421,  6.2674,  7.3537,  0.5357,  7.7487,\n",
      "         7.4596,  0.5294,  9.2511,  7.5642,  0.5230, 10.7742,  7.6675,  0.5166,\n",
      "        12.3179,  7.7695,  0.5101, 13.8819,  7.8703,  0.5037])\n",
      "decoder_prediction:  tensor([ 3.8892e-01,  7.3686e+00, -7.9156e-02,  1.8081e+00,  7.3555e+00,\n",
      "        -3.0663e-03,  3.2399e+00,  7.3885e+00,  7.8087e-02,  4.7972e+00,\n",
      "         7.4077e+00,  1.0168e-01,  6.2047e+00,  7.4708e+00,  1.5873e-01,\n",
      "         7.7501e+00,  7.5444e+00,  2.0113e-01,  9.2664e+00,  7.5893e+00,\n",
      "         2.6045e-01,  1.0751e+01,  7.6156e+00,  2.5256e-01,  1.2364e+01,\n",
      "         7.7091e+00,  2.6805e-01,  1.3820e+01,  7.7275e+00,  2.7532e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [212.05217411744798, 0.5576019719891505, 12.00000000985248, 6.917543314679577]\n",
      "action_list [-8.268153473732904e-12, 0.5609336679381952]\n",
      "new_action_list [4.66993041760343e-10, 0.55468495695244]\n",
      "time_step:  113\n",
      "reference_tensor:  tensor([ 1.9522,  7.0285,  0.5547,  3.3689,  7.1382,  0.5484,  4.8073,  7.2466,\n",
      "         0.5421,  6.2674,  7.3537,  0.5357,  7.7487,  7.4596,  0.5294,  9.2511,\n",
      "         7.5642,  0.5230, 10.7742,  7.6675,  0.5166, 12.3179,  7.7695,  0.5101,\n",
      "        13.8819,  7.8703,  0.5037, 15.4659,  7.9697,  0.4973])\n",
      "decoder_prediction:  tensor([ 1.8826e+00,  7.4318e+00, -7.1866e-02,  3.3007e+00,  7.4173e+00,\n",
      "        -2.4182e-03,  4.7473e+00,  7.4511e+00,  7.8378e-02,  6.3370e+00,\n",
      "         7.4852e+00,  1.0280e-01,  7.7619e+00,  7.5419e+00,  1.6220e-01,\n",
      "         9.3040e+00,  7.6195e+00,  1.9076e-01,  1.0845e+01,  7.6626e+00,\n",
      "         2.4582e-01,  1.2343e+01,  7.7078e+00,  2.3779e-01,  1.3977e+01,\n",
      "         7.7857e+00,  2.4455e-01,  1.5443e+01,  7.8125e+00,  2.4864e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-50.0, -52.042501262968905, 10.0, 10.220449051643698]\n",
      "action_list [0, 0]\n",
      "new_action_list [-5.0, 0.22367772638495537]\n",
      "time_step:  0\n",
      "reference_tensor:  tensor([-49.9939,  10.2652,   0.2237, -47.9365,  10.3087,   0.2177, -45.8706,\n",
      "         10.3511,   0.2118, -43.7962,  10.3923,   0.2062, -41.7138,  10.4324,\n",
      "          0.2007, -39.6234,  10.4715,   0.1954, -37.5252,  10.5096,   0.1902,\n",
      "        -35.4196,  10.5466,   0.1853, -33.3067,  10.5827,   0.1806, -31.1866,\n",
      "         10.6179,   0.1760])\n",
      "decoder_prediction:  tensor([-50.2318,  10.6033,   1.0306, -48.1890,  10.8244,   0.9121, -46.0081,\n",
      "         10.9337,   0.8039, -43.7921,  11.0325,   0.6935, -41.5784,  11.1798,\n",
      "          0.6218, -39.3098,  11.2653,   0.5248, -37.1114,  11.3270,   0.4178,\n",
      "        -34.8660,  11.2943,   0.3530, -32.6077,  11.4279,   0.3014, -30.3182,\n",
      "         11.4007,   0.2209], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-48.1, -49.99393789811246, 9.0, 10.265184596920689]\n",
      "action_list [-5.0, 0.22367772638495537]\n",
      "new_action_list [-5.0, 0.21766358964970883]\n",
      "time_step:  1\n",
      "reference_tensor:  tensor([-47.9365,  10.3087,   0.2177, -45.8706,  10.3511,   0.2118, -43.7962,\n",
      "         10.3923,   0.2062, -41.7138,  10.4324,   0.2007, -39.6234,  10.4715,\n",
      "          0.1954, -37.5252,  10.5096,   0.1902, -35.4196,  10.5466,   0.1853,\n",
      "        -33.3067,  10.5827,   0.1806, -31.1866,  10.6179,   0.1760, -29.0596,\n",
      "         10.6523,   0.1717])\n",
      "decoder_prediction:  tensor([-47.9862,  10.1419,   0.7079, -46.0134,  10.2924,   0.6167, -43.9512,\n",
      "         10.3659,   0.5403, -41.8325,  10.4341,   0.4587, -39.7523,  10.5400,\n",
      "          0.4128, -37.6258,  10.6051,   0.3410, -35.5344,  10.6390,   0.2632,\n",
      "        -33.4318,  10.6191,   0.2199, -31.3018,  10.7094,   0.1869, -29.1714,\n",
      "         10.6809,   0.1250], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-46.4, -47.936547706935336, 8.0, 10.30871731485063]\n",
      "action_list [-5.0, 0.21766358964970883]\n",
      "new_action_list [-5.0, 0.2118224194128511]\n",
      "time_step:  2\n",
      "reference_tensor:  tensor([-45.8706,  10.3511,   0.2118, -43.7962,  10.3923,   0.2062, -41.7138,\n",
      "         10.4324,   0.2007, -39.6234,  10.4715,   0.1954, -37.5252,  10.5096,\n",
      "          0.1902, -35.4196,  10.5466,   0.1853, -33.3067,  10.5827,   0.1806,\n",
      "        -31.1866,  10.6179,   0.1760, -29.0596,  10.6523,   0.1717, -26.9258,\n",
      "         10.6858,   0.1675])\n",
      "decoder_prediction:  tensor([-45.9384,  10.2606,   0.5604, -43.9329,  10.3798,   0.4802, -41.8578,\n",
      "         10.4348,   0.4174, -39.7208,  10.4875,   0.3491, -37.6343,  10.5737,\n",
      "          0.3152, -35.5076,  10.6276,   0.2554, -33.4027,  10.6482,   0.1910,\n",
      "        -31.2998,  10.6311,   0.1581, -29.1663,  10.7029,   0.1344, -27.0419,\n",
      "         10.6728,   0.0815], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-44.9, -45.87056779557695, 7.0, 10.351081798733201]\n",
      "action_list [-5.0, 0.2118224194128511]\n",
      "new_action_list [-5.0, 0.206155768776749]\n",
      "time_step:  3\n",
      "reference_tensor:  tensor([-43.7962,  10.3923,   0.2062, -41.7138,  10.4324,   0.2007, -39.6234,\n",
      "         10.4715,   0.1954, -37.5252,  10.5096,   0.1902, -35.4196,  10.5466,\n",
      "          0.1853, -33.3067,  10.5827,   0.1806, -31.1866,  10.6179,   0.1760,\n",
      "        -29.0596,  10.6523,   0.1717, -26.9258,  10.6858,   0.1675, -24.7854,\n",
      "         10.7185,   0.1634])\n",
      "decoder_prediction:  tensor([-43.8778,  10.3657,   0.4576, -41.8439,  10.4652,   0.3864, -39.7545,\n",
      "         10.5062,   0.3343, -37.6018,  10.5480,   0.2765, -35.5049,  10.6220,\n",
      "          0.2526, -33.3729,  10.6684,   0.2020, -31.2547,  10.6807,   0.1467,\n",
      "        -29.1460,  10.6643,   0.1219, -27.0062,  10.7264,   0.1055, -24.8788,\n",
      "         10.6954,   0.0587], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-43.6, -43.79622832045477, 6.0, 10.39231295248855]\n",
      "action_list [-5.0, 0.206155768776749]\n",
      "new_action_list [-5.0, 0.20066617112519392]\n",
      "time_step:  4\n",
      "reference_tensor:  tensor([-41.7138,  10.4324,   0.2007, -39.6234,  10.4715,   0.1954, -37.5252,\n",
      "         10.5096,   0.1902, -35.4196,  10.5466,   0.1853, -33.3067,  10.5827,\n",
      "          0.1806, -31.1866,  10.6179,   0.1760, -29.0596,  10.6523,   0.1717,\n",
      "        -26.9258,  10.6858,   0.1675, -24.7854,  10.7185,   0.1634, -22.6385,\n",
      "         10.7504,   0.1595])\n",
      "decoder_prediction:  tensor([-41.7668,  10.4596,   0.3717, -39.7072,  10.5439,   0.3087, -37.6039,\n",
      "         10.5723,   0.2665, -35.4381,  10.6051,   0.2184, -33.3299,  10.6699,\n",
      "          0.2038, -31.1923,  10.7104,   0.1614, -29.0620,  10.7162,   0.1136,\n",
      "        -26.9464,  10.7000,   0.0962, -24.8007,  10.7559,   0.0863, -22.6677,\n",
      "         10.7243,   0.0446], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-42.5, -41.71375240653456, 5.0, 10.43244618671359]\n",
      "action_list [-5.0, 0.20066617112519392]\n",
      "new_action_list [-5.0, 0.19535711992964683]\n",
      "time_step:  5\n",
      "reference_tensor:  tensor([-39.6234,  10.4715,   0.1954, -37.5252,  10.5096,   0.1902, -35.4196,\n",
      "         10.5466,   0.1853, -33.3067,  10.5827,   0.1806, -31.1866,  10.6179,\n",
      "          0.1760, -29.0596,  10.6523,   0.1717, -26.9258,  10.6858,   0.1675,\n",
      "        -24.7854,  10.7185,   0.1634, -22.6385,  10.7504,   0.1595, -20.4853,\n",
      "         10.7815,   0.1558])\n",
      "decoder_prediction:  tensor([-3.9650e+01,  1.0548e+01,  2.9627e-01, -3.7566e+01,  1.0620e+01,\n",
      "         2.4097e-01, -3.5449e+01,  1.0637e+01,  2.0805e-01, -3.3271e+01,\n",
      "         1.0662e+01,  1.6914e-01, -3.1151e+01,  1.0719e+01,  1.6338e-01,\n",
      "        -2.9007e+01,  1.0755e+01,  1.2838e-01, -2.6865e+01,  1.0755e+01,\n",
      "         8.7264e-02, -2.4742e+01,  1.0739e+01,  7.6553e-02, -2.2590e+01,\n",
      "         1.0790e+01,  7.2892e-02, -2.0450e+01,  1.0759e+01,  3.5486e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-41.6, -39.62335602679325, 4.0, 10.471517610699518]\n",
      "action_list [-5.0, 0.19535711992964683]\n",
      "new_action_list [-5.0, 0.19023294423959827]\n",
      "time_step:  6\n",
      "reference_tensor:  tensor([-37.5252,  10.5096,   0.1902, -35.4196,  10.5466,   0.1853, -33.3067,\n",
      "         10.5827,   0.1806, -31.1866,  10.6179,   0.1760, -29.0596,  10.6523,\n",
      "          0.1717, -26.9258,  10.6858,   0.1675, -24.7854,  10.7185,   0.1634,\n",
      "        -22.6385,  10.7504,   0.1595, -20.4853,  10.7815,   0.1558, -18.3260,\n",
      "         10.8120,   0.1522])\n",
      "decoder_prediction:  tensor([-3.7546e+01,  1.0632e+01,  2.2886e-01, -3.5438e+01,  1.0693e+01,\n",
      "         1.8077e-01, -3.3308e+01,  1.0699e+01,  1.5671e-01, -3.1119e+01,\n",
      "         1.0717e+01,  1.2647e-01, -2.8986e+01,  1.0768e+01,  1.2928e-01,\n",
      "        -2.6836e+01,  1.0800e+01,  1.0112e-01, -2.4683e+01,  1.0795e+01,\n",
      "         6.5877e-02, -2.2551e+01,  1.0778e+01,  6.1489e-02, -2.0394e+01,\n",
      "         1.0827e+01,  6.3649e-02, -1.8245e+01,  1.0796e+01,  3.0066e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.9, -37.525247845768554, 3.0, 10.509564199547437]\n",
      "action_list [-5.0, 0.19023294423959827]\n",
      "new_action_list [-5.0, 0.18529852999080088]\n",
      "time_step:  7\n",
      "reference_tensor:  tensor([-35.4196,  10.5466,   0.1853, -33.3067,  10.5827,   0.1806, -31.1866,\n",
      "         10.6179,   0.1760, -29.0596,  10.6523,   0.1717, -26.9258,  10.6858,\n",
      "          0.1675, -24.7854,  10.7185,   0.1634, -22.6385,  10.7504,   0.1595,\n",
      "        -20.4853,  10.7815,   0.1558, -18.3260,  10.8120,   0.1522, -16.1606,\n",
      "         10.8417,   0.1487])\n",
      "decoder_prediction:  tensor([-3.5455e+01,  1.0710e+01,  1.6842e-01, -3.3325e+01,  1.0764e+01,\n",
      "         1.2715e-01, -3.1181e+01,  1.0759e+01,  1.1154e-01, -2.8982e+01,\n",
      "         1.0771e+01,  8.9545e-02, -2.6837e+01,  1.0817e+01,  1.0062e-01,\n",
      "        -2.4681e+01,  1.0845e+01,  7.8799e-02, -2.2517e+01,  1.0836e+01,\n",
      "         4.8790e-02, -2.0376e+01,  1.0819e+01,  5.0345e-02, -1.8213e+01,\n",
      "         1.0867e+01,  5.8012e-02, -1.6055e+01,  1.0835e+01,  2.7803e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.4, -35.41962903525925, 2.0, 10.546623905545598]\n",
      "action_list [-5.0, 0.18529852999080088]\n",
      "new_action_list [-5.0, 0.18055883514011684]\n",
      "time_step:  8\n",
      "reference_tensor:  tensor([-33.3067,  10.5827,   0.1806, -31.1866,  10.6179,   0.1760, -29.0596,\n",
      "         10.6523,   0.1717, -26.9258,  10.6858,   0.1675, -24.7854,  10.7185,\n",
      "          0.1634, -22.6385,  10.7504,   0.1595, -20.4853,  10.7815,   0.1558,\n",
      "        -18.3260,  10.8120,   0.1522, -16.1606,  10.8417,   0.1487, -13.9893,\n",
      "         10.8708,   0.1454])\n",
      "decoder_prediction:  tensor([-3.3375e+01,  1.0785e+01,  1.1440e-01, -3.1224e+01,  1.0832e+01,\n",
      "         7.9595e-02, -2.9067e+01,  1.0817e+01,  7.2034e-02, -2.6859e+01,\n",
      "         1.0825e+01,  5.7895e-02, -2.4700e+01,  1.0867e+01,  7.6931e-02,\n",
      "        -2.2537e+01,  1.0891e+01,  6.1003e-02, -2.0363e+01,  1.0879e+01,\n",
      "         3.5638e-02, -1.8213e+01,  1.0861e+01,  4.2785e-02, -1.6044e+01,\n",
      "         1.0908e+01,  5.5669e-02, -1.3875e+01,  1.0877e+01,  2.8421e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.1, -33.30669307744733, 1.0, 10.582735672573621]\n",
      "action_list [-5.0, 0.18055883514011684]\n",
      "new_action_list [-5.0, 0.17601815912418164]\n",
      "time_step:  9\n",
      "reference_tensor:  tensor([-31.1866,  10.6179,   0.1760, -29.0596,  10.6523,   0.1717, -26.9258,\n",
      "         10.6858,   0.1675, -24.7854,  10.7185,   0.1634, -22.6385,  10.7504,\n",
      "          0.1595, -20.4853,  10.7815,   0.1558, -18.3260,  10.8120,   0.1522,\n",
      "        -16.1606,  10.8417,   0.1487, -13.9893,  10.8708,   0.1454, -11.8123,\n",
      "         10.8993,   0.1423])\n",
      "decoder_prediction:  tensor([-3.1302e+01,  1.0859e+01,  6.6337e-02, -2.9129e+01,  1.0900e+01,\n",
      "         3.7661e-02, -2.6959e+01,  1.0876e+01,  3.7780e-02, -2.4742e+01,\n",
      "         1.0879e+01,  3.1126e-02, -2.2569e+01,  1.0918e+01,  5.7844e-02,\n",
      "        -2.0400e+01,  1.0939e+01,  4.7398e-02, -1.8215e+01,  1.0925e+01,\n",
      "         2.6128e-02, -1.6056e+01,  1.0906e+01,  3.8544e-02, -1.3880e+01,\n",
      "         1.0954e+01,  5.6374e-02, -1.1700e+01,  1.0923e+01,  3.1710e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -31.18662557975012, 0.0, 10.617939304398458]\n",
      "action_list [-5.0, 0.17601815912418164]\n",
      "new_action_list [0.0, 0.17167916316012255]\n",
      "time_step:  10\n",
      "reference_tensor:  tensor([-29.0596,  10.6523,   0.1717, -26.9258,  10.6858,   0.1675, -24.7854,\n",
      "         10.7185,   0.1634, -22.6385,  10.7504,   0.1595, -20.4853,  10.7815,\n",
      "          0.1558, -18.3260,  10.8120,   0.1522, -16.1606,  10.8417,   0.1487,\n",
      "        -13.9893,  10.8708,   0.1454, -11.8123,  10.8993,   0.1423,  -9.6297,\n",
      "         10.9271,   0.1393])\n",
      "decoder_prediction:  tensor([-2.9256e+01,  1.0700e+01,  3.1658e-01, -2.7095e+01,  1.0701e+01,\n",
      "         2.5308e-01, -2.4950e+01,  1.0781e+01,  1.8399e-01, -2.2802e+01,\n",
      "         1.0824e+01,  1.3320e-01, -2.0646e+01,  1.0806e+01,  6.8054e-02,\n",
      "        -1.8487e+01,  1.0817e+01,  4.9106e-02, -1.6291e+01,  1.0842e+01,\n",
      "         5.9458e-02, -1.4102e+01,  1.0919e+01,  3.8173e-02, -1.1909e+01,\n",
      "         1.0856e+01,  8.9895e-03, -9.7380e+00,  1.0915e+01,  1.9208e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -29.059604135607227, 0.0, 10.652275137030482]\n",
      "action_list [0.0, 0.17167916316012255]\n",
      "new_action_list [0.0, 0.16747279401378276]\n",
      "time_step:  11\n",
      "reference_tensor:  tensor([-26.9258,  10.6858,   0.1675, -24.7854,  10.7185,   0.1634, -22.6385,\n",
      "         10.7504,   0.1595, -20.4853,  10.7815,   0.1558, -18.3260,  10.8120,\n",
      "          0.1522, -16.1606,  10.8417,   0.1487, -13.9893,  10.8708,   0.1454,\n",
      "        -11.8123,  10.8993,   0.1423,  -9.6297,  10.9271,   0.1393,  -7.4416,\n",
      "         10.9544,   0.1364])\n",
      "decoder_prediction:  tensor([-2.6980e+01,  1.0701e+01,  2.8656e-01, -2.4812e+01,  1.0703e+01,\n",
      "         2.2939e-01, -2.2666e+01,  1.0775e+01,  1.6813e-01, -2.0523e+01,\n",
      "         1.0816e+01,  1.2474e-01, -1.8363e+01,  1.0799e+01,  6.7567e-02,\n",
      "        -1.6209e+01,  1.0809e+01,  5.3275e-02, -1.4016e+01,  1.0835e+01,\n",
      "         6.5978e-02, -1.1826e+01,  1.0910e+01,  4.9398e-02, -9.6390e+00,\n",
      "         1.0853e+01,  2.4810e-02, -7.4646e+00,  1.0914e+01,  3.6259e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -26.925799652320855, 0.0, 10.685769695833239]\n",
      "action_list [0.0, 0.16747279401378276]\n",
      "new_action_list [0.0, 0.16342184005775012]\n",
      "time_step:  12\n",
      "reference_tensor:  tensor([-24.7854,  10.7185,   0.1634, -22.6385,  10.7504,   0.1595, -20.4853,\n",
      "         10.7815,   0.1558, -18.3260,  10.8120,   0.1522, -16.1606,  10.8417,\n",
      "          0.1487, -13.9893,  10.8708,   0.1454, -11.8123,  10.8993,   0.1423,\n",
      "         -9.6297,  10.9271,   0.1393,  -7.4416,  10.9544,   0.1364,  -5.2480,\n",
      "         10.9811,   0.1336])\n",
      "decoder_prediction:  tensor([-24.9004,  10.7822,   0.2685, -22.7102,  10.7867,   0.2156, -20.5466,\n",
      "         10.8512,   0.1601, -18.3941,  10.8912,   0.1224, -16.2133,  10.8756,\n",
      "          0.0715, -14.0467,  10.8861,   0.0606, -11.8397,  10.9117,   0.0746,\n",
      "         -9.6330,  10.9849,   0.0617,  -7.4351,  10.9347,   0.0408,  -5.2396,\n",
      "         10.9963,   0.0529], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -24.785377276353053, 0.0, 10.718454063844788]\n",
      "action_list [0.0, 0.16342184005775012]\n",
      "new_action_list [0.0, 0.15952559804192137]\n",
      "time_step:  13\n",
      "reference_tensor:  tensor([-22.6385,  10.7504,   0.1595, -20.4853,  10.7815,   0.1558, -18.3260,\n",
      "         10.8120,   0.1522, -16.1606,  10.8417,   0.1487, -13.9893,  10.8708,\n",
      "          0.1454, -11.8123,  10.8993,   0.1423,  -9.6297,  10.9271,   0.1393,\n",
      "         -7.4416,  10.9544,   0.1364,  -5.2480,  10.9811,   0.1336,  -3.0492,\n",
      "         11.0073,   0.1309])\n",
      "decoder_prediction:  tensor([-22.7849,  10.8327,   0.2443, -20.5788,  10.8383,   0.1966, -18.4042,\n",
      "         10.8957,   0.1476, -16.2474,  10.9340,   0.1161, -14.0534,  10.9195,\n",
      "          0.0720, -11.8804,  10.9294,   0.0651,  -9.6661,  10.9551,   0.0810,\n",
      "         -7.4494,  11.0263,   0.0721,  -5.2470,  10.9820,   0.0551,  -3.0378,\n",
      "         11.0446,   0.0683], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -22.638495951623256, 0.0, 10.750359183453172]\n",
      "action_list [0.0, 0.15952559804192137]\n",
      "new_action_list [0.0, 0.15578282001716426]\n",
      "time_step:  14\n",
      "reference_tensor:  tensor([-20.4853,  10.7815,   0.1558, -18.3260,  10.8120,   0.1522, -16.1606,\n",
      "         10.8417,   0.1487, -13.9893,  10.8708,   0.1454, -11.8123,  10.8993,\n",
      "          0.1423,  -9.6297,  10.9271,   0.1393,  -7.4416,  10.9544,   0.1364,\n",
      "         -5.2480,  10.9811,   0.1336,  -3.0492,  11.0073,   0.1309,  -0.8452,\n",
      "         11.0329,   0.1283])\n",
      "decoder_prediction:  tensor([-20.6428,  10.8911,   0.2213, -18.4195,  10.8981,   0.1789, -16.2321,\n",
      "         10.9487,   0.1361, -14.0695,  10.9852,   0.1108, -11.8606,  10.9720,\n",
      "          0.0733,  -9.6791,  10.9814,   0.0704,  -7.4560,  11.0075,   0.0881,\n",
      "         -5.2275,  11.0763,   0.0832,  -3.0189,  11.0383,   0.0701,  -0.7941,\n",
      "         11.1017,   0.0843], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -20.48530845853228, 0.0, 10.781515747456606]\n",
      "action_list [0.0, 0.15578282001716426]\n",
      "new_action_list [0.0, 0.15219148294530246]\n",
      "time_step:  15\n",
      "reference_tensor:  tensor([-18.3260,  10.8120,   0.1522, -16.1606,  10.8417,   0.1487, -13.9893,\n",
      "         10.8708,   0.1454, -11.8123,  10.8993,   0.1423,  -9.6297,  10.9271,\n",
      "          0.1393,  -7.4416,  10.9544,   0.1364,  -5.2480,  10.9811,   0.1336,\n",
      "         -3.0492,  11.0073,   0.1309,  -0.8452,  11.0329,   0.1283,   1.3639,\n",
      "         11.0581,   0.1257])\n",
      "decoder_prediction:  tensor([-18.4702,  10.9505,   0.1984, -16.2296,  10.9589,   0.1614, -14.0294,\n",
      "         11.0029,   0.1248, -11.8608,  11.0374,   0.1057,  -9.6370,  11.0257,\n",
      "          0.0748,  -7.4463,  11.0347,   0.0762,  -5.2143,  11.0612,   0.0954,\n",
      "         -2.9739,  11.1274,   0.0945,  -0.7587,  11.0960,   0.0854,   1.4818,\n",
      "         11.1602,   0.1006], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -18.325961479382052, 0.0, 10.811954044045667]\n",
      "action_list [0.0, 0.15219148294530246]\n",
      "new_action_list [0.0, 0.14874854818481165]\n",
      "time_step:  16\n",
      "reference_tensor:  tensor([-16.1606,  10.8417,   0.1487, -13.9893,  10.8708,   0.1454, -11.8123,\n",
      "         10.8993,   0.1423,  -9.6297,  10.9271,   0.1393,  -7.4416,  10.9544,\n",
      "          0.1364,  -5.2480,  10.9811,   0.1336,  -3.0492,  11.0073,   0.1309,\n",
      "         -0.8452,  11.0329,   0.1283,   1.3639,  11.0581,   0.1257,   3.5780,\n",
      "         11.0827,   0.1232])\n",
      "decoder_prediction:  tensor([-16.2355,  10.9886,   0.1721, -13.9820,  10.9976,   0.1413, -11.7732,\n",
      "         11.0351,   0.1114,  -9.6030,  11.0671,   0.0989,  -7.3694,  11.0569,\n",
      "          0.0749,  -5.1734,  11.0653,   0.0810,  -2.9370,  11.0925,   0.1022,\n",
      "         -0.6895,  11.1559,   0.1055,   1.5281,  11.1312,   0.1006,   3.7796,\n",
      "         11.1959,   0.1170], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -16.160595699609225, 0.0, 10.84170375368263]\n",
      "action_list [0.0, 0.14874854818481165]\n",
      "new_action_list [0.0, 0.1454497300427232]\n",
      "time_step:  17\n",
      "reference_tensor:  tensor([-13.9893,  10.8708,   0.1454, -11.8123,  10.8993,   0.1423,  -9.6297,\n",
      "         10.9271,   0.1393,  -7.4416,  10.9544,   0.1364,  -5.2480,  10.9811,\n",
      "          0.1336,  -3.0492,  11.0073,   0.1309,  -0.8452,  11.0329,   0.1283,\n",
      "          1.3639,  11.0581,   0.1257,   3.5780,  11.0827,   0.1232,   5.7970,\n",
      "         11.1069,   0.1208])\n",
      "decoder_prediction:  tensor([-13.9188,  10.9904,   0.1405, -11.6592,  10.9989,   0.1169,  -9.4497,\n",
      "         11.0298,   0.0945,  -7.2853,  11.0587,   0.0894,  -5.0498,  11.0498,\n",
      "          0.0729,  -2.8557,  11.0577,   0.0845,  -0.6223,  11.0854,   0.1079,\n",
      "          1.6243,  11.1460,   0.1159,   3.8369,  11.1281,   0.1156,   6.0914,\n",
      "         11.1932,   0.1334], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -13.989345954271847, 0.0, 10.870793699691175]\n",
      "action_list [0.0, 0.1454497300427232]\n",
      "new_action_list [0.0, 0.14228929845683852]\n",
      "time_step:  18\n",
      "reference_tensor:  tensor([-11.8123,  10.8993,   0.1423,  -9.6297,  10.9271,   0.1393,  -7.4416,\n",
      "         10.9544,   0.1364,  -5.2480,  10.9811,   0.1336,  -3.0492,  11.0073,\n",
      "          0.1309,  -0.8452,  11.0329,   0.1283,   1.3639,  11.0581,   0.1257,\n",
      "          3.5780,  11.0827,   0.1232,   5.7970,  11.1069,   0.1208,   8.0207,\n",
      "         11.1305,   0.1184])\n",
      "decoder_prediction:  tensor([-11.8083,  10.9568,   0.2013,  -9.5523,  10.9877,   0.1796,  -7.3395,\n",
      "         11.0215,   0.1576,  -5.1891,  11.0579,   0.1544,  -2.9433,  11.0640,\n",
      "          0.1411,  -0.7440,  11.0784,   0.1512,   1.4850,  11.1172,   0.1686,\n",
      "          3.7409,  11.1713,   0.1766,   5.9525,  11.1769,   0.1754,   8.2266,\n",
      "         11.2451,   0.1894], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -11.812341428364476, 0.0, 10.899251559382543]\n",
      "action_list [0.0, 0.14228929845683852]\n",
      "new_action_list [0.0, 0.1392599448554692]\n",
      "time_step:  19\n",
      "reference_tensor:  tensor([-9.6297, 10.9271,  0.1393, -7.4416, 10.9544,  0.1364, -5.2480, 10.9811,\n",
      "         0.1336, -3.0492, 11.0073,  0.1309, -0.8452, 11.0329,  0.1283,  1.3639,\n",
      "        11.0581,  0.1257,  3.5780, 11.0827,  0.1232,  5.7970, 11.1069,  0.1208,\n",
      "         8.0207, 11.1305,  0.1184, 10.2491, 11.1538,  0.1161])\n",
      "decoder_prediction:  tensor([-9.6807, 10.9157,  0.2732, -7.4303, 10.9717,  0.2531, -5.2145, 11.0098,\n",
      "         0.2307, -3.0800, 11.0548,  0.2286, -0.8236, 11.0777,  0.2181,  1.3818,\n",
      "        11.0996,  0.2260,  3.6054, 11.1510,  0.2364,  5.8711, 11.1979,  0.2439,\n",
      "         8.0818, 11.2294,  0.2411, 10.3769, 11.3009,  0.2507],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -9.629705917590861, 0.0, 10.927103548353637]\n",
      "action_list [0.0, 0.1392599448554692]\n",
      "new_action_list [0.0, 0.13635274067294903]\n",
      "time_step:  20\n",
      "reference_tensor:  tensor([-7.4416, 10.9544,  0.1364, -5.2480, 10.9811,  0.1336, -3.0492, 11.0073,\n",
      "         0.1309, -0.8452, 11.0329,  0.1283,  1.3639, 11.0581,  0.1257,  3.5780,\n",
      "        11.0827,  0.1232,  5.7970, 11.1069,  0.1208,  8.0207, 11.1305,  0.1184,\n",
      "        10.2491, 11.1538,  0.1161, 12.4822, 11.1765,  0.1137])\n",
      "decoder_prediction:  tensor([-7.5030, 10.8755,  0.3471, -5.2583, 10.9569,  0.3287, -3.0392, 11.0000,\n",
      "         0.3057, -0.9205, 11.0536,  0.3048,  1.3465, 11.0938,  0.2969,  3.5594,\n",
      "        11.1233,  0.3027,  5.7777, 11.1879,  0.3058,  8.0537, 11.2270,  0.3128,\n",
      "        10.2641, 11.2852,  0.3083, 12.5809, 11.3598,  0.3134],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -7.441558153106676, 0.0, 10.954374096488227]\n",
      "action_list [0.0, 0.13635274067294903]\n",
      "new_action_list [0.0, 0.13355721341700377]\n",
      "time_step:  21\n",
      "reference_tensor:  tensor([-5.2480, 10.9811,  0.1336, -3.0492, 11.0073,  0.1309, -0.8452, 11.0329,\n",
      "         0.1283,  1.3639, 11.0581,  0.1257,  3.5780, 11.0827,  0.1232,  5.7970,\n",
      "        11.1069,  0.1208,  8.0207, 11.1305,  0.1184, 10.2491, 11.1538,  0.1161,\n",
      "        12.4822, 11.1765,  0.1137, 14.7197, 11.1988,  0.1114])\n",
      "decoder_prediction:  tensor([-5.3597, 10.9118,  0.3022, -3.1751, 10.9714,  0.3028, -0.9722, 11.0311,\n",
      "         0.2921,  1.1981, 11.0646,  0.2826,  3.4138, 11.1218,  0.2769,  5.6780,\n",
      "        11.1638,  0.2929,  7.8908, 11.2282,  0.3057, 10.1468, 11.2404,  0.2981,\n",
      "        12.4062, 11.3221,  0.2952, 14.6813, 11.3636,  0.2985],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -5.248012189540688, 0.0, 10.981085539171627]\n",
      "action_list [0.0, 0.13355721341700377]\n",
      "new_action_list [0.0, 0.1308615548924241]\n",
      "time_step:  22\n",
      "reference_tensor:  tensor([-3.0492, 11.0073,  0.1309, -0.8452, 11.0329,  0.1283,  1.3639, 11.0581,\n",
      "         0.1257,  3.5780, 11.0827,  0.1232,  5.7970, 11.1069,  0.1208,  8.0207,\n",
      "        11.1305,  0.1184, 10.2491, 11.1538,  0.1161, 12.4822, 11.1765,  0.1137,\n",
      "        14.7197, 11.1988,  0.1114, 16.9616, 11.2206,  0.1090])\n",
      "decoder_prediction:  tensor([-2.9130, 10.9665,  0.2927, -0.7965, 11.0007,  0.3117,  1.4000, 11.0991,\n",
      "         0.3009,  3.6388, 11.1143,  0.2855,  5.8075, 11.1927,  0.2670,  8.1372,\n",
      "        11.2509,  0.2876, 10.3561, 11.3195,  0.2892, 12.5963, 11.3185,  0.2687,\n",
      "        14.9105, 11.4096,  0.2632, 17.1603, 11.4187,  0.2590],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -3.0491778506085154, 0.0, 11.007257850150111]\n",
      "action_list [0.0, 0.1308615548924241]\n",
      "new_action_list [0.0, 0.1282529607909119]\n",
      "time_step:  23\n",
      "reference_tensor:  tensor([-0.8452, 11.0329,  0.1283,  1.3639, 11.0581,  0.1257,  3.5780, 11.0827,\n",
      "         0.1232,  5.7970, 11.1069,  0.1208,  8.0207, 11.1305,  0.1184, 10.2491,\n",
      "        11.1538,  0.1161, 12.4822, 11.1765,  0.1137, 14.7197, 11.1988,  0.1114,\n",
      "        16.9616, 11.2206,  0.1090, 19.2079, 11.2419,  0.1067])\n",
      "decoder_prediction:  tensor([-0.8126, 10.9710,  0.2947,  1.2874, 11.0044,  0.3059,  3.4854, 11.0998,\n",
      "         0.2986,  5.7547, 11.1354,  0.2850,  7.9303, 11.2065,  0.2712, 10.2363,\n",
      "        11.2712,  0.2741, 12.4730, 11.3350,  0.2707, 14.7152, 11.3612,  0.2496,\n",
      "        17.0401, 11.4315,  0.2349, 19.2864, 11.4513,  0.2255],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, -0.8451612213626731, 0.0, 11.032908442308294]\n",
      "action_list [0.0, 0.1282529607909119]\n",
      "new_action_list [0.0, 0.1257180825275445]\n",
      "time_step:  24\n",
      "reference_tensor:  tensor([ 1.3639, 11.0581,  0.1257,  3.5780, 11.0827,  0.1232,  5.7970, 11.1069,\n",
      "         0.1208,  8.0207, 11.1305,  0.1184, 10.2491, 11.1538,  0.1161, 12.4822,\n",
      "        11.1765,  0.1137, 14.7197, 11.1988,  0.1114, 16.9616, 11.2206,  0.1090,\n",
      "        19.2079, 11.2419,  0.1067, 21.4584, 11.2628,  0.1044])\n",
      "decoder_prediction:  tensor([ 1.3673, 10.9881,  0.2981,  3.4525, 11.0205,  0.3010,  5.6548, 11.1135,\n",
      "         0.2967,  7.9582, 11.1703,  0.2849, 10.1434, 11.2336,  0.2757, 12.4277,\n",
      "        11.3050,  0.2600, 14.6854, 11.3641,  0.2512, 16.9323, 11.4185,  0.2296,\n",
      "        19.2709, 11.4671,  0.2049, 21.5163, 11.4979,  0.1902],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.0, 1.3639348287495352, 0.0, 11.058052058813804]\n",
      "action_list [0.0, 0.1257180825275445]\n",
      "new_action_list [0.0, 0.12324355442042337]\n",
      "time_step:  25\n",
      "reference_tensor:  tensor([ 3.5780, 11.0827,  0.1232,  5.7970, 11.1069,  0.1208,  8.0207, 11.1305,\n",
      "         0.1184, 10.2491, 11.1538,  0.1161, 12.4822, 11.1765,  0.1137, 14.7197,\n",
      "        11.1988,  0.1114, 16.9616, 11.2206,  0.1090, 19.2079, 11.2419,  0.1067,\n",
      "        21.4584, 11.2628,  0.1044, 23.7130, 11.2832,  0.1021])\n",
      "decoder_prediction:  tensor([ 3.5782, 11.0109,  0.3021,  5.6492, 11.0421,  0.2964,  7.8571, 11.1330,\n",
      "         0.2950, 10.1959, 11.2113,  0.2848, 12.3920, 11.2665,  0.2803, 14.6556,\n",
      "        11.3447,  0.2454, 16.9356, 11.3991,  0.2313, 19.1884, 11.4821,  0.2091,\n",
      "        21.5422, 11.5085,  0.1740, 23.7876, 11.5508,  0.1540],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-50.0, -49.957413384990765, 10.0, 8.334497767953609]\n",
      "action_list [0, 0]\n",
      "new_action_list [-5.0, 3.0]\n",
      "time_step:  0\n",
      "reference_tensor:  tensor([-4.8231e+01,  8.9345e+00,  3.0000e+00, -4.6384e+01,  9.5345e+00,\n",
      "         3.0000e+00, -4.4417e+01,  1.0134e+01,  3.0000e+00, -4.2330e+01,\n",
      "         1.0734e+01,  3.0000e+00, -4.0123e+01,  1.1334e+01,  3.0000e+00,\n",
      "        -3.7801e+01,  1.1882e+01,  2.7356e+00, -3.5417e+01,  1.1965e+01,\n",
      "         4.1723e-01, -3.3022e+01,  1.1977e+01,  6.1115e-02, -3.0627e+01,\n",
      "         1.1979e+01,  6.3960e-03, -2.8231e+01,  1.1978e+01, -1.8892e-03])\n",
      "decoder_prediction:  tensor([-48.6619,   9.3926,   0.8748, -46.8472,   9.5833,   0.7860, -44.9206,\n",
      "          9.6846,   0.7017, -42.9486,   9.7685,   0.6126, -40.9986,   9.9103,\n",
      "          0.5585, -38.9776,   9.9952,   0.4803, -37.0235,  10.0544,   0.3856,\n",
      "        -35.0398,  10.0245,   0.3324, -33.0277,  10.1568,   0.2919, -31.0018,\n",
      "         10.1288,   0.2190], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-48.1, -48.230513831400046, 9.0, 8.934497767953609]\n",
      "action_list [-5.0, 3.0]\n",
      "new_action_list [-5.0, 3.0]\n",
      "time_step:  1\n",
      "reference_tensor:  tensor([-4.6384e+01,  9.5345e+00,  3.0000e+00, -4.4417e+01,  1.0134e+01,\n",
      "         3.0000e+00, -4.2330e+01,  1.0734e+01,  3.0000e+00, -4.0123e+01,\n",
      "         1.1334e+01,  3.0000e+00, -3.7801e+01,  1.1882e+01,  2.7356e+00,\n",
      "        -3.5417e+01,  1.1965e+01,  4.1723e-01, -3.3022e+01,  1.1977e+01,\n",
      "         6.1115e-02, -3.0627e+01,  1.1979e+01,  6.3960e-03, -2.8231e+01,\n",
      "         1.1978e+01, -1.8892e-03, -2.5836e+01,  1.1978e+01, -2.8059e-03])\n",
      "decoder_prediction:  tensor([-46.3644,  10.5076,   0.8820, -44.3153,  10.7113,   0.7765, -42.1603,\n",
      "         10.7878,   0.6921, -39.9749,  10.8800,   0.6019, -37.7804,  11.0113,\n",
      "          0.5528, -35.5685,  11.0885,   0.4671, -33.3948,  11.1369,   0.3741,\n",
      "        -31.1823,  11.1128,   0.3239, -28.9698,  11.2358,   0.2855, -26.7131,\n",
      "         11.2151,   0.2122], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-46.4, -46.38361427780932, 8.0, 9.534497767953608]\n",
      "action_list [-5.0, 3.0]\n",
      "new_action_list [1.2201043232655833, 3.0]\n",
      "time_step:  2\n",
      "reference_tensor:  tensor([-4.4417e+01,  1.0134e+01,  3.0000e+00, -4.2330e+01,  1.0734e+01,\n",
      "         3.0000e+00, -4.0123e+01,  1.1334e+01,  3.0000e+00, -3.7801e+01,\n",
      "         1.1882e+01,  2.7356e+00, -3.5417e+01,  1.1965e+01,  4.1723e-01,\n",
      "        -3.3022e+01,  1.1977e+01,  6.1115e-02, -3.0627e+01,  1.1979e+01,\n",
      "         6.3960e-03, -2.8231e+01,  1.1978e+01, -1.8892e-03, -2.5836e+01,\n",
      "         1.1978e+01, -2.8059e-03, -2.3440e+01,  1.1977e+01, -2.2546e-03])\n",
      "decoder_prediction:  tensor([-44.3465,  10.8374,   1.1837, -42.2085,  10.9854,   1.0259, -39.9812,\n",
      "         11.1858,   0.8510, -37.7759,  11.3260,   0.7018, -35.4973,  11.3769,\n",
      "          0.5355, -33.2051,  11.4357,   0.4360, -30.9154,  11.5256,   0.3842,\n",
      "        -28.5653,  11.6237,   0.2916, -26.2331,  11.5951,   0.1937, -23.8927,\n",
      "         11.6857,   0.1652], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-44.77559791353469, -44.4167147242186, 8.244020864653116, 10.134497767953608]\n",
      "action_list [1.2201043232655833, 3.0]\n",
      "new_action_list [0.8861407543141856, 3.0]\n",
      "time_step:  3\n",
      "reference_tensor:  tensor([-4.2330e+01,  1.0734e+01,  3.0000e+00, -4.0123e+01,  1.1334e+01,\n",
      "         3.0000e+00, -3.7801e+01,  1.1882e+01,  2.7356e+00, -3.5417e+01,\n",
      "         1.1965e+01,  4.1723e-01, -3.3022e+01,  1.1977e+01,  6.1115e-02,\n",
      "        -3.0627e+01,  1.1979e+01,  6.3960e-03, -2.8231e+01,  1.1978e+01,\n",
      "        -1.8892e-03, -2.5836e+01,  1.1978e+01, -2.8059e-03, -2.3440e+01,\n",
      "         1.1977e+01, -2.2546e-03, -2.1045e+01,  1.1977e+01, -1.0187e-03])\n",
      "decoder_prediction:  tensor([-42.4360,  11.1569,   1.1182, -40.2286,  11.3023,   0.9647, -37.9392,\n",
      "         11.4829,   0.8006, -35.6736,  11.6167,   0.6605, -33.3314,  11.6646,\n",
      "          0.5075, -30.9906,  11.7190,   0.4122, -28.6450,  11.8008,   0.3630,\n",
      "        -26.2403,  11.8929,   0.2779, -23.8601,  11.8678,   0.1878, -21.4622,\n",
      "         11.9536,   0.1599], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-43.109070925517784, -42.32981517062788, 8.421249015515953, 10.734497767953608]\n",
      "action_list [0.8861407543141856, 3.0]\n",
      "new_action_list [0.5291171811187666, 3.0]\n",
      "time_step:  4\n",
      "reference_tensor:  tensor([-4.0123e+01,  1.1334e+01,  3.0000e+00, -3.7801e+01,  1.1882e+01,\n",
      "         2.7356e+00, -3.5417e+01,  1.1965e+01,  4.1723e-01, -3.3022e+01,\n",
      "         1.1977e+01,  6.1115e-02, -3.0627e+01,  1.1979e+01,  6.3960e-03,\n",
      "        -2.8231e+01,  1.1978e+01, -1.8892e-03, -2.5836e+01,  1.1978e+01,\n",
      "        -2.8059e-03, -2.3440e+01,  1.1977e+01, -2.2546e-03, -2.1045e+01,\n",
      "         1.1977e+01, -1.0187e-03, -1.8649e+01,  1.1977e+01,  8.9208e-04])\n",
      "decoder_prediction:  tensor([-40.2706,  11.4928,   1.0346, -37.9907,  11.6316,   0.8874, -35.6372,\n",
      "         11.7908,   0.7358, -33.3086,  11.9157,   0.6063, -30.9026,  11.9588,\n",
      "          0.4680, -28.5108,  12.0078,   0.3788, -26.1078,  12.0802,   0.3334,\n",
      "        -23.6488,  12.1653,   0.2571, -21.2192,  12.1427,   0.1761, -18.7644,\n",
      "         12.2224,   0.1496], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-41.41423877879222, -40.12291561703716, 8.527072451739706, 11.334497767953607]\n",
      "action_list [0.5291171811187666, 3.0]\n",
      "new_action_list [0.18253775837647385, 2.735583954211232]\n",
      "time_step:  5\n",
      "reference_tensor:  tensor([-3.7801e+01,  1.1882e+01,  2.7356e+00, -3.5417e+01,  1.1965e+01,\n",
      "         4.1723e-01, -3.3022e+01,  1.1977e+01,  6.1115e-02, -3.0627e+01,\n",
      "         1.1979e+01,  6.3960e-03, -2.8231e+01,  1.1978e+01, -1.8892e-03,\n",
      "        -2.5836e+01,  1.1978e+01, -2.8059e-03, -2.3440e+01,  1.1977e+01,\n",
      "        -2.2546e-03, -2.1045e+01,  1.1977e+01, -1.0187e-03, -1.8649e+01,\n",
      "         1.1977e+01,  8.9208e-04, -1.6254e+01,  1.1978e+01,  3.4790e-03])\n",
      "decoder_prediction:  tensor([-38.0099,  11.8226,   0.9526, -35.6584,  11.9553,   0.8119, -33.2419,\n",
      "         12.0933,   0.6727, -30.8517,  12.2093,   0.5540, -28.3827,  12.2482,\n",
      "          0.4304, -25.9409,  12.2919,   0.3475, -23.4817,  12.3553,   0.3058,\n",
      "        -20.9690,  12.4334,   0.2383, -18.4909,  12.4138,   0.1663, -15.9796,\n",
      "         12.4878,   0.1413], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-39.70517353327675, -37.80130438436221, 8.563580003415, 11.881614558795853]\n",
      "action_list [0.18253775837647385, 2.735583954211232]\n",
      "new_action_list [-0.17176131177485465, 0.4172267810002157]\n",
      "time_step:  6\n",
      "reference_tensor:  tensor([-3.5417e+01,  1.1965e+01,  4.1723e-01, -3.3022e+01,  1.1977e+01,\n",
      "         6.1115e-02, -3.0627e+01,  1.1979e+01,  6.3960e-03, -2.8231e+01,\n",
      "         1.1978e+01, -1.8892e-03, -2.5836e+01,  1.1978e+01, -2.8059e-03,\n",
      "        -2.3440e+01,  1.1977e+01, -2.2546e-03, -2.1045e+01,  1.1977e+01,\n",
      "        -1.0187e-03, -1.8649e+01,  1.1977e+01,  8.9208e-04, -1.6254e+01,\n",
      "         1.1978e+01,  3.4790e-03, -1.3858e+01,  1.1979e+01,  6.6227e-03])\n",
      "decoder_prediction:  tensor([-35.6981,  12.1321,   0.8735, -33.2792,  12.2598,   0.7395, -30.8033,\n",
      "         12.3769,   0.6130, -28.3556,  12.4844,   0.5053, -25.8271,  12.5201,\n",
      "          0.3965, -23.3384,  12.5590,   0.3198, -20.8267,  12.6139,   0.2815,\n",
      "        -18.2637,  12.6847,   0.2227, -15.7408,  12.6696,   0.1598, -13.1758,\n",
      "         12.7376,   0.1359], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-37.99589275882924, -35.41663693698304, 8.529227741060028, 11.965059914995896]\n",
      "action_list [-0.17176131177485465, 0.4172267810002157]\n",
      "new_action_list [-0.49141672794664654, 0.06111458132107536]\n",
      "time_step:  7\n",
      "reference_tensor:  tensor([-3.3022e+01,  1.1977e+01,  6.1115e-02, -3.0627e+01,  1.1979e+01,\n",
      "         6.3960e-03, -2.8231e+01,  1.1978e+01, -1.8892e-03, -2.5836e+01,\n",
      "         1.1978e+01, -2.8059e-03, -2.3440e+01,  1.1977e+01, -2.2546e-03,\n",
      "        -2.1045e+01,  1.1977e+01, -1.0187e-03, -1.8649e+01,  1.1977e+01,\n",
      "         8.9208e-04, -1.6254e+01,  1.1978e+01,  3.4790e-03, -1.3858e+01,\n",
      "         1.1979e+01,  6.6227e-03, -1.1462e+01,  1.1981e+01,  1.0226e-02])\n",
      "decoder_prediction:  tensor([-33.0293,  11.8705,   0.7057, -30.6535,  11.9712,   0.5935, -28.2406,\n",
      "         12.0665,   0.4896, -25.8493,  12.1548,   0.4024, -23.3925,  12.1813,\n",
      "          0.3149, -20.9720,  12.2135,   0.2548, -18.5247,  12.2578,   0.2272,\n",
      "        -16.0396,  12.3224,   0.1824, -13.5874,  12.3062,   0.1334, -11.1006,\n",
      "         12.3665,   0.1160], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-36.29987554517617, -33.022402662357436, 8.430944395470698, 11.97728283126011]\n",
      "action_list [-0.49141672794664654, 0.06111458132107536]\n",
      "new_action_list [-1.1023023026247025, 0.006396036419020756]\n",
      "time_step:  8\n",
      "reference_tensor:  tensor([-3.0627e+01,  1.1979e+01,  6.3960e-03, -2.8231e+01,  1.1978e+01,\n",
      "        -1.8892e-03, -2.5836e+01,  1.1978e+01, -2.8059e-03, -2.3440e+01,\n",
      "         1.1977e+01, -2.2546e-03, -2.1045e+01,  1.1977e+01, -1.0187e-03,\n",
      "        -1.8649e+01,  1.1977e+01,  8.9208e-04, -1.6254e+01,  1.1978e+01,\n",
      "         3.4790e-03, -1.3858e+01,  1.1979e+01,  6.6227e-03, -1.1462e+01,\n",
      "         1.1981e+01,  1.0226e-02, -9.0655e+00,  1.1984e+01,  1.3880e-02])\n",
      "decoder_prediction:  tensor([-30.5686,  11.6596,   0.5483, -28.2268,  11.7424,   0.4572, -25.8649,\n",
      "         11.8108,   0.3782, -23.5177,  11.8809,   0.3121, -21.1183,  11.9045,\n",
      "          0.2500, -18.7558,  11.9321,   0.2046, -16.3634,  11.9651,   0.1838,\n",
      "        -13.9450,  12.0179,   0.1536, -11.5545,  12.0102,   0.1201,  -9.1308,\n",
      "         12.0585,   0.1054], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-34.635732712134526, -30.626818175377032, 8.210483934945758, 11.978562038543915]\n",
      "action_list [-1.1023023026247025, 0.006396036419020756]\n",
      "new_action_list [-1.9000745585003, -0.0018892270000632322]\n",
      "time_step:  9\n",
      "reference_tensor:  tensor([-2.8231e+01,  1.1978e+01, -1.8892e-03, -2.5836e+01,  1.1978e+01,\n",
      "        -2.8059e-03, -2.3440e+01,  1.1977e+01, -2.2546e-03, -2.1045e+01,\n",
      "         1.1977e+01, -1.0187e-03, -1.8649e+01,  1.1977e+01,  8.9208e-04,\n",
      "        -1.6254e+01,  1.1978e+01,  3.4790e-03, -1.3858e+01,  1.1979e+01,\n",
      "         6.6227e-03, -1.1462e+01,  1.1981e+01,  1.0226e-02, -9.0655e+00,\n",
      "         1.1984e+01,  1.3880e-02, -6.6684e+00,  1.1987e+01,  1.7177e-02])\n",
      "decoder_prediction:  tensor([-28.1713,  11.6273,   0.4247, -25.8296,  11.7049,   0.3508, -23.4789,\n",
      "         11.7439,   0.2953, -21.1393,  11.7998,   0.2484, -18.7537,  11.8270,\n",
      "          0.2127, -16.4118,  11.8523,   0.1781, -14.0385,  11.8749,   0.1593,\n",
      "        -11.6456,  11.9117,   0.1426,  -9.2811,  11.9215,   0.1243,  -6.8753,\n",
      "         11.9558,   0.1085], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-33.03163741631538, -28.231143552208252, 7.830469023245698, 11.978184193143901]\n",
      "action_list [-1.9000745585003, -0.0018892270000632322]\n",
      "new_action_list [-2.7574174449259017, -0.0028059362460825963]\n",
      "time_step:  10\n",
      "reference_tensor:  tensor([-2.5836e+01,  1.1978e+01, -2.8059e-03, -2.3440e+01,  1.1977e+01,\n",
      "        -2.2546e-03, -2.1045e+01,  1.1977e+01, -1.0187e-03, -1.8649e+01,\n",
      "         1.1977e+01,  8.9208e-04, -1.6254e+01,  1.1978e+01,  3.4790e-03,\n",
      "        -1.3858e+01,  1.1979e+01,  6.6227e-03, -1.1462e+01,  1.1981e+01,\n",
      "         1.0226e-02, -9.0655e+00,  1.1984e+01,  1.3880e-02, -6.6684e+00,\n",
      "         1.1987e+01,  1.7177e-02, -4.2705e+00,  1.1991e+01,  1.9805e-02])\n",
      "decoder_prediction:  tensor([-25.8115,  11.6736,   0.3197, -23.4551,  11.7520,   0.2607, -21.0980,\n",
      "         11.7613,   0.2278, -18.7500,  11.8051,   0.1987, -16.3587,  11.8388,\n",
      "          0.1893, -14.0204,  11.8630,   0.1635, -11.6500,  11.8762,   0.1446,\n",
      "         -9.2639,  11.8952,   0.1406,  -6.9090,  11.9264,   0.1368,  -4.5006,\n",
      "         11.9462,   0.1183], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.520691960564758, -25.835562832304394, 7.278985534260517, 11.977623005894685]\n",
      "action_list [-2.7574174449259017, -0.0028059362460825963]\n",
      "new_action_list [-3.646518593514705, -0.0022545796993380302]\n",
      "time_step:  11\n",
      "reference_tensor:  tensor([-2.3440e+01,  1.1977e+01, -2.2546e-03, -2.1045e+01,  1.1977e+01,\n",
      "        -1.0187e-03, -1.8649e+01,  1.1977e+01,  8.9208e-04, -1.6254e+01,\n",
      "         1.1978e+01,  3.4790e-03, -1.3858e+01,  1.1979e+01,  6.6227e-03,\n",
      "        -1.1462e+01,  1.1981e+01,  1.0226e-02, -9.0655e+00,  1.1984e+01,\n",
      "         1.3880e-02, -6.6684e+00,  1.1987e+01,  1.7177e-02, -4.2705e+00,\n",
      "         1.1991e+01,  1.9805e-02, -1.8718e+00,  1.1996e+01,  2.1565e-02])\n",
      "decoder_prediction:  tensor([-23.4737,  11.7538,   0.2231, -21.0967,  11.8356,   0.1783, -18.7254,\n",
      "         11.8153,   0.1675, -16.3621,  11.8477,   0.1556, -13.9569,  11.8896,\n",
      "          0.1722, -11.6142,  11.9132,   0.1546,  -9.2400,  11.9174,   0.1343,\n",
      "         -6.8527,  11.9177,   0.1427,  -4.5000,  11.9723,   0.1534,  -2.0802,\n",
      "         11.9771,   0.1312], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-30.137825225582947, -23.440083322719442, 6.549681815557577, 11.977172089954818]\n",
      "action_list [-3.646518593514705, -0.0022545796993380302]\n",
      "new_action_list [-4.488624115749275, -0.001018696894139942]\n",
      "time_step:  12\n",
      "reference_tensor:  tensor([-2.1045e+01,  1.1977e+01, -1.0187e-03, -1.8649e+01,  1.1977e+01,\n",
      "         8.9208e-04, -1.6254e+01,  1.1978e+01,  3.4790e-03, -1.3858e+01,\n",
      "         1.1979e+01,  6.6227e-03, -1.1462e+01,  1.1981e+01,  1.0226e-02,\n",
      "        -9.0655e+00,  1.1984e+01,  1.3880e-02, -6.6684e+00,  1.1987e+01,\n",
      "         1.7177e-02, -4.2705e+00,  1.1991e+01,  1.9805e-02, -1.8718e+00,\n",
      "         1.1996e+01,  2.1565e-02,  5.2782e-01,  1.2000e+01,  2.2428e-02])\n",
      "decoder_prediction:  tensor([-21.1428,  11.8476,   0.1343, -18.7427,  11.9334,   0.1029, -16.3542,\n",
      "         11.8855,   0.1128, -13.9731,  11.9071,   0.1173, -11.5506,  11.9573,\n",
      "          0.1585,  -9.1995,  11.9805,   0.1486,  -6.8183,  11.9767,   0.1268,\n",
      "         -4.4257,  11.9587,   0.1468,  -2.0714,  12.0365,   0.1711,   0.3637,\n",
      "         12.0271,   0.1455], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-28.917661344786417, -21.044669278666362, 5.6519569924077215, 11.97696835057599]\n",
      "action_list [-4.488624115749275, -0.001018696894139942]\n",
      "new_action_list [-5.0, 0.0008920797992408871]\n",
      "time_step:  13\n",
      "reference_tensor:  tensor([-1.8649e+01,  1.1977e+01,  8.9208e-04, -1.6254e+01,  1.1978e+01,\n",
      "         3.4790e-03, -1.3858e+01,  1.1979e+01,  6.6227e-03, -1.1462e+01,\n",
      "         1.1981e+01,  1.0226e-02, -9.0655e+00,  1.1984e+01,  1.3880e-02,\n",
      "        -6.6684e+00,  1.1987e+01,  1.7177e-02, -4.2705e+00,  1.1991e+01,\n",
      "         1.9805e-02, -1.8718e+00,  1.1996e+01,  2.1565e-02,  5.2782e-01,\n",
      "         1.2000e+01,  2.2428e-02,  2.9283e+00,  1.2005e+01,  2.2441e-02])\n",
      "decoder_prediction:  tensor([-18.8010,  11.9353,   0.0672, -16.3789,  12.0230,   0.0466, -13.9736,\n",
      "         11.9555,   0.0717, -11.5780,  11.9691,   0.0888,  -9.1387,  12.0244,\n",
      "          0.1479,  -6.7774,  12.0470,   0.1448,  -4.3874,  12.0382,   0.1231,\n",
      "         -1.9863,  12.0079,   0.1519,   0.3726,  12.1019,   0.1863,   2.8236,\n",
      "         12.0839,   0.1592], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-27.887269946304873, -18.64925776695518, 4.6519569924077215, 11.977146766535839]\n",
      "action_list [-5.0, 0.0008920797992408871]\n",
      "new_action_list [-5.0, 0.0034789843245908022]\n",
      "time_step:  14\n",
      "reference_tensor:  tensor([-1.6254e+01,  1.1978e+01,  3.4790e-03, -1.3858e+01,  1.1979e+01,\n",
      "         6.6227e-03, -1.1462e+01,  1.1981e+01,  1.0226e-02, -9.0655e+00,\n",
      "         1.1984e+01,  1.3880e-02, -6.6684e+00,  1.1987e+01,  1.7177e-02,\n",
      "        -4.2705e+00,  1.1991e+01,  1.9805e-02, -1.8718e+00,  1.1996e+01,\n",
      "         2.1565e-02,  5.2782e-01,  1.2000e+01,  2.2428e-02,  2.9283e+00,\n",
      "         1.2005e+01,  2.2441e-02,  5.3297e+00,  1.2009e+01,  2.1578e-02])\n",
      "decoder_prediction:  tensor([-16.4247,  12.0035,   0.0309, -13.9836,  12.0893,   0.0171, -11.5647,\n",
      "         12.0144,   0.0495,  -9.1618,  12.0240,   0.0740,  -6.7082,  12.0794,\n",
      "          0.1405,  -4.3367,  12.1006,   0.1430,  -1.9374,  12.0915,   0.1241,\n",
      "          0.4750,  12.0581,   0.1578,   2.8409,  12.1576,   0.1969,   5.3065,\n",
      "         12.1396,   0.1717], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-27.056878547823327, -16.25375883396152, 3.6519569924077215, 11.977842563400756]\n",
      "action_list [-5.0, 0.0034789843245908022]\n",
      "new_action_list [-5.0, 0.0066226872166460764]\n",
      "time_step:  15\n",
      "reference_tensor:  tensor([-1.3858e+01,  1.1979e+01,  6.6227e-03, -1.1462e+01,  1.1981e+01,\n",
      "         1.0226e-02, -9.0655e+00,  1.1984e+01,  1.3880e-02, -6.6684e+00,\n",
      "         1.1987e+01,  1.7177e-02, -4.2705e+00,  1.1991e+01,  1.9805e-02,\n",
      "        -1.8718e+00,  1.1996e+01,  2.1565e-02,  5.2782e-01,  1.2000e+01,\n",
      "         2.2428e-02,  2.9283e+00,  1.2005e+01,  2.2441e-02,  5.3297e+00,\n",
      "         1.2009e+01,  2.1578e-02,  7.7319e+00,  1.2013e+01,  2.0013e-02])\n",
      "decoder_prediction:  tensor([-1.3986e+01,  1.2072e+01, -5.1534e-03, -1.1526e+01,  1.2156e+01,\n",
      "        -1.1573e-02, -9.0935e+00,  1.2074e+01,  2.7932e-02, -6.6833e+00,\n",
      "         1.2079e+01,  5.9890e-02, -4.2159e+00,  1.2135e+01,  1.3365e-01,\n",
      "        -1.8330e+00,  1.2155e+01,  1.4214e-01,  5.7552e-01,  1.2146e+01,\n",
      "         1.2583e-01,  2.9990e+00,  1.2109e+01,  1.6441e-01,  5.3725e+00,\n",
      "         1.2215e+01,  2.0829e-01,  7.8527e+00,  1.2196e+01,  1.8496e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-26.42648714934178, -13.858057867537035, 2.6519569924077215, 11.979167100844085]\n",
      "action_list [-5.0, 0.0066226872166460764]\n",
      "new_action_list [-4.47150979877383, 0.010225693547879165]\n",
      "time_step:  16\n",
      "reference_tensor:  tensor([-1.1462e+01,  1.1981e+01,  1.0226e-02, -9.0655e+00,  1.1984e+01,\n",
      "         1.3880e-02, -6.6684e+00,  1.1987e+01,  1.7177e-02, -4.2705e+00,\n",
      "         1.1991e+01,  1.9805e-02, -1.8718e+00,  1.1996e+01,  2.1565e-02,\n",
      "         5.2782e-01,  1.2000e+01,  2.2428e-02,  2.9283e+00,  1.2005e+01,\n",
      "         2.2441e-02,  5.3297e+00,  1.2009e+01,  2.1578e-02,  7.7319e+00,\n",
      "         1.2013e+01,  2.0013e-02,  1.0135e+01,  1.2017e+01,  1.7897e-02])\n",
      "decoder_prediction:  tensor([-11.6247,  12.0887,   0.0510,  -9.1574,  12.1817,   0.0444,  -6.7140,\n",
      "         12.1119,   0.0783,  -4.3113,  12.1241,   0.1087,  -1.8286,  12.1841,\n",
      "          0.1765,   0.5685,  12.2065,   0.1852,   2.9844,  12.2093,   0.1689,\n",
      "          5.4270,  12.1762,   0.2052,   7.8112,  12.2874,   0.2448,  10.3141,\n",
      "         12.2799,   0.2233], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-25.985525946835715, -11.46201993349726, 1.7576550326529554, 11.981212239553662]\n",
      "action_list [-4.47150979877383, 0.010225693547879165]\n",
      "new_action_list [-3.5776881314683555, 0.013880014970599644]\n",
      "time_step:  17\n",
      "reference_tensor:  tensor([-9.0655, 11.9840,  0.0139, -6.6684, 11.9874,  0.0172, -4.2705, 11.9914,\n",
      "         0.0198, -1.8718, 11.9957,  0.0216,  0.5278, 12.0002,  0.0224,  2.9283,\n",
      "        12.0047,  0.0224,  5.3297, 12.0090,  0.0216,  7.7319, 12.0130,  0.0200,\n",
      "        10.1348, 12.0166,  0.0179, 12.5384, 12.0197,  0.0154])\n",
      "decoder_prediction:  tensor([-9.2902, 12.0056,  0.1771, -6.8351, 12.1175,  0.1656, -4.3953, 12.0734,\n",
      "         0.1853, -2.0231, 12.1015,  0.2081,  0.4642, 12.1696,  0.2609,  2.8664,\n",
      "        12.1983,  0.2655,  5.2764, 12.2223,  0.2469,  7.7323, 12.1980,  0.2759,\n",
      "        10.1184, 12.3170,  0.3046, 12.6390, 12.3283,  0.2846],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-25.70554870293449, -9.065499885287117, 1.0421174063592842, 11.983988242547781]\n",
      "action_list [-3.5776881314683555, 0.013880014970599644]\n",
      "new_action_list [-2.5844710503459436, 0.01717744380588492]\n",
      "time_step:  18\n",
      "reference_tensor:  tensor([-6.6684e+00,  1.1987e+01,  1.7177e-02, -4.2705e+00,  1.1991e+01,\n",
      "         1.9805e-02, -1.8718e+00,  1.1996e+01,  2.1565e-02,  5.2782e-01,\n",
      "         1.2000e+01,  2.2428e-02,  2.9283e+00,  1.2005e+01,  2.2441e-02,\n",
      "         5.3297e+00,  1.2009e+01,  2.1578e-02,  7.7319e+00,  1.2013e+01,\n",
      "         2.0013e-02,  1.0135e+01,  1.2017e+01,  1.7897e-02,  1.2538e+01,\n",
      "         1.2020e+01,  1.5438e-02,  1.4943e+01,  1.2022e+01,  1.2846e-02])\n",
      "decoder_prediction:  tensor([-6.6848, 11.8921,  0.2901, -4.2629, 12.0138,  0.2781, -1.8389, 12.0022,\n",
      "         0.2847,  0.5059, 12.0408,  0.2972,  2.9765, 12.1185,  0.3333,  5.3883,\n",
      "        12.1554,  0.3367,  7.7839, 12.2009,  0.3190, 10.2401, 12.1814,  0.3372,\n",
      "        12.6321, 12.3092,  0.3544, 15.1509, 12.3331,  0.3369],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-25.54881464266955, -6.668358687901446, 0.5252231962900954, 11.987423731308958]\n",
      "action_list [-2.5844710503459436, 0.01717744380588492]\n",
      "new_action_list [-1.5240465585293375, 0.01980547470657398]\n",
      "time_step:  19\n",
      "reference_tensor:  tensor([-4.2705e+00,  1.1991e+01,  1.9805e-02, -1.8718e+00,  1.1996e+01,\n",
      "         2.1565e-02,  5.2782e-01,  1.2000e+01,  2.2428e-02,  2.9283e+00,\n",
      "         1.2005e+01,  2.2441e-02,  5.3297e+00,  1.2009e+01,  2.1578e-02,\n",
      "         7.7319e+00,  1.2013e+01,  2.0013e-02,  1.0135e+01,  1.2017e+01,\n",
      "         1.7897e-02,  1.2538e+01,  1.2020e+01,  1.5438e-02,  1.4943e+01,\n",
      "         1.2022e+01,  1.2846e-02,  1.7347e+01,  1.2024e+01,  1.0294e-02])\n",
      "decoder_prediction:  tensor([-4.3106, 11.7393,  0.3117, -2.0077, 11.8159,  0.3197,  0.3630, 11.8745,\n",
      "         0.3126,  2.7327, 11.8914,  0.3086,  5.0980, 11.9830,  0.3101,  7.5573,\n",
      "        12.0354,  0.3238,  9.9205, 12.0953,  0.3042, 12.3227, 12.0717,  0.2996,\n",
      "        14.7479, 12.1923,  0.3061, 17.1904, 12.1919,  0.2898],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-25.47425093458212, -4.270477832145524, 0.2204138845842279, 11.991384826250274]\n",
      "action_list [-1.5240465585293375, 0.01980547470657398]\n",
      "new_action_list [-0.4527096842105928, 0.02156459575119101]\n",
      "time_step:  20\n",
      "reference_tensor:  tensor([-1.8718e+00,  1.1996e+01,  2.1565e-02,  5.2782e-01,  1.2000e+01,\n",
      "         2.2428e-02,  2.9283e+00,  1.2005e+01,  2.2441e-02,  5.3297e+00,\n",
      "         1.2009e+01,  2.1578e-02,  7.7319e+00,  1.2013e+01,  2.0013e-02,\n",
      "         1.0135e+01,  1.2017e+01,  1.7897e-02,  1.2538e+01,  1.2020e+01,\n",
      "         1.5438e-02,  1.4943e+01,  1.2022e+01,  1.2846e-02,  1.7347e+01,\n",
      "         1.2024e+01,  1.0294e-02,  1.9752e+01,  1.2026e+01,  7.9110e-03])\n",
      "decoder_prediction:  tensor([-1.8409, 11.7094,  0.3551,  0.4140, 11.7628,  0.3561,  2.7718, 11.8567,\n",
      "         0.3365,  5.1746, 11.8900,  0.3208,  7.5155, 11.9691,  0.3012,  9.9745,\n",
      "        12.0299,  0.3008, 12.3519, 12.0950,  0.2822, 14.7491, 12.1080,  0.2640,\n",
      "        17.2052, 12.1894,  0.2512, 19.6226, 12.2032,  0.2365],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-25.439222351349486, -1.8717695749804477, 0.1298719477421093, 11.995697745400511]\n",
      "action_list [-0.4527096842105928, 0.02156459575119101]\n",
      "new_action_list [-0.274109254429592, 0.02242798155212309]\n",
      "time_step:  21\n",
      "reference_tensor:  tensor([5.2782e-01, 1.2000e+01, 2.2428e-02, 2.9283e+00, 1.2005e+01, 2.2441e-02,\n",
      "        5.3297e+00, 1.2009e+01, 2.1578e-02, 7.7319e+00, 1.2013e+01, 2.0013e-02,\n",
      "        1.0135e+01, 1.2017e+01, 1.7897e-02, 1.2538e+01, 1.2020e+01, 1.5438e-02,\n",
      "        1.4943e+01, 1.2022e+01, 1.2846e-02, 1.7347e+01, 1.2024e+01, 1.0294e-02,\n",
      "        1.9752e+01, 1.2026e+01, 7.9110e-03, 2.2158e+01, 1.2027e+01, 5.7763e-03])\n",
      "decoder_prediction:  tensor([ 0.5964, 11.7543,  0.3675,  2.8361, 11.8033,  0.3586,  5.2030, 11.9005,\n",
      "         0.3393,  7.6498, 11.9570,  0.3229, 10.0032, 12.0261,  0.3041, 12.4478,\n",
      "        12.0944,  0.2831, 14.8541, 12.1558,  0.2597, 17.2619, 12.2017,  0.2386,\n",
      "        19.7426, 12.2554,  0.2128, 22.1618, 12.2825,  0.1934],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-25.418730146889654, 0.5278185337306951, 0.0750500968561909, 12.000183341710935]\n",
      "action_list [-0.274109254429592, 0.02242798155212309]\n",
      "new_action_list [-0.35483922784268174, 0.022440733257841374]\n",
      "time_step:  22\n",
      "reference_tensor:  tensor([2.9283e+00, 1.2005e+01, 2.2441e-02, 5.3297e+00, 1.2009e+01, 2.1578e-02,\n",
      "        7.7319e+00, 1.2013e+01, 2.0013e-02, 1.0135e+01, 1.2017e+01, 1.7897e-02,\n",
      "        1.2538e+01, 1.2020e+01, 1.5438e-02, 1.4943e+01, 1.2022e+01, 1.2846e-02,\n",
      "        1.7347e+01, 1.2024e+01, 1.0294e-02, 1.9752e+01, 1.2026e+01, 7.9110e-03,\n",
      "        2.2158e+01, 1.2027e+01, 5.7763e-03, 2.4563e+01, 1.2028e+01, 3.9276e-03])\n",
      "decoder_prediction:  tensor([ 3.0485, 11.7525,  0.3663,  5.2689, 11.8013,  0.3485,  7.6369, 11.8933,\n",
      "         0.3340, 10.1171, 11.9738,  0.3209, 12.4785, 12.0344,  0.3095, 14.8925,\n",
      "        12.1101,  0.2675, 17.3179, 12.1657,  0.2378, 19.7265, 12.2425,  0.2172,\n",
      "        22.2169, 12.2733,  0.1807, 24.6314, 12.3127,  0.1551],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-25.41081691207527, 2.928304016738039, 0.004082251287654562, 12.004671488362503]\n",
      "action_list [-0.35483922784268174, 0.022440733257841374]\n",
      "new_action_list [-0.02041125643827281, 0.021577580530269747]\n",
      "time_step:  23\n",
      "reference_tensor:  tensor([5.3297e+00, 1.2009e+01, 2.1578e-02, 7.7319e+00, 1.2013e+01, 2.0013e-02,\n",
      "        1.0135e+01, 1.2017e+01, 1.7897e-02, 1.2538e+01, 1.2020e+01, 1.5438e-02,\n",
      "        1.4943e+01, 1.2022e+01, 1.2846e-02, 1.7347e+01, 1.2024e+01, 1.0294e-02,\n",
      "        1.9752e+01, 1.2026e+01, 7.9110e-03, 2.2158e+01, 1.2027e+01, 5.7763e-03,\n",
      "        2.4563e+01, 1.2028e+01, 3.9276e-03, 2.6969e+01, 1.2028e+01, 2.3708e-03])\n",
      "decoder_prediction:  tensor([ 5.3278, 11.7009,  0.2279,  7.6104, 11.7375,  0.2330,  9.9724, 11.8147,\n",
      "         0.2267, 12.4291, 11.8636,  0.2628, 14.8028, 11.9334,  0.2274, 17.1714,\n",
      "        11.9999,  0.2143, 19.5849, 12.0254,  0.1226, 21.9666, 12.1485,  0.1384,\n",
      "        24.3428, 12.1287,  0.1531, 26.8109, 12.1640,  0.1122],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-50.0, -45.320307278072384, 10.0, 8.39253608194375]\n",
      "action_list [0, 0]\n",
      "new_action_list [-5.0, -0.120043750007574]\n",
      "time_step:  0\n",
      "reference_tensor:  tensor([-43.6442,   8.3685,  -0.1200, -41.9730,   8.3434,  -0.1257, -40.3069,\n",
      "          8.3172,  -0.1308, -38.6462,   8.2901,  -0.1358, -36.9910,   8.2619,\n",
      "         -0.1407, -35.3415,   8.2328,  -0.1454, -33.6980,   8.2029,  -0.1497,\n",
      "        -32.0605,   8.1722,  -0.1537, -30.4292,   8.1408,  -0.1570, -28.8042,\n",
      "          8.1088,  -0.1597])\n",
      "decoder_prediction:  tensor([-43.6039,   9.3260,   0.6301, -41.7825,   9.4718,   0.5670, -39.8845,\n",
      "          9.5410,   0.5115, -37.9388,   9.6000,   0.4501, -36.0261,   9.7170,\n",
      "          0.4219, -34.0527,   9.7870,   0.3671, -32.1280,   9.8291,   0.2938,\n",
      "        -30.1917,   9.8012,   0.2605, -28.2248,   9.9158,   0.2380, -26.2510,\n",
      "          9.8866,   0.1791], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-48.1, -43.64420093668379, 9.0, 8.368527331942234]\n",
      "action_list [-5.0, -0.120043750007574]\n",
      "new_action_list [-5.0, -0.12572230215492558]\n",
      "time_step:  1\n",
      "reference_tensor:  tensor([-41.9730,   8.3434,  -0.1257, -40.3069,   8.3172,  -0.1308, -38.6462,\n",
      "          8.2901,  -0.1358, -36.9910,   8.2619,  -0.1407, -35.3415,   8.2328,\n",
      "         -0.1454, -33.6980,   8.2029,  -0.1497, -32.0605,   8.1722,  -0.1537,\n",
      "        -30.4292,   8.1408,  -0.1570, -28.8042,   8.1088,  -0.1597, -27.1857,\n",
      "          8.0765,  -0.1614])\n",
      "decoder_prediction:  tensor([-41.6879,   8.0831,   0.2789, -40.0869,   8.1540,   0.2542, -38.4667,\n",
      "          8.1890,   0.2388, -36.7726,   8.2169,   0.2126, -35.1535,   8.2961,\n",
      "          0.2154, -33.4754,   8.3500,   0.1903, -31.8097,   8.3670,   0.1482,\n",
      "        -30.1737,   8.3548,   0.1384, -28.4861,   8.4305,   0.1368, -26.8278,\n",
      "          8.4014,   0.0970], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-46.4, -41.97300991633844, 8.0, 8.343382871511249]\n",
      "action_list [-5.0, -0.12572230215492558]\n",
      "new_action_list [-2.692651306659065, -0.1307858595474492]\n",
      "time_step:  2\n",
      "reference_tensor:  tensor([-40.3069,   8.3172,  -0.1308, -38.6462,   8.2901,  -0.1358, -36.9910,\n",
      "          8.2619,  -0.1407, -35.3415,   8.2328,  -0.1454, -33.6980,   8.2029,\n",
      "         -0.1497, -32.0605,   8.1722,  -0.1537, -30.4292,   8.1408,  -0.1570,\n",
      "        -28.8042,   8.1088,  -0.1597, -27.1857,   8.0765,  -0.1614, -25.5736,\n",
      "          8.0442,  -0.1619])\n",
      "decoder_prediction:  tensor([-40.2730,   8.0369,   0.3002, -38.6671,   8.0670,   0.2649, -37.0612,\n",
      "          8.1392,   0.2249, -35.3948,   8.1758,   0.1851, -33.7907,   8.2144,\n",
      "          0.1517, -32.1284,   8.2561,   0.1291, -30.4576,   8.2816,   0.1104,\n",
      "        -28.8185,   8.3174,   0.0908, -27.1293,   8.3261,   0.0724, -25.4924,\n",
      "          8.3373,   0.0544], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-44.85385302613318, -40.306949059227136, 7.461469738668187, 8.317225699601758]\n",
      "action_list [-2.692651306659065, -0.1307858595474492]\n",
      "new_action_list [-1.9418470651572337, -0.13579828043355066]\n",
      "time_step:  3\n",
      "reference_tensor:  tensor([-38.6462,   8.2901,  -0.1358, -36.9910,   8.2619,  -0.1407, -35.3415,\n",
      "          8.2328,  -0.1454, -33.6980,   8.2029,  -0.1497, -32.0605,   8.1722,\n",
      "         -0.1537, -30.4292,   8.1408,  -0.1570, -28.8042,   8.1088,  -0.1597,\n",
      "        -27.1857,   8.0765,  -0.1614, -25.5736,   8.0442,  -0.1619, -23.9680,\n",
      "          8.0120,  -0.1610])\n",
      "decoder_prediction:  tensor([-3.8692e+01,  7.9716e+00,  2.5669e-01, -3.7091e+01,  7.9794e+00,\n",
      "         2.2402e-01, -3.5503e+01,  8.0574e+00,  1.8238e-01, -3.3858e+01,\n",
      "         8.0916e+00,  1.4438e-01, -3.2274e+01,  8.1126e+00,  1.0474e-01,\n",
      "        -3.0633e+01,  8.1477e+00,  8.8107e-02, -2.8974e+01,  8.1729e+00,\n",
      "         8.1336e-02, -2.7350e+01,  8.2246e+00,  6.2802e-02, -2.5677e+01,\n",
      "         8.2088e+00,  4.2793e-02, -2.4064e+01,  8.2329e+00,  3.4804e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-43.40039601970269, -38.64621988491545, 7.073100325636741, 8.290066043515049]\n",
      "action_list [-1.9418470651572337, -0.13579828043355066]\n",
      "new_action_list [-1.8760674040259, -0.14070556766759157]\n",
      "time_step:  4\n",
      "reference_tensor:  tensor([-36.9910,   8.2619,  -0.1407, -35.3415,   8.2328,  -0.1454, -33.6980,\n",
      "          8.2029,  -0.1497, -32.0605,   8.1722,  -0.1537, -30.4292,   8.1408,\n",
      "         -0.1570, -28.8042,   8.1088,  -0.1597, -27.1857,   8.0765,  -0.1614,\n",
      "        -25.5736,   8.0442,  -0.1619, -23.9680,   8.0120,  -0.1610, -22.3688,\n",
      "          7.9803,  -0.1584])\n",
      "decoder_prediction:  tensor([-3.7015e+01,  7.9723e+00,  1.9308e-01, -3.5407e+01,  7.9683e+00,\n",
      "         1.6721e-01, -3.3822e+01,  8.0379e+00,  1.3309e-01, -3.2182e+01,\n",
      "         8.0661e+00,  1.0260e-01, -3.0603e+01,  8.0799e+00,  6.9532e-02,\n",
      "        -2.8972e+01,  8.1109e+00,  5.9349e-02, -2.7316e+01,  8.1321e+00,\n",
      "         5.8832e-02, -2.5701e+01,  8.1854e+00,  4.5648e-02, -2.4036e+01,\n",
      "         8.1643e+00,  3.0322e-02, -2.2432e+01,  8.1895e+00,  2.6565e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-42.02329730265586, -36.9910207875658, 6.697886844831561, 8.26192492998153]\n",
      "action_list [-1.8760674040259, -0.14070556766759157]\n",
      "new_action_list [-1.8525621520708873, -0.14538139283634033]\n",
      "time_step:  5\n",
      "reference_tensor:  tensor([-35.3415,   8.2328,  -0.1454, -33.6980,   8.2029,  -0.1497, -32.0605,\n",
      "          8.1722,  -0.1537, -30.4292,   8.1408,  -0.1570, -28.8042,   8.1088,\n",
      "         -0.1597, -27.1857,   8.0765,  -0.1614, -25.5736,   8.0442,  -0.1619,\n",
      "        -23.9680,   8.0120,  -0.1610, -22.3688,   7.9803,  -0.1584, -20.7758,\n",
      "          7.9495,  -0.1539])\n",
      "decoder_prediction:  tensor([-3.5345e+01,  7.9865e+00,  1.3417e-01, -3.3727e+01,  7.9727e+00,\n",
      "         1.1490e-01, -3.2143e+01,  8.0337e+00,  8.8338e-02, -3.0505e+01,\n",
      "         8.0562e+00,  6.5254e-02, -2.8927e+01,  8.0643e+00,  3.9134e-02,\n",
      "        -2.7302e+01,  8.0917e+00,  3.4996e-02, -2.5648e+01,  8.1091e+00,\n",
      "         3.9842e-02, -2.4037e+01,  8.1629e+00,  3.1919e-02, -2.2378e+01,\n",
      "         8.1386e+00,  2.1359e-02, -2.0779e+01,  8.1642e+00,  2.1133e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-40.72077117673096, -35.34154342942622, 6.327374414417383, 8.232848651414262]\n",
      "action_list [-1.8525621520708873, -0.14538139283634033]\n",
      "new_action_list [-1.866428169367919, -0.14974134727867977]\n",
      "time_step:  6\n",
      "reference_tensor:  tensor([-33.6980,   8.2029,  -0.1497, -32.0605,   8.1722,  -0.1537, -30.4292,\n",
      "          8.1408,  -0.1570, -28.8042,   8.1088,  -0.1597, -27.1857,   8.0765,\n",
      "         -0.1614, -25.5736,   8.0442,  -0.1619, -23.9680,   8.0120,  -0.1610,\n",
      "        -22.3688,   7.9803,  -0.1584, -20.7758,   7.9495,  -0.1539, -19.1888,\n",
      "          7.9201,  -0.1470])\n",
      "decoder_prediction:  tensor([-3.3685e+01,  7.9989e+00,  7.6743e-02, -3.2060e+01,  7.9766e+00,\n",
      "         6.4204e-02, -3.0476e+01,  8.0285e+00,  4.5536e-02, -2.8840e+01,\n",
      "         8.0454e+00,  3.0007e-02, -2.7263e+01,  8.0488e+00,  1.1385e-02,\n",
      "        -2.5643e+01,  8.0730e+00,  1.3154e-02, -2.3991e+01,  8.0868e+00,\n",
      "         2.2809e-02, -2.2385e+01,  8.1401e+00,  2.0224e-02, -2.0731e+01,\n",
      "         8.1142e+00,  1.4643e-02, -1.9137e+01,  8.1397e+00,  1.7471e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-39.492624857234844, -33.69796852608894, 5.954088780543799, 8.202900381958527]\n",
      "action_list [-1.866428169367919, -0.14974134727867977]\n",
      "new_action_list [-1.9141133804764352, -0.15367597784664067]\n",
      "time_step:  7\n",
      "reference_tensor:  tensor([-32.0605,   8.1722,  -0.1537, -30.4292,   8.1408,  -0.1570, -28.8042,\n",
      "          8.1088,  -0.1597, -27.1857,   8.0765,  -0.1614, -25.5736,   8.0442,\n",
      "         -0.1619, -23.9680,   8.0120,  -0.1610, -22.3688,   7.9803,  -0.1584,\n",
      "        -20.7758,   7.9495,  -0.1539, -19.1888,   7.9201,  -0.1470, -17.6076,\n",
      "          7.8925,  -0.1378])\n",
      "decoder_prediction:  tensor([-3.2039e+01,  8.0103e+00,  2.0579e-02, -3.0406e+01,  7.9804e+00,\n",
      "         1.4874e-02, -2.8822e+01,  8.0229e+00,  4.3956e-03, -2.7188e+01,\n",
      "         8.0342e+00, -3.4456e-03, -2.5612e+01,  8.0339e+00, -1.4077e-02,\n",
      "        -2.3998e+01,  8.0552e+00, -6.5307e-03, -2.2348e+01,  8.0654e+00,\n",
      "         7.4418e-03, -2.0746e+01,  8.1174e+00,  1.0266e-02, -1.9099e+01,\n",
      "         8.0912e+00,  9.8538e-03, -1.7509e+01,  8.1160e+00,  1.5311e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-38.34008936873562, -32.06046196925416, 5.571266104448512, 8.172165186389199]\n",
      "action_list [-1.9141133804764352, -0.15367597784664067]\n",
      "new_action_list [-1.9892952696913417, -0.15704684097035515]\n",
      "time_step:  8\n",
      "reference_tensor:  tensor([-30.4292,   8.1408,  -0.1570, -28.8042,   8.1088,  -0.1597, -27.1857,\n",
      "          8.0765,  -0.1614, -25.5736,   8.0442,  -0.1619, -23.9680,   8.0120,\n",
      "         -0.1610, -22.3688,   7.9803,  -0.1584, -20.7758,   7.9495,  -0.1539,\n",
      "        -19.1888,   7.9201,  -0.1470, -17.6076,   7.8925,  -0.1378, -16.0316,\n",
      "          7.8673,  -0.1261])\n",
      "decoder_prediction:  tensor([-3.0407e+01,  8.0207e+00, -3.4315e-02, -2.8766e+01,  7.9842e+00,\n",
      "        -3.3115e-02, -2.7183e+01,  8.0169e+00, -3.5185e-02, -2.5550e+01,\n",
      "         8.0227e+00, -3.5255e-02, -2.3975e+01,  8.0193e+00, -3.7517e-02,\n",
      "        -2.2367e+01,  8.0380e+00, -2.4317e-02, -2.0719e+01,  8.0447e+00,\n",
      "        -6.4476e-03, -1.9122e+01,  8.0949e+00,  1.8257e-03, -1.7481e+01,\n",
      "         8.0695e+00,  6.7222e-03, -1.5894e+01,  8.0931e+00,  1.4448e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-37.26562205323974, -30.429169868795732, 5.173407050510243, 8.140755818195128]\n",
      "action_list [-1.9892952696913417, -0.15704684097035515]\n",
      "new_action_list [-2.0866524691088353, -0.15968439441808427]\n",
      "time_step:  9\n",
      "reference_tensor:  tensor([-28.8042,   8.1088,  -0.1597, -27.1857,   8.0765,  -0.1614, -25.5736,\n",
      "          8.0442,  -0.1619, -23.9680,   8.0120,  -0.1610, -22.3688,   7.9803,\n",
      "         -0.1584, -20.7758,   7.9495,  -0.1539, -19.1888,   7.9201,  -0.1470,\n",
      "        -17.6076,   7.8925,  -0.1378, -16.0316,   7.8673,  -0.1261, -14.4604,\n",
      "          7.8450,  -0.1118])\n",
      "decoder_prediction:  tensor([-2.8786e+01,  8.0302e+00, -8.7895e-02, -2.7138e+01,  7.9878e+00,\n",
      "        -7.9744e-02, -2.5555e+01,  8.0105e+00, -7.3258e-02, -2.3924e+01,\n",
      "         8.0110e+00, -6.5507e-02, -2.2351e+01,  8.0052e+00, -5.9118e-02,\n",
      "        -2.0748e+01,  8.0215e+00, -4.0376e-02, -1.9103e+01,  8.0248e+00,\n",
      "        -1.8979e-02, -1.7510e+01,  8.0727e+00, -5.2422e-03, -1.5876e+01,\n",
      "         8.0491e+00,  5.0606e-03, -1.4292e+01,  8.0711e+00,  1.4749e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-36.27267369251987, -28.804212393045066, 4.756076556688476, 8.108818939311512]\n",
      "action_list [-2.0866524691088353, -0.15968439441808427]\n",
      "new_action_list [-2.1996925345574696, -0.1613864346916376]\n",
      "time_step:  10\n",
      "reference_tensor:  tensor([-27.1857,   8.0765,  -0.1614, -25.5736,   8.0442,  -0.1619, -23.9680,\n",
      "          8.0120,  -0.1610, -22.3688,   7.9803,  -0.1584, -20.7758,   7.9495,\n",
      "         -0.1539, -19.1888,   7.9201,  -0.1470, -17.6076,   7.8925,  -0.1378,\n",
      "        -16.0316,   7.8673,  -0.1261, -14.4604,   7.8450,  -0.1118, -12.8933,\n",
      "          7.8259,  -0.0952])\n",
      "decoder_prediction:  tensor([-2.7175e+01,  8.0390e+00, -1.3998e-01, -2.5520e+01,  7.9914e+00,\n",
      "        -1.2487e-01, -2.3938e+01,  8.0041e+00, -1.0977e-01, -2.2309e+01,\n",
      "         7.9993e+00, -9.4202e-02, -2.0736e+01,  7.9916e+00, -7.8999e-02,\n",
      "        -1.9138e+01,  8.0058e+00, -5.4828e-02, -1.7496e+01,  8.0058e+00,\n",
      "        -3.0218e-02, -1.5908e+01,  8.0509e+00, -1.1042e-02, -1.4280e+01,\n",
      "         8.0299e+00,  4.7084e-03, -1.2699e+01,  8.0502e+00,  1.6107e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-35.36545223187332, -27.185676333876597, 4.316138049776982, 8.076541652373184]\n",
      "action_list [-2.1996925345574696, -0.1613864346916376]\n",
      "new_action_list [-2.3202904314511112, -0.16191941989649689]\n",
      "time_step:  11\n",
      "reference_tensor:  tensor([-25.5736,   8.0442,  -0.1619, -23.9680,   8.0120,  -0.1610, -22.3688,\n",
      "          7.9803,  -0.1584, -20.7758,   7.9495,  -0.1539, -19.1888,   7.9201,\n",
      "         -0.1470, -17.6076,   7.8925,  -0.1378, -16.0316,   7.8673,  -0.1261,\n",
      "        -14.4604,   7.8450,  -0.1118, -12.8933,   7.8259,  -0.0952, -11.3296,\n",
      "          7.8105,  -0.0771])\n",
      "decoder_prediction:  tensor([-2.5571e+01,  8.0474e+00, -1.9025e-01, -2.3910e+01,  7.9952e+00,\n",
      "        -1.6823e-01, -2.2327e+01,  7.9979e+00, -1.4456e-01, -2.0700e+01,\n",
      "         7.9880e+00, -1.2126e-01, -1.9127e+01,  7.9790e+00, -9.7233e-02,\n",
      "        -1.7535e+01,  7.9912e+00, -6.7751e-02, -1.5895e+01,  7.9881e+00,\n",
      "        -4.0185e-02, -1.4312e+01,  8.0302e+00, -1.5647e-02, -1.2690e+01,\n",
      "         8.0123e+00,  5.5163e-03, -1.1111e+01,  8.0307e+00,  1.8439e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-34.54863043054695, -25.57360639179989, 3.85207996348676, 8.044157768393884]\n",
      "action_list [-2.3202904314511112, -0.16191941989649689]\n",
      "new_action_list [-2.4396147163572337, -0.16102396428945454]\n",
      "time_step:  12\n",
      "reference_tensor:  tensor([-23.9680,   8.0120,  -0.1610, -22.3688,   7.9803,  -0.1584, -20.7758,\n",
      "          7.9495,  -0.1539, -19.1888,   7.9201,  -0.1470, -17.6076,   7.8925,\n",
      "         -0.1378, -16.0316,   7.8673,  -0.1261, -14.4604,   7.8450,  -0.1118,\n",
      "        -12.8933,   7.8259,  -0.0952, -11.3296,   7.8105,  -0.0771,  -9.7687,\n",
      "          7.7989,  -0.0578])\n",
      "decoder_prediction:  tensor([-2.3969e+01,  8.0555e+00, -2.3831e-01, -2.2302e+01,  7.9992e+00,\n",
      "        -2.0948e-01, -2.0719e+01,  7.9923e+00, -1.7744e-01, -1.9094e+01,\n",
      "         7.9774e+00, -1.4655e-01, -1.7522e+01,  7.9673e+00, -1.1386e-01,\n",
      "        -1.5934e+01,  7.9778e+00, -7.9198e-02, -1.4297e+01,  7.9719e+00,\n",
      "        -4.8873e-02, -1.2718e+01,  8.0108e+00, -1.9111e-02, -1.1102e+01,\n",
      "         7.9965e+00,  7.3482e-03, -9.5250e+00,  8.0130e+00,  2.1675e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-33.82700673217674, -23.9679953174069, 3.364157020215313, 8.011952975535992]\n",
      "action_list [-2.4396147163572337, -0.16102396428945454]\n",
      "new_action_list [-2.5475856579269034, -0.15842536389276424]\n",
      "time_step:  13\n",
      "reference_tensor:  tensor([-22.3688,   7.9803,  -0.1584, -20.7758,   7.9495,  -0.1539, -19.1888,\n",
      "          7.9201,  -0.1470, -17.6076,   7.8925,  -0.1378, -16.0316,   7.8673,\n",
      "         -0.1261, -14.4604,   7.8450,  -0.1118, -12.8933,   7.8259,  -0.0952,\n",
      "        -11.3296,   7.8105,  -0.0771,  -9.7687,   7.7989,  -0.0578,  -8.2096,\n",
      "          7.7915,  -0.0373])\n",
      "decoder_prediction:  tensor([-2.2368e+01,  8.0634e+00, -2.8367e-01, -2.0694e+01,  8.0035e+00,\n",
      "        -2.4821e-01, -1.9111e+01,  7.9874e+00, -2.0812e-01, -1.7488e+01,\n",
      "         7.9678e+00, -1.6990e-01, -1.5916e+01,  7.9570e+00, -1.2891e-01,\n",
      "        -1.4332e+01,  7.9658e+00, -8.9196e-02, -1.2698e+01,  7.9574e+00,\n",
      "        -5.6245e-02, -1.1122e+01,  7.9933e+00, -2.1465e-02, -9.5117e+00,\n",
      "         7.9827e+00,  1.0075e-02, -7.9362e+00,  7.9974e+00,  2.5759e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-33.205127041292215, -22.368773229577556, 2.8546398886299325, 7.98026790275744]\n",
      "action_list [-2.5475856579269034, -0.15842536389276424]\n",
      "new_action_list [-2.6656813289318118, -0.15385070631941158]\n",
      "time_step:  14\n",
      "reference_tensor:  tensor([-2.0776e+01,  7.9495e+00, -1.5385e-01, -1.9189e+01,  7.9201e+00,\n",
      "        -1.4703e-01, -1.7608e+01,  7.8925e+00, -1.3780e-01, -1.6032e+01,\n",
      "         7.8673e+00, -1.2605e-01, -1.4460e+01,  7.8450e+00, -1.1181e-01,\n",
      "        -1.2893e+01,  7.8259e+00, -9.5205e-02, -1.1330e+01,  7.8105e+00,\n",
      "        -7.7073e-02, -9.7687e+00,  7.7989e+00, -5.7818e-02, -8.2096e+00,\n",
      "         7.7915e+00, -3.7345e-02, -6.6517e+00,  7.7883e+00, -1.5784e-02])\n",
      "decoder_prediction:  tensor([-2.0761e+01,  8.0728e+00, -3.2768e-01, -1.9081e+01,  8.0097e+00,\n",
      "        -2.8556e-01, -1.7498e+01,  7.9845e+00, -2.3743e-01, -1.5876e+01,\n",
      "         7.9604e+00, -1.9190e-01, -1.4304e+01,  7.9491e+00, -1.4252e-01,\n",
      "        -1.2723e+01,  7.9565e+00, -9.7830e-02, -1.1091e+01,  7.9458e+00,\n",
      "        -6.2502e-02, -9.5183e+00,  7.9783e+00, -2.2736e-02, -7.9133e+00,\n",
      "         7.9720e+00,  1.3901e-02, -6.3384e+00,  7.9849e+00,  3.0762e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-32.687512690144864, -20.775796663152455, 2.32150362284357, 7.949497761493558]\n",
      "action_list [-2.6656813289318118, -0.15385070631941158]\n",
      "new_action_list [-2.698428795860926, -0.1470337475892158]\n",
      "time_step:  15\n",
      "reference_tensor:  tensor([-1.9189e+01,  7.9201e+00, -1.4703e-01, -1.7608e+01,  7.8925e+00,\n",
      "        -1.3780e-01, -1.6032e+01,  7.8673e+00, -1.2605e-01, -1.4460e+01,\n",
      "         7.8450e+00, -1.1181e-01, -1.2893e+01,  7.8259e+00, -9.5205e-02,\n",
      "        -1.1330e+01,  7.8105e+00, -7.7073e-02, -9.7687e+00,  7.7989e+00,\n",
      "        -5.7818e-02, -8.2096e+00,  7.7915e+00, -3.7345e-02, -6.6517e+00,\n",
      "         7.7883e+00, -1.5784e-02, -5.0939e+00,  7.7897e+00,  6.7020e-03])\n",
      "decoder_prediction:  tensor([-1.9146e+01,  8.0804e+00, -3.6483e-01, -1.7460e+01,  8.0139e+00,\n",
      "        -3.1683e-01, -1.5877e+01,  7.9818e+00, -2.6211e-01, -1.4257e+01,\n",
      "         7.9539e+00, -2.1026e-01, -1.2685e+01,  7.9417e+00, -1.5431e-01,\n",
      "        -1.1106e+01,  7.9477e+00, -1.0496e-01, -9.4763e+00,  7.9356e+00,\n",
      "        -6.6960e-02, -7.9060e+00,  7.9661e+00, -2.2974e-02, -6.3054e+00,\n",
      "         7.9627e+00,  1.7794e-02, -4.7307e+00,  7.9751e+00,  3.6284e-02],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-32.277180541493365, -19.188837785805525, 1.7818178636713848, 7.920091011975715]\n",
      "action_list [-2.698428795860926, -0.1470337475892158]\n",
      "new_action_list [-2.6831716114929307, -0.13779950815606376]\n",
      "time_step:  16\n",
      "reference_tensor:  tensor([-1.7608e+01,  7.8925e+00, -1.3780e-01, -1.6032e+01,  7.8673e+00,\n",
      "        -1.2605e-01, -1.4460e+01,  7.8450e+00, -1.1181e-01, -1.2893e+01,\n",
      "         7.8259e+00, -9.5205e-02, -1.1330e+01,  7.8105e+00, -7.7073e-02,\n",
      "        -9.7687e+00,  7.7989e+00, -5.7818e-02, -8.2096e+00,  7.7915e+00,\n",
      "        -3.7345e-02, -6.6517e+00,  7.7883e+00, -1.5784e-02, -5.0939e+00,\n",
      "         7.7897e+00,  6.7020e-03, -3.5353e+00,  7.7956e+00,  2.9920e-02])\n",
      "decoder_prediction:  tensor([-17.5285,   8.0843,  -0.3923, -15.8374,   8.0158,  -0.3392, -14.2529,\n",
      "          7.9787,  -0.2791, -12.6372,   7.9481,  -0.2218, -11.0637,   7.9356,\n",
      "         -0.1606,  -9.4874,   7.9406,  -0.1071,  -7.8591,   7.9283,  -0.0668,\n",
      "         -6.2898,   7.9574,  -0.0193,  -4.6927,   7.9572,   0.0247,  -3.1170,\n",
      "          7.9702,   0.0448], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.974480400988952, -17.607575573573506, 1.2451835413727985, 7.892531110344502]\n",
      "action_list [-2.6831716114929307, -0.13779950815606376]\n",
      "new_action_list [-2.610099520332283, -0.12605162171624654]\n",
      "time_step:  17\n",
      "reference_tensor:  tensor([-1.6032e+01,  7.8673e+00, -1.2605e-01, -1.4460e+01,  7.8450e+00,\n",
      "        -1.1181e-01, -1.2893e+01,  7.8259e+00, -9.5205e-02, -1.1330e+01,\n",
      "         7.8105e+00, -7.7073e-02, -9.7687e+00,  7.7989e+00, -5.7818e-02,\n",
      "        -8.2096e+00,  7.7915e+00, -3.7345e-02, -6.6517e+00,  7.7883e+00,\n",
      "        -1.5784e-02, -5.0939e+00,  7.7897e+00,  6.7020e-03, -3.5353e+00,\n",
      "         7.7956e+00,  2.9920e-02, -1.9751e+00,  7.8064e+00,  5.3654e-02])\n",
      "decoder_prediction:  tensor([-16.0873,   8.0498,  -0.3402, -14.4004,   7.9979,  -0.2868, -12.8150,\n",
      "          7.9647,  -0.2279, -11.2121,   7.9410,  -0.1704,  -9.6320,   7.9387,\n",
      "         -0.1084,  -8.0536,   7.9485,  -0.0569,  -6.4293,   7.9451,  -0.0207,\n",
      "         -4.8536,   7.9712,   0.0261,  -3.2581,   7.9865,   0.0682,  -1.6690,\n",
      "          8.0035,   0.0858], grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.777645683121037, -16.031590383938934, 0.7231636373063419, 7.867320786001253]\n",
      "action_list [-2.610099520332283, -0.12605162171624654]\n",
      "new_action_list [-2.4848797138243257, -0.11180730655644099]\n",
      "time_step:  18\n",
      "reference_tensor:  tensor([-1.4460e+01,  7.8450e+00, -1.1181e-01, -1.2893e+01,  7.8259e+00,\n",
      "        -9.5205e-02, -1.1330e+01,  7.8105e+00, -7.7073e-02, -9.7687e+00,\n",
      "         7.7989e+00, -5.7818e-02, -8.2096e+00,  7.7915e+00, -3.7345e-02,\n",
      "        -6.6517e+00,  7.7883e+00, -1.5784e-02, -5.0939e+00,  7.7897e+00,\n",
      "         6.7020e-03, -3.5353e+00,  7.7956e+00,  2.9920e-02, -1.9751e+00,\n",
      "         7.8064e+00,  5.3654e-02, -4.1231e-01,  7.8219e+00,  7.7667e-02])\n",
      "decoder_prediction:  tensor([-1.4620e+01,  8.0162e+00, -2.8415e-01, -1.2937e+01,  7.9807e+00,\n",
      "        -2.3092e-01, -1.1351e+01,  7.9528e+00, -1.7409e-01, -9.7606e+00,\n",
      "         7.9364e+00, -1.1692e-01, -8.1735e+00,  7.9439e+00, -5.5222e-02,\n",
      "        -6.5921e+00,  7.9585e+00, -5.6584e-03, -4.9713e+00,  7.9646e+00,\n",
      "         2.6457e-02, -3.3881e+00,  7.9886e+00,  7.2098e-02, -1.7932e+00,\n",
      "         8.0185e+00,  1.1190e-01, -1.9012e-01,  8.0403e+00,  1.2731e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.682710549936253, -14.46036237286981, 0.22618769454147675, 7.844959324689965]\n",
      "action_list [-2.4848797138243257, -0.11180730655644099]\n",
      "new_action_list [-1.1309384727073837, -0.09520521895631606]\n",
      "time_step:  19\n",
      "reference_tensor:  tensor([-1.2893e+01,  7.8259e+00, -9.5205e-02, -1.1330e+01,  7.8105e+00,\n",
      "        -7.7073e-02, -9.7687e+00,  7.7989e+00, -5.7818e-02, -8.2096e+00,\n",
      "         7.7915e+00, -3.7345e-02, -6.6517e+00,  7.7883e+00, -1.5784e-02,\n",
      "        -5.0939e+00,  7.7897e+00,  6.7020e-03, -3.5353e+00,  7.7956e+00,\n",
      "         2.9920e-02, -1.9751e+00,  7.8064e+00,  5.3654e-02, -4.1231e-01,\n",
      "         7.8219e+00,  7.7667e-02,  1.1541e+00,  7.8422e+00,  1.0171e-01])\n",
      "decoder_prediction:  tensor([-1.3016e+01,  7.8312e+00, -1.6711e-01, -1.1363e+01,  7.8011e+00,\n",
      "        -1.2179e-01, -9.8044e+00,  7.8056e+00, -8.3961e-02, -8.2656e+00,\n",
      "         7.8061e+00, -3.8073e-02, -6.6993e+00,  7.8099e+00,  3.3798e-04,\n",
      "        -5.1388e+00,  7.8274e+00,  4.5919e-02, -3.5403e+00,  7.8532e+00,\n",
      "         8.1792e-02, -1.9653e+00,  7.8991e+00,  1.1767e-01, -3.8738e-01,\n",
      "         7.9162e+00,  1.4320e-01,  1.2041e+00,  7.9647e+00,  1.6497e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -12.89327461231094, 0.0, 7.825918280898701]\n",
      "action_list [-1.1309384727073837, -0.09520521895631606]\n",
      "new_action_list [0.0, -0.07707256116675312]\n",
      "time_step:  20\n",
      "reference_tensor:  tensor([-1.1330e+01,  7.8105e+00, -7.7073e-02, -9.7687e+00,  7.7989e+00,\n",
      "        -5.7818e-02, -8.2096e+00,  7.7915e+00, -3.7345e-02, -6.6517e+00,\n",
      "         7.7883e+00, -1.5784e-02, -5.0939e+00,  7.7897e+00,  6.7020e-03,\n",
      "        -3.5353e+00,  7.7956e+00,  2.9920e-02, -1.9751e+00,  7.8064e+00,\n",
      "         5.3654e-02, -4.1231e-01,  7.8219e+00,  7.7667e-02,  1.1541e+00,\n",
      "         7.8422e+00,  1.0171e-01,  2.7251e+00,  7.8674e+00,  1.2553e-01])\n",
      "decoder_prediction:  tensor([-1.1413e+01,  7.7324e+00, -5.5332e-02, -9.7738e+00,  7.7111e+00,\n",
      "        -1.7563e-02, -8.2257e+00,  7.7432e+00,  3.5745e-03, -6.7196e+00,\n",
      "         7.7593e+00,  3.9445e-02, -5.1563e+00,  7.7622e+00,  5.8143e-02,\n",
      "        -3.6003e+00,  7.7831e+00,  9.9538e-02, -2.0091e+00,  7.8267e+00,\n",
      "         1.3726e-01, -4.2684e-01,  7.8899e+00,  1.6454e-01,  1.1487e+00,\n",
      "         7.8994e+00,  1.7772e-01,  2.7459e+00,  7.9706e+00,  2.0399e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -11.329632407354538, 0.0, 7.810503768665351]\n",
      "action_list [0.0, -0.07707256116675312]\n",
      "new_action_list [0.0, -0.05781847055906422]\n",
      "time_step:  21\n",
      "reference_tensor:  tensor([-9.7687e+00,  7.7989e+00, -5.7818e-02, -8.2096e+00,  7.7915e+00,\n",
      "        -3.7345e-02, -6.6517e+00,  7.7883e+00, -1.5784e-02, -5.0939e+00,\n",
      "         7.7897e+00,  6.7020e-03, -3.5353e+00,  7.7956e+00,  2.9920e-02,\n",
      "        -1.9751e+00,  7.8064e+00,  5.3654e-02, -4.1231e-01,  7.8219e+00,\n",
      "         7.7667e-02,  1.1541e+00,  7.8422e+00,  1.0171e-01,  2.7251e+00,\n",
      "         7.8674e+00,  1.2553e-01,  4.3015e+00,  7.8971e+00,  1.4897e-01])\n",
      "decoder_prediction:  tensor([-9.8429e+00,  7.7065e+00, -1.9098e-03, -8.2066e+00,  7.7040e+00,\n",
      "         3.6779e-02, -6.6554e+00,  7.7391e+00,  5.7656e-02, -5.1600e+00,\n",
      "         7.7618e+00,  9.4383e-02, -3.5878e+00,  7.7770e+00,  1.1516e-01,\n",
      "        -2.0268e+00,  7.8033e+00,  1.5483e-01, -4.3859e-01,  7.8561e+00,\n",
      "         1.8736e-01,  1.1520e+00,  7.9141e+00,  2.1427e-01,  2.7276e+00,\n",
      "         7.9427e+00,  2.2632e-01,  4.3413e+00,  8.0164e+00,  2.4928e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -9.768688023032652, 0.0, 7.7989400745535375]\n",
      "action_list [0.0, -0.05781847055906422]\n",
      "new_action_list [0.0, -0.037344934070224725]\n",
      "time_step:  22\n",
      "reference_tensor:  tensor([-8.2096e+00,  7.7915e+00, -3.7345e-02, -6.6517e+00,  7.7883e+00,\n",
      "        -1.5784e-02, -5.0939e+00,  7.7897e+00,  6.7020e-03, -3.5353e+00,\n",
      "         7.7956e+00,  2.9920e-02, -1.9751e+00,  7.8064e+00,  5.3654e-02,\n",
      "        -4.1231e-01,  7.8219e+00,  7.7667e-02,  1.1541e+00,  7.8422e+00,\n",
      "         1.0171e-01,  2.7251e+00,  7.8674e+00,  1.2553e-01,  4.3015e+00,\n",
      "         7.8971e+00,  1.4897e-01,  5.8844e+00,  7.9315e+00,  1.7198e-01])\n",
      "decoder_prediction:  tensor([-8.2512,  7.6527,  0.0500, -6.6235,  7.6684,  0.0902, -5.0748,  7.7068,\n",
      "         0.1111, -3.5959,  7.7358,  0.1490, -2.0208,  7.7636,  0.1721, -0.4598,\n",
      "         7.7954,  0.2104,  1.1198,  7.8577,  0.2378,  2.7128,  7.9104,  0.2644,\n",
      "         4.2832,  7.9583,  0.2754,  5.9078,  8.0346,  0.2952],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -8.20964690680335, 0.0, 7.791471087739493]\n",
      "action_list [0.0, -0.037344934070224725]\n",
      "new_action_list [0.0, -0.01578373295225688]\n",
      "time_step:  23\n",
      "reference_tensor:  tensor([-6.6517e+00,  7.7883e+00, -1.5784e-02, -5.0939e+00,  7.7897e+00,\n",
      "         6.7020e-03, -3.5353e+00,  7.7956e+00,  2.9920e-02, -1.9751e+00,\n",
      "         7.8064e+00,  5.3654e-02, -4.1231e-01,  7.8219e+00,  7.7667e-02,\n",
      "         1.1541e+00,  7.8422e+00,  1.0171e-01,  2.7251e+00,  7.8674e+00,\n",
      "         1.2553e-01,  4.3015e+00,  7.8971e+00,  1.4897e-01,  5.8844e+00,\n",
      "         7.9315e+00,  1.7198e-01,  7.4746e+00,  7.9705e+00,  1.9457e-01])\n",
      "decoder_prediction:  tensor([-6.6308,  7.6063,  0.1036, -5.0104,  7.6408,  0.1453, -3.4626,  7.6827,\n",
      "         0.1660, -1.9988,  7.7180,  0.2050, -0.4191,  7.7586,  0.2302,  1.1439,\n",
      "         7.7962,  0.2671,  2.7164,  7.8681,  0.2892,  4.3136,  7.9152,  0.3156,\n",
      "         5.8805,  7.9830,  0.3254,  7.5178,  8.0616,  0.3419],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -6.651668363914496, 0.0, 7.788314341149041]\n",
      "action_list [0.0, -0.01578373295225688]\n",
      "new_action_list [0.0, 0.006702016592429051]\n",
      "time_step:  24\n",
      "reference_tensor:  tensor([-5.0939e+00,  7.7897e+00,  6.7020e-03, -3.5353e+00,  7.7956e+00,\n",
      "         2.9920e-02, -1.9751e+00,  7.8064e+00,  5.3654e-02, -4.1231e-01,\n",
      "         7.8219e+00,  7.7667e-02,  1.1541e+00,  7.8422e+00,  1.0171e-01,\n",
      "         2.7251e+00,  7.8674e+00,  1.2553e-01,  4.3015e+00,  7.8971e+00,\n",
      "         1.4897e-01,  5.8844e+00,  7.9315e+00,  1.7198e-01,  7.4746e+00,\n",
      "         7.9705e+00,  1.9457e-01,  9.0730e+00,  8.0138e+00,  2.1677e-01])\n",
      "decoder_prediction:  tensor([-4.9812,  7.5648,  0.1586, -3.3675,  7.6183,  0.2020, -1.8194,  7.6642,\n",
      "         0.2223, -0.3697,  7.7058,  0.2623,  1.2156,  7.7596,  0.2895,  2.7822,\n",
      "         7.8030,  0.3250,  4.3485,  7.8849,  0.3416,  5.9511,  7.9261,  0.3676,\n",
      "         7.5157,  8.0141,  0.3762,  9.1671,  8.0950,  0.3893],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -5.09387145535284, 0.0, 7.789654744467527]\n",
      "action_list [0.0, 0.006702016592429051]\n",
      "new_action_list [0.0, 0.02992026766209438]\n",
      "time_step:  25\n",
      "reference_tensor:  tensor([-3.5353,  7.7956,  0.0299, -1.9751,  7.8064,  0.0537, -0.4123,  7.8219,\n",
      "         0.0777,  1.1541,  7.8422,  0.1017,  2.7251,  7.8674,  0.1255,  4.3015,\n",
      "         7.8971,  0.1490,  5.8844,  7.9315,  0.1720,  7.4746,  7.9705,  0.1946,\n",
      "         9.0730,  8.0138,  0.2168, 10.6805,  8.0615,  0.2386])\n",
      "decoder_prediction:  tensor([-3.3504,  7.5710,  0.1477, -1.7728,  7.6171,  0.2022, -0.2344,  7.6734,\n",
      "         0.2293,  1.2398,  7.7053,  0.2647,  2.7971,  7.7721,  0.2937,  4.3929,\n",
      "         7.8240,  0.3346,  5.9538,  7.9085,  0.3552,  7.5459,  7.9330,  0.3730,\n",
      "         9.1367,  8.0395,  0.3821, 10.7677,  8.1025,  0.3934],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -3.535342101106096, 0.0, 7.795638797999946]\n",
      "action_list [0.0, 0.02992026766209438]\n",
      "new_action_list [0.0, 0.05365402819173171]\n",
      "time_step:  26\n",
      "reference_tensor:  tensor([-1.9751,  7.8064,  0.0537, -0.4123,  7.8219,  0.0777,  1.1541,  7.8422,\n",
      "         0.1017,  2.7251,  7.8674,  0.1255,  4.3015,  7.8971,  0.1490,  5.8844,\n",
      "         7.9315,  0.1720,  7.4746,  7.9705,  0.1946,  9.0730,  8.0138,  0.2168,\n",
      "        10.6805,  8.0615,  0.2386, 12.2980,  8.1135,  0.2600])\n",
      "decoder_prediction:  tensor([-1.7715e+00,  7.7130e+00,  1.1619e-02, -2.5249e-01,  7.7120e+00,\n",
      "         8.2466e-02,  1.2725e+00,  7.7694e+00,  1.3320e-01,  2.8450e+00,\n",
      "         7.7800e+00,  1.5576e-01,  4.3463e+00,  7.8451e+00,  1.9538e-01,\n",
      "         5.9899e+00,  7.9066e+00,  2.4318e-01,  7.5658e+00,  7.9734e+00,\n",
      "         2.9076e-01,  9.1374e+00,  7.9798e+00,  2.8990e-01,  1.0804e+01,\n",
      "         8.0862e+00,  2.9953e-01,  1.2368e+01,  8.1117e+00,  3.1271e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -1.975141260942273, 0.0, 7.806369603638292]\n",
      "action_list [0.0, 0.05365402819173171]\n",
      "new_action_list [0.0, 0.07766683428957757]\n",
      "time_step:  27\n",
      "reference_tensor:  tensor([-0.4123,  7.8219,  0.0777,  1.1541,  7.8422,  0.1017,  2.7251,  7.8674,\n",
      "         0.1255,  4.3015,  7.8971,  0.1490,  5.8844,  7.9315,  0.1720,  7.4746,\n",
      "         7.9705,  0.1946,  9.0730,  8.0138,  0.2168, 10.6805,  8.0615,  0.2386,\n",
      "        12.2980,  8.1135,  0.2600, 13.9264,  8.1698,  0.2811])\n",
      "decoder_prediction:  tensor([-0.2188,  7.7846, -0.0363,  1.2787,  7.7679,  0.0343,  2.8041,  7.8207,\n",
      "         0.0957,  4.4291,  7.8364,  0.1146,  5.9215,  7.8948,  0.1618,  7.5680,\n",
      "         7.9622,  0.2016,  9.1632,  8.0191,  0.2574, 10.7337,  8.0353,  0.2502,\n",
      "        12.4341,  8.1289,  0.2550, 13.9767,  8.1490,  0.2665],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, -0.4123140035288202, 0.0, 7.8219029704962075]\n",
      "action_list [0.0, 0.07766683428957757]\n",
      "new_action_list [0.0, 0.10170948155338846]\n",
      "time_step:  28\n",
      "reference_tensor:  tensor([ 1.1541,  7.8422,  0.1017,  2.7251,  7.8674,  0.1255,  4.3015,  7.8971,\n",
      "         0.1490,  5.8844,  7.9315,  0.1720,  7.4746,  7.9705,  0.1946,  9.0730,\n",
      "         8.0138,  0.2168, 10.6805,  8.0615,  0.2386, 12.2980,  8.1135,  0.2600,\n",
      "        13.9264,  8.1698,  0.2811, 15.5664,  8.2301,  0.3018])\n",
      "decoder_prediction:  tensor([ 1.3506,  7.8086, -0.0327,  2.8396,  7.7915,  0.0317,  4.3705,  7.8424,\n",
      "         0.0952,  6.0225,  7.8735,  0.1153,  7.5244,  7.9265,  0.1656,  9.1575,\n",
      "         7.9987,  0.1919, 10.7701,  8.0521,  0.2436, 12.3465,  8.0887,  0.2358,\n",
      "        14.0590,  8.1666,  0.2336, 15.6035,  8.1947,  0.2411],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n",
      "observation_list [-31.660091780482105, 1.1541007802014889, 0.0, 7.842244866806885]\n",
      "action_list [0.0, 0.10170948155338846]\n",
      "new_action_list [0.4512887346963086, 0.12552765818445005]\n",
      "time_step:  29\n",
      "reference_tensor:  tensor([ 2.7251,  7.8674,  0.1255,  4.3015,  7.8971,  0.1490,  5.8844,  7.9315,\n",
      "         0.1720,  7.4746,  7.9705,  0.1946,  9.0730,  8.0138,  0.2168, 10.6805,\n",
      "         8.0615,  0.2386, 12.2980,  8.1135,  0.2600, 13.9264,  8.1698,  0.2811,\n",
      "        15.5664,  8.2301,  0.3018, 17.2188,  8.2945,  0.3221])\n",
      "decoder_prediction:  tensor([ 3.0158e+00,  7.8401e+00, -1.2962e-02,  4.4888e+00,  7.8137e+00,\n",
      "         4.4484e-02,  6.0234e+00,  7.8768e+00,  1.0390e-01,  7.7075e+00,\n",
      "         7.9224e+00,  1.1917e-01,  9.2112e+00,  7.9667e+00,  1.6247e-01,\n",
      "         1.0842e+01,  8.0441e+00,  1.7619e-01,  1.2476e+01,  8.0972e+00,\n",
      "         2.2718e-01,  1.4059e+01,  8.1590e+00,  2.1349e-01,  1.5796e+01,\n",
      "         8.2124e+00,  1.9991e-01,  1.7337e+01,  8.2508e+00,  2.0651e-01],\n",
      "       grad_fn=<AddBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the network\n",
    "\n",
    "####### Load the neural network weights from saved models #######\n",
    "\n",
    "loaded_network=NN_structure(n_epochs,min_timesteps,n_rollout,n_skips_per_rollout,n_test,n_input,n_output,n_state_enc,learning_rate,gen_model,pred_model,device)\n",
    "loaded_network.load_model_weights(\"encoder_rnn_decoder_simple_nn_n_rollout_n_skips_MSELOSS_action_t_included_for_results\")\n",
    "\n",
    "\n",
    "#test_keys=[keys_for_testing[15]]\n",
    "\n",
    "test_results=loaded_network.test(76)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
