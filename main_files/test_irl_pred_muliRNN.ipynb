{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy.linalg as LA\n",
    "import random\n",
    "import pandas as pd\n",
    "from numpy import inf\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "import pyprind\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('data_irl_model/Feb23_data_exploratory_policy.json')\n",
    "f = open('data_irl_model/Feb22_dataSVO.json')\n",
    "data_irl = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keys=list(data_irl.keys())\n",
    "data_keys.sort()\n",
    "\n",
    "keys_for_training=[]\n",
    "keys_for_testing=[]\n",
    "\n",
    "index=0\n",
    "for vehicle in data_keys:\n",
    "    if index%10==0:\n",
    "        keys_for_testing.append(vehicle)\n",
    "        index+=1\n",
    "    else:\n",
    "        keys_for_training.append(vehicle)\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_irl[str(keys_for_testing[10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 1) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15496/2861230755.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput_tens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_irl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys_for_testing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#.to_device(self.device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_irl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys_for_testing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_irl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeys_for_testing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 1) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "time_step=5\n",
    "[data_irl[str(keys_for_testing[0])][0],data_irl[str(keys_for_testing[0])][1]]#[:][time_step]\n",
    "\n",
    "input_tens=torch.empty(len(data_irl[str(keys_for_testing[0])]),dtype=torch.float)#.to_device(self.device)\n",
    "for i in range(len(data_irl[str(keys_for_testing[0])])):\n",
    "    torch.cat((input_tens,torch.tensor(data_irl[str(keys_for_testing[0])][i][time_step])))\n",
    "\n",
    "print(input_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nish\\AppData\\Local\\Temp/ipykernel_15496/2787279764.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  float_arr = np.vstack(a123[:, time_step]).astype(np.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-41.2827],\n",
       "        [-48.9769],\n",
       "        [  8.9757],\n",
       "        [  6.6194],\n",
       "        [  1.1115],\n",
       "        [ -1.5041]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a123=np.array(data_irl[str(keys_for_testing[0])])\n",
    "float_arr = np.vstack(a123[:, :]).astype(np.float)\n",
    "#float_arr = np.vstack(a123[:, time_step]).astype(np.float)\n",
    "#input=torch.tensor(float_arr,dtype=torch.float)\n",
    "#input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################################ AIS_gen ################################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class GenerateAis1(nn.Module):\n",
    "\n",
    "    #def __init__(self,n_input,n_state,n_psi2_in=64,n_psi2_out=128):\n",
    "    def __init__(self,n_input,n_state,n_psi2_in=8,n_psi2_out=16):\n",
    "        super(GenerateAis1,self).__init__()\n",
    "        self.PSI_layer1=nn.Linear(n_input,n_psi2_in)     # Use RELU after\n",
    "        self.PSI_layer2=nn.Linear(n_psi2_in,n_psi2_out)      # Use RELU after\n",
    "        self.PSI_layer3=nn.GRUCell(n_psi2_out,n_state)       # This is the Gated layer\n",
    "\n",
    "    def forward(self,x,h):\n",
    "        #x=torch.transpose(x,0,1)\n",
    "        #h=torch.transpose(h,0,1)\n",
    "        x=torch.relu(self.PSI_layer1(x))\n",
    "        x=torch.relu(self.PSI_layer2(x))\n",
    "        h=self.PSI_layer3(x,h)\n",
    "        return h \n",
    "    \n",
    "################################ Model 2 ################################ \n",
    "\n",
    "class GenerateAis2(nn.Module):\n",
    "\n",
    "    #def __init__(self,n_input,n_state,n_psi2_in=64,n_psi2_out=128):\n",
    "    def __init__(self,n_input,n_state_enc,n_psi1_out=8):\n",
    "        super(GenerateAis2,self).__init__()\n",
    "        self.PSI_layer1=nn.Linear(n_input,n_psi1_out)     # Use RELU after\n",
    "        self.PSI_layer2=nn.GRUCell(n_psi1_out,n_state_enc)       # This is the Gated layer\n",
    "\n",
    "    def forward(self,x,h):\n",
    "        #x=torch.transpose(x,0,1)\n",
    "        #h=torch.transpose(h,0,1)\n",
    "        x=torch.relu(self.PSI_layer1(x))\n",
    "        h=self.PSI_layer2(x,h)\n",
    "        return h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################################ AIS_pred ###############################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class PredictAis1(nn.Module):\n",
    "    \n",
    "    #def __init__(self,n_output,n_state,n_phi2_in=16,n_phi2_out=8):\n",
    "    def __init__(self,n_output,n_state,n_phi2_in=32,n_phi2_out=64):\n",
    "        super(PredictAis1,self).__init__()\n",
    "        self.PHI_layer1=nn.Linear(n_state,n_phi2_in)  # Use RELU after\n",
    "        self.PHI_layer2=nn.Linear(n_phi2_in,n_phi2_out)     # Use RELU after\n",
    "        self.PHI_layer3=nn.Linear(n_phi2_out,n_output)         # mean vector of a unit-variance multivariate Gaussian distribution, samples from which are used to predict the next observation\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.PHI_layer1(x))\n",
    "        x=torch.relu(self.PHI_layer2(x))\n",
    "        output=self.PHI_layer3(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "################################ Model 2 - RNN based ################################ \n",
    "\n",
    "class PredictAis2(nn.Module):\n",
    "    \n",
    "    #def __init__(self,n_output,n_state,n_phi2_in=16,n_phi2_out=8):\n",
    "    def __init__(self,n_output,n_input_dec,n_state_dec):\n",
    "        super(PredictAis2,self).__init__()\n",
    "        #self.PHI_layer1=nn.Linear(n_output,n_state_enc)  # Use RELU after\n",
    "        self.PHI_layer2=nn.GRUCell(n_input_dec,n_state_dec)       # This is the Gated layer - n_state_enc+1 for time step as input\n",
    "        self.PHI_layer3=nn.Linear(n_state_dec,n_output)         # mean vector of a unit-variance multivariate Gaussian distribution, samples from which are used to predict the next observation\n",
    "\n",
    "    def forward(self,x,h):        \n",
    "        #x=self.PHI_layer1(x)   \n",
    "        h=self.PHI_layer2(x,h)\n",
    "        output=self.PHI_layer3(h)\n",
    "        return output,h\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_structure(object):\n",
    "    def __init__(self,n_epochs,min_timesteps,n_rollout,n_test,n_input,n_output,n_state_enc,n_state_dec,learning_rate,ais_gen_model,ais_pred_model,device):\n",
    "        self.n_epochs=n_epochs\n",
    "        self.min_timesteps=min_timesteps\n",
    "        self.rollout=n_rollout\n",
    "        self.n_test=n_test\n",
    "        self.n_input=n_input\n",
    "        self.n_output=n_output\n",
    "        self.n_state_enc=n_state_enc    # Hidden state size in RNN\n",
    "        self.n_state_dec=n_state_dec\n",
    "        self.learning_rate=learning_rate                \n",
    "        self.device=device\n",
    "        self.ais_gen_model=ais_gen_model\n",
    "        self.ais_pred_model=ais_pred_model\n",
    "\n",
    "        self.n_psi2_in=8\n",
    "        self.n_psi2_out=16\n",
    "        self.n_phi2_in=32\n",
    "        self.n_phi2_out=64\n",
    "        self.n_psi1_out=8\n",
    "        \n",
    "        if ais_gen_model==1:\n",
    "            self.gen_model=GenerateAis1(self.n_input,self.n_state_enc,self.n_psi2_in,self.n_psi2_out).to(self.device)      \n",
    "        \n",
    "        if ais_gen_model==2: \n",
    "            self.gen_model=GenerateAis2(self.n_input,self.n_state_enc,self.n_psi1_out).to(self.device)  \n",
    "        \n",
    "        if ais_pred_model==1:\n",
    "            self.pred_model=PredictAis1(self.n_output,self.n_state_enc,self.n_phi2_in,self.n_phi2_out).to(self.device)\n",
    "        \n",
    "        if ais_pred_model==2:\n",
    "            self.pred_model=PredictAis2(self.n_output,self.n_state_enc+1,self.n_state_dec).to(self.device)\n",
    "\n",
    "    def save_model_weights(self,text=\"_\"):\n",
    "        #name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "        #torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        \n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        if self.ais_pred_model==1:\n",
    "            name_pred_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "            name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "\n",
    "        if self.ais_pred_model==2:\n",
    "            name_pred_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "            name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "\n",
    "        torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "\n",
    "        return \"saved\"\n",
    "    \n",
    "    def load_model_weights(self,text=\"_\"):\n",
    "        #name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "        #torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        #self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        #self.gen_model.eval()\n",
    "\n",
    "        name_gen_path=\"_\"\n",
    "        name_pred_path=\"_\"\n",
    "        \n",
    "        if self.ais_pred_model==1:\n",
    "            name_pred_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "            name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+text+\".pth\"\n",
    "\n",
    "        if self.ais_pred_model==2:\n",
    "            name_pred_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "            name_gen_path=\"trained_models/IRL_based_models/IRL_SVOpolicy_multi_rnn_ais_gen\"+str(self.ais_gen_model)+\"_\"+str(self.n_psi2_in)+str(self.n_psi2_out)+\"_pred\"+str(self.ais_pred_model)+\"_\"+str(self.n_phi2_in)+str(self.n_phi2_out)+\"_epochs\"+str(self.n_epochs)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state_enc)+\"_\"+str(self.n_state_dec)+text+\".pth\"\n",
    "        \n",
    "        #torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "        self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        self.gen_model.eval()\n",
    "\n",
    "        self.pred_model.load_state_dict(torch.load(name_pred_path))\n",
    "        self.pred_model.eval()\n",
    "\n",
    "        return \"loaded\"\n",
    "    \n",
    "\n",
    "    def train(self):\n",
    "        train_bar=pyprind.ProgBar(self.n_epochs)\n",
    "        #self.optimizer_enc = torch.optim.Adam(list(self.gen_model.parameters()) + list(self.pred_model.parameters()), lr=self.learning_rate, amsgrad=True)\n",
    "        #self.optimizer_dec = torch.optim.Adam(list(self.pred_model.parameters()), lr=self.learning_rate, amsgrad=True)\n",
    "        self.optimizer = torch.optim.Adam(list(self.gen_model.parameters()) + list(self.pred_model.parameters()), lr=self.learning_rate, amsgrad=True)\n",
    "        self.loss=nn.MSELoss()\n",
    "        self.loss_train=[]\n",
    "        self.loss_train.append(0)\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "\n",
    "            train_bar.update()\n",
    "            keys_training=sample(keys_for_training,len(keys_for_training)) #shuffle the keys\n",
    "            #train_bar=pyprind.ProgBar(len(keys_for_training))\n",
    "\n",
    "            for key in keys_training:\n",
    "                #train_bar.update()\n",
    "                key=str(key)\n",
    "                key_loss=0\n",
    "                ############# Create the data for the training locally- we are restricting the number of timesteps to num_timesteps######\n",
    "                negative_vals=[]\n",
    "                for i in [0,1]:\n",
    "                    negative_vals.append(list(filter(lambda x: x < 1, data_irl[key][i])))\n",
    "                num_timesteps=min(self.min_timesteps,len(negative_vals[0]),len(negative_vals[1]))\n",
    "\n",
    "                # Ais initialization\n",
    "                time_step_loss=0\n",
    "\n",
    "                ais=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device)\n",
    "\n",
    "                action_list=[0,0] ## initialize the action list differently ?????                \n",
    "\n",
    "                #for time_step in range(len(data_irl[key][0])-1):\n",
    "                    \n",
    "                for time_step in range(num_timesteps):                    \n",
    "                    observation_list=[]\n",
    "                    for i in range(len(data_irl[key])-2): # exclude the last two columns (actions/inputs)\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if temp!= None:\n",
    "                            observation_list.append(temp)\n",
    "                        \n",
    "                    input_list=[]\n",
    "                    input_list.extend(observation_list)\n",
    "                    input_list.extend(action_list)\n",
    "                    input_tensor=torch.tensor(input_list,dtype=torch.float).to(self.device)\n",
    "                    '''\n",
    "                    print(\"\\n\")\n",
    "                    print(\"Before rollout, the input is \",input_tensor)\n",
    "                    '''\n",
    "\n",
    "                    # Update action list for the next time step and for the reference\n",
    "                    for i in [4,5]:\n",
    "                        temp=data_irl[key][i][time_step]\n",
    "                        if temp!= None:\n",
    "                            action_list[i-4]=temp\n",
    "                        else:\n",
    "                            action_list[i-4]=0\n",
    "\n",
    "                    reference_list=[]\n",
    "                    observation_list_ref=[]\n",
    "                    for i in [1,3]:#range(len(data_irl[key])-2): # exclude the last two columns (actions/inputs)\n",
    "                        temp=data_irl[key][i][time_step+1]\n",
    "                        if temp!= None:\n",
    "                            observation_list_ref.append(temp)                      \n",
    "                    reference_list.extend(observation_list_ref)\n",
    "                    '''\n",
    "                    print(action_list)\n",
    "                    '''\n",
    "                    reference_list.extend([action_list[1]])\n",
    "   \n",
    "                    reference_tensor=torch.tensor(reference_list,dtype=torch.float).to(self.device)\n",
    "                    '''\n",
    "                    print(\"Before rollout, the reference is \",reference_tensor)\n",
    "                    '''\n",
    "                    #############################\n",
    "                    # Setting things up for the rollout\n",
    "                    ais_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device) # Just initialize it to 0.5\n",
    "                    ais_rollout_dec=0.5*torch.ones(self.n_state_dec,dtype=torch.float).to(self.device) # Just initialize it to 0.5                   \n",
    "\n",
    "\n",
    "                    rollout_prediction=0.5*torch.ones(self.n_output,dtype=torch.float).to(self.device)\n",
    "\n",
    "\n",
    "                    internal_rollout_horizon=min(self.rollout,len(data_irl[key][0])-time_step-2)\n",
    "                    rollout_loss=0\n",
    "                    # Rollout the rnn only for 10 more time steps from time_step to time_step+rollout_horizon\n",
    "                    \n",
    "                    for k in range(internal_rollout_horizon):\n",
    "                        rollout_reference_list=[]\n",
    "\n",
    "                        if k==0:\n",
    "                            rollout_input=input_tensor\n",
    "                            rollout_reference=reference_tensor\n",
    "                            '''\n",
    "                            print(\"for rollout\",k,\"rollout_reference is \",rollout_reference)\n",
    "                            '''\n",
    "                            ais_rollout_enc=ais\n",
    "                            ais_rollout_enc=self.gen_model(rollout_input,ais_rollout_enc)\n",
    "                            ais=ais_rollout_enc\n",
    "                            \n",
    "                            #decoder_input=list(ais_rollout_enc.detach().cpu().numpy())\n",
    "                            #decoder_input.extend([time_step+k])\n",
    "                            #decoder_input_tensor=torch.tensor(decoder_input,dtype=torch.float).to(self.device)\n",
    "\n",
    "                            time_step_tensor=torch.tensor([time_step+k],dtype=torch.float).to(self.device)\n",
    "                            decoder_input_tensor=torch.cat((ais_rollout_enc,time_step_tensor),0)\n",
    "\n",
    "                            rollout_prediction,ais_rollout_dec=self.pred_model(decoder_input_tensor,ais_rollout_dec)\n",
    "                            '''\n",
    "                            print(\"for rollout\",k,\"decoder_input  is \",decoder_input_tensor)\n",
    "                            print(\"for rollout\",k,\"rollout_prediction is \",rollout_prediction)\n",
    "                            '''\n",
    "\n",
    "                            rollout_loss+=-torch.distributions.MultivariateNormal(rollout_prediction,torch.eye(rollout_prediction.shape[0]).to(self.device)).log_prob(rollout_reference)\n",
    "\n",
    "                            #key_loss+=-torch.distributions.MultivariateNormal(rollout_prediction,torch.eye(rollout_prediction.shape[0]).to(self.device)).log_prob(rollout_reference)\n",
    "\n",
    "                        else:                           \n",
    "                            for i in [1,3,5]:#range(len(data_irl[key])):\n",
    "                                if i<4:\n",
    "                                    rollout_reference_list.append(data_irl[key][i][time_step+k+1])\n",
    "                                elif i>=4 and data_irl[key][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                    rollout_reference_list.append(data_irl[key][i][time_step+k])\n",
    "                                else:\n",
    "                                    rollout_reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                            rollout_reference=torch.tensor(rollout_reference_list,dtype=torch.float).to(self.device)\n",
    "                            '''\n",
    "                            print(\"for rollout\",k,\"rollout_reference is \",rollout_reference)\n",
    "                            '''\n",
    "\n",
    "                            #decoder_input=list(ais_rollout_enc.detach().cpu().numpy())\n",
    "                            #decoder_input.extend([time_step+k])\n",
    "                            #decoder_input_tensor=torch.tensor(decoder_input,dtype=torch.float).to(self.device)\n",
    "\n",
    "                            time_step_tensor=torch.tensor([time_step+k],dtype=torch.float).to(self.device)\n",
    "                            decoder_input_tensor=torch.cat((ais_rollout_enc,time_step_tensor),0)\n",
    "\n",
    "                            rollout_prediction,ais_rollout_dec=self.pred_model(decoder_input_tensor,ais_rollout_dec)\n",
    "                            '''\n",
    "                            print(\"for rollout\",k,\"decoder_input  is \",decoder_input_tensor)\n",
    "                            print(\"for rollout\",k,\"rollout_prediction is \",rollout_prediction)\n",
    "                            '''\n",
    "\n",
    "                            rollout_loss+=-torch.distributions.MultivariateNormal(rollout_prediction,torch.eye(rollout_prediction.shape[0]).to(self.device)).log_prob(rollout_reference)\n",
    "\n",
    "                    '''\n",
    "                    self.optimizer_dec.zero_grad()\n",
    "                    rollout_loss.backward()\n",
    "                    self.optimizer_dec.step()\n",
    "                    '''\n",
    "                    time_step_loss+=rollout_loss\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                time_step_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                #self.optimizer_enc.zero_grad()\n",
    "                #key_loss.backward()\n",
    "                #self.optimizer_enc.step()\n",
    "                #print(\"saving model weights\")\n",
    "                #status=self.save_model_weights(\"Rollout_10\")               \n",
    "            print(\"saving model weights for epoch \",epoch)\n",
    "            status=self.save_model_weights(\"reduced_timesteps10_Rollout_5_added_time_step_to_decoder_input\")\n",
    "\n",
    "\n",
    "\n",
    "    def test(self,test_keys):\n",
    "        test_bar=pyprind.ProgBar(len(test_keys))\n",
    "        self.comparision_list=[]\n",
    "        #self.load_model_weights(\"Rollout_10\")\n",
    "        #print(\"loaded model weights\")\n",
    "            \n",
    "        self.test_run_comparision=[]\n",
    "        for test_run in range(len(test_keys)):\n",
    "            test_bar.update()\n",
    "            key_test=str(test_keys[test_run])\n",
    "        \n",
    "            \n",
    "            ############# locally restrict the data for the training - we are restricting the number of timesteps to num_timesteps######\n",
    "            negative_vals=[]\n",
    "            for i in [0,1]:\n",
    "                negative_vals.append(list(filter(lambda x: x < 1, data_irl[key_test][i])))\n",
    "\n",
    "            num_timesteps=min(self.min_timesteps,len(negative_vals[0]),len(negative_vals[1]))\n",
    "            \n",
    "            # Ais initialization\n",
    "            time_step_loss=0\n",
    "            ais=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device)\n",
    "            action_list=[0,0]             \n",
    "\n",
    "            time_step_comparision=[]\n",
    "            for time_step in range(num_timesteps):                    \n",
    "                observation_list=[]\n",
    "                for i in range(len(data_irl[key_test])-2): # exclude the last two columns (actions/inputs)\n",
    "                    temp=data_irl[key_test][i][time_step]\n",
    "                    if temp!= None:\n",
    "                        observation_list.append(temp)\n",
    "                    \n",
    "                input_list=[]\n",
    "                input_list.extend(observation_list)\n",
    "                input_list.extend(action_list)\n",
    "                input_tensor=torch.tensor(input_list,dtype=torch.float).to(self.device)\n",
    "                print(\"\\n\")\n",
    "                print(\"Before rollout, the input is \",input_tensor)\n",
    "                # Update action list for the next time step and for the reference\n",
    "                for i in [4,5]:\n",
    "                    temp=data_irl[key_test][i][time_step]\n",
    "                    if temp!= None:\n",
    "                        action_list[i-4]=temp\n",
    "                    else:\n",
    "                        action_list[i-4]=0\n",
    "\n",
    "                reference_list=[]\n",
    "                observation_list_ref=[]\n",
    "                for i in [1,3]:#range(len(data_irl[key_test])-2): # exclude the last two columns (actions/inputs)\n",
    "                    temp=data_irl[key_test][i][time_step+1]\n",
    "                    if temp!= None:\n",
    "                        observation_list_ref.append(temp)                      \n",
    "                reference_list.extend(observation_list_ref)\n",
    "                reference_list.extend([action_list[1]])\n",
    "\n",
    "                reference_tensor=torch.tensor(reference_list,dtype=torch.float).to(self.device)\n",
    "\n",
    "                ais_rollout_enc=0.5*torch.ones(self.n_state_enc,dtype=torch.float).to(self.device) # Just initialize it to 0.5\n",
    "                ais_rollout_dec=0.5*torch.ones(self.n_state_dec,dtype=torch.float).to(self.device) # Just initialize it to 0.5\n",
    "\n",
    "\n",
    "                rollout_reference=0.5*torch.ones(self.n_output,dtype=torch.float).to(self.device)\n",
    "\n",
    "                rollout_prediction=0.5*torch.ones(self.n_output,dtype=torch.float).to(self.device)\n",
    "\n",
    "                internal_rollout_horizon=min(self.rollout,len(data_irl[key_test][0])-time_step-2)\n",
    "                rollout_loss=0\n",
    "\n",
    "                rollout_comparison=[]\n",
    "                for k in range(internal_rollout_horizon):\n",
    "                    temp_comparision=[]\n",
    "                    \n",
    "                    #print(\"\\n\")\n",
    "                    if k==0:\n",
    "                        rollout_input=input_tensor\n",
    "                        rollout_reference=reference_tensor\n",
    "                        ais_rollout_enc=ais\n",
    "                        ais_rollout_enc=self.gen_model(rollout_input,ais_rollout_enc)\n",
    "                        ais=ais_rollout_enc\n",
    "                        \n",
    "                        #decoder_input=list(ais_rollout_enc.detach().cpu().numpy())\n",
    "                        #decoder_input.extend([time_step+k])\n",
    "                        #decoder_input_tensor=torch.tensor(decoder_input,dtype=torch.float).to(self.device)\n",
    "                        \n",
    "                        time_step_tensor=torch.tensor([time_step+k],dtype=torch.float).to(self.device)\n",
    "                        decoder_input_tensor=torch.cat((ais_rollout_enc,time_step_tensor),0)\n",
    "                        rollout_prediction,ais_rollout_dec=self.pred_model(decoder_input_tensor,ais_rollout_dec)\n",
    "                        \n",
    "                        print(\"for rollout\",k,\"rollout_reference is \",rollout_reference)\n",
    "                        print(\"for rollout\",k,\"decoder_input  is \",decoder_input_tensor,time_step+k)\n",
    "                        print(\"for rollout\",k,\"rollout_prediction is \",rollout_prediction)\n",
    "                        \n",
    "                        rollout_loss+=-torch.distributions.MultivariateNormal(rollout_prediction,torch.eye(rollout_prediction.shape[0]).to(self.device)).log_prob(rollout_reference)\n",
    "\n",
    "                        temp_comparision.extend(rollout_reference.detach().cpu().numpy())\n",
    "                        temp_comparision.extend(rollout_prediction.detach().cpu().numpy())\n",
    "\n",
    "                    else:\n",
    "                        rollout_reference_list=[]                           \n",
    "                        for i in [1,3,5]:#range(len(data_irl[key_test])):\n",
    "                            if i<4:\n",
    "                                rollout_reference_list.append(data_irl[key_test][i][time_step+k+1])\n",
    "                            elif i>=4 and data_irl[key_test][i][time_step+k]!=None: # Previous action is observed at time_step+k+1\n",
    "                                rollout_reference_list.append(data_irl[key_test][i][time_step+k])\n",
    "                            else:\n",
    "                                rollout_reference_list.append(0) # Zero padding for the input action\n",
    "\n",
    "                        rollout_reference=torch.tensor(rollout_reference_list,dtype=torch.float).to(self.device)\n",
    "\n",
    "                        \n",
    "                        #decoder_input=list(ais_rollout_enc.detach().cpu().numpy())\n",
    "                        #decoder_input.extend([time_step+k])\n",
    "                        #decoder_input_tensor=torch.tensor(decoder_input,dtype=torch.float).to(self.device)\n",
    "\n",
    "                        time_step_tensor=torch.tensor([time_step+k],dtype=torch.float).to(self.device)\n",
    "                        decoder_input_tensor=torch.cat((ais_rollout_enc,time_step_tensor),0)\n",
    "                        rollout_prediction,ais_rollout_dec=self.pred_model(decoder_input_tensor,ais_rollout_dec)                                                \n",
    "                        \n",
    "                        print(\"for rollout\",k,\"rollout_reference is \",rollout_reference)\n",
    "                        print(\"for rollout\",k,\"decoder_input  is \",decoder_input_tensor,time_step+k)\n",
    "                        print(\"for rollout\",k,\"rollout_prediction is \",rollout_prediction)\n",
    "\n",
    "                        temp_comparision.extend(rollout_reference.detach().cpu().numpy())\n",
    "                        temp_comparision.extend(rollout_prediction.detach().cpu().numpy())\n",
    "\n",
    "                        rollout_loss+=-torch.distributions.MultivariateNormal(rollout_prediction,torch.eye(rollout_prediction.shape[0]).to(self.device)).log_prob(rollout_reference)\n",
    "                    rollout_comparison.append(temp_comparision)\n",
    "                time_step_comparision.append(rollout_comparison)    \n",
    "            self.test_run_comparision.extend(time_step_comparision)\n",
    "    \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Parameters #######\n",
    "n_epochs=60\n",
    "#min_timesteps=20\n",
    "#n_rollout=10\n",
    "#n_state_enc =24\n",
    "#n_state_dec =12\n",
    "min_timesteps=10\n",
    "n_rollout=5\n",
    "n_test=1\n",
    "n_input=6\n",
    "n_output=3\n",
    "n_state_enc =4\n",
    "n_state_dec =5 \n",
    "learning_rate=0.0005\n",
    "gen_model=2\n",
    "pred_model=2\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Initialise the neural network #######\n",
    "\n",
    "network=NN_structure(n_epochs,min_timesteps,n_rollout,n_test,n_input,n_output,n_state_enc,n_state_dec,learning_rate,gen_model,pred_model,device)\n",
    "print(\"Training has started\")\n",
    "network.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [#] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-50.0000, -60.5453,  10.0000,   9.3482,   0.0000,   0.0000],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-58.6157,   9.9482,   3.0000], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 0\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4011,   9.0604,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-56.5660,  10.5482,   3.0000], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 1\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4045,   9.0611,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-54.3964,  11.1482,   3.0000], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 2.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 2\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4048,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-52.1426,  11.3894,   1.2057], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 3.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 3\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-49.8577,  11.4595,   0.3509], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 4.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 4\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-48.1000, -58.6157,   9.0000,   9.9482,  -5.0000,   3.0000],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-56.5660,  10.5482,   3.0000], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1., 1., 1., 1., 1.], device='cuda:0', grad_fn=<CatBackward0>) 1\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4031,   9.0608,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-54.3964,  11.1482,   3.0000], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1., 1., 1., 1., 2.], device='cuda:0', grad_fn=<CatBackward0>) 2\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4048,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-52.1426,  11.3894,   1.2057], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1., 1., 1., 1., 3.], device='cuda:0', grad_fn=<CatBackward0>) 3\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-49.8577,  11.4595,   0.3509], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([1., 1., 1., 1., 4.], device='cuda:0', grad_fn=<CatBackward0>) 4\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-47.5648,  11.4699,   0.0518], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([1., 1., 1., 1., 5.], device='cuda:0', grad_fn=<CatBackward0>) 5\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-46.4000, -56.5660,   8.0000,  10.5482,  -5.0000,   3.0000],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-54.3964,  11.1482,   3.0000], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1., 1., 1., 1., 2.], device='cuda:0', grad_fn=<CatBackward0>) 2\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4039,   9.0610,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-52.1426,  11.3894,   1.2057], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1., 1., 1., 1., 3.], device='cuda:0', grad_fn=<CatBackward0>) 3\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-49.8577,  11.4595,   0.3509], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1., 1., 1., 1., 4.], device='cuda:0', grad_fn=<CatBackward0>) 4\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-47.5648,  11.4699,   0.0518], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([1., 1., 1., 1., 5.], device='cuda:0', grad_fn=<CatBackward0>) 5\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-45.2720,  11.4585,  -0.0570], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([1., 1., 1., 1., 6.], device='cuda:0', grad_fn=<CatBackward0>) 6\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-44.7614, -54.3964,   8.3856,  11.1482,   1.9279,   3.0000],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-52.1426,  11.3894,   1.2057], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1., 1., 1., 1., 3.], device='cuda:0', grad_fn=<CatBackward0>) 3\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4044,   9.0611,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-49.8577,  11.4595,   0.3509], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1., 1., 1., 1., 4.], device='cuda:0', grad_fn=<CatBackward0>) 4\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-47.5648,  11.4699,   0.0518], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1., 1., 1., 1., 5.], device='cuda:0', grad_fn=<CatBackward0>) 5\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-45.2720,  11.4585,  -0.0570], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([1., 1., 1., 1., 6.], device='cuda:0', grad_fn=<CatBackward0>) 6\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4050,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-42.9823,  11.4384,  -0.1004], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([1., 1., 1., 1., 7.], device='cuda:0', grad_fn=<CatBackward0>) 7\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-43.0544, -52.1426,   8.6849,  11.3894,   1.4964,   1.2057],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-49.8577,  11.4595,   0.3509], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1., 1., 1., 1., 4.], device='cuda:0', grad_fn=<CatBackward0>) 4\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4046,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-47.5648,  11.4699,   0.0518], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1., 1., 1., 1., 5.], device='cuda:0', grad_fn=<CatBackward0>) 5\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-45.2720,  11.4585,  -0.0570], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1., 1., 1., 1., 6.], device='cuda:0', grad_fn=<CatBackward0>) 6\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4050,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-42.9823,  11.4384,  -0.1004], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([1., 1., 1., 1., 7.], device='cuda:0', grad_fn=<CatBackward0>) 7\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-40.6970,  11.4142,  -0.1212], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([1., 1., 1., 1., 8.], device='cuda:0', grad_fn=<CatBackward0>) 8\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-41.2950, -49.8577,   8.9096,  11.4595,   1.1237,   0.3509],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-47.5648,  11.4699,   0.0518], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1., 1., 1., 1., 5.], device='cuda:0', grad_fn=<CatBackward0>) 5\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4047,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-45.2720,  11.4585,  -0.0570], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1., 1., 1., 1., 6.], device='cuda:0', grad_fn=<CatBackward0>) 6\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4050,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-42.9823,  11.4384,  -0.1004], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1., 1., 1., 1., 7.], device='cuda:0', grad_fn=<CatBackward0>) 7\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-40.6970,  11.4142,  -0.1212], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([1., 1., 1., 1., 8.], device='cuda:0', grad_fn=<CatBackward0>) 8\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-38.4169,  11.3874,  -0.1338], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([1., 1., 1., 1., 9.], device='cuda:0', grad_fn=<CatBackward0>) 9\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-39.5008, -47.5648,   9.0316,  11.4699,   0.6098,   0.0518],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-45.2720,  11.4585,  -0.0570], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1., 1., 1., 1., 6.], device='cuda:0', grad_fn=<CatBackward0>) 6\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4048,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-42.9823,  11.4384,  -0.1004], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1., 1., 1., 1., 7.], device='cuda:0', grad_fn=<CatBackward0>) 7\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-40.6970,  11.4142,  -0.1212], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1., 1., 1., 1., 8.], device='cuda:0', grad_fn=<CatBackward0>) 8\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-38.4169,  11.3874,  -0.1338], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([1., 1., 1., 1., 9.], device='cuda:0', grad_fn=<CatBackward0>) 9\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-36.1422,  11.3589,  -0.1423], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([ 1.,  1.,  1.,  1., 10.], device='cuda:0', grad_fn=<CatBackward0>) 10\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-3.7694e+01, -4.5272e+01,  9.0374e+00,  1.1458e+01,  2.9143e-02,\n",
      "        -5.6989e-02], device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-42.9823,  11.4384,  -0.1004], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 7.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 7\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4048,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-40.6970,  11.4142,  -0.1212], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 8.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 8\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-38.4169,  11.3874,  -0.1338], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 9.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 9\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-36.1422,  11.3589,  -0.1423], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 10.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 10\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-33.8734,  11.3295,  -0.1474], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 11.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 11\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-35.8968, -42.9823,   8.9336,  11.4384,  -0.5190,  -0.1004],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-40.6970,  11.4142,  -0.1212], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 8.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 8\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-38.4169,  11.3874,  -0.1338], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 9.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 9\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-36.1422,  11.3589,  -0.1423], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 10.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 10\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-33.8734,  11.3295,  -0.1474], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 11.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 11\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-31.6104,  11.2999,  -0.1477], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 12.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 12\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "\n",
      "\n",
      "Before rollout, the input is  tensor([-34.1308, -40.6970,   8.7266,  11.4142,  -1.0348,  -0.1212],\n",
      "       device='cuda:0')\n",
      "for rollout 0 rollout_reference is  tensor([-38.4169,  11.3874,  -0.1338], device='cuda:0')\n",
      "for rollout 0 decoder_input  is  tensor([1.0000, 1.0000, 1.0000, 1.0000, 9.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 9\n",
      "for rollout 0 rollout_prediction is  tensor([-41.4049,   9.0612,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 1 rollout_reference is  tensor([-36.1422,  11.3589,  -0.1423], device='cuda:0')\n",
      "for rollout 1 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 10.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 10\n",
      "for rollout 1 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 2 rollout_reference is  tensor([-33.8734,  11.3295,  -0.1474], device='cuda:0')\n",
      "for rollout 2 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 11.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 11\n",
      "for rollout 2 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 3 rollout_reference is  tensor([-31.6104,  11.2999,  -0.1477], device='cuda:0')\n",
      "for rollout 3 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 12.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 12\n",
      "for rollout 3 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "for rollout 4 rollout_reference is  tensor([-29.3533,  11.2718,  -0.1406], device='cuda:0')\n",
      "for rollout 4 decoder_input  is  tensor([ 1.0000,  1.0000,  1.0000,  1.0000, 13.0000], device='cuda:0',\n",
      "       grad_fn=<CatBackward0>) 13\n",
      "for rollout 4 rollout_prediction is  tensor([-41.4050,   9.0613,   0.1079], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test the network\n",
    "\n",
    "####### Load the neural network weights from saved models #######\n",
    "\n",
    "loaded_network=NN_structure(n_epochs,min_timesteps,n_rollout,n_test,n_input,n_output,n_state_enc,n_state_dec,learning_rate,gen_model,pred_model,device)\n",
    "loaded_network.load_model_weights(\"reduced_timesteps10_Rollout_5_added_time_step_to_decoder_input\")\n",
    "\n",
    "\n",
    "test_keys=[keys_for_testing[15]]\n",
    "test_results=loaded_network.test(test_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-58.615685, 9.948225, 3.0, -41.40107, 9.060353, 0.10786998],\n",
       "  [-56.56604, 10.548224, 3.0, -41.40448, 9.06115, 0.1079319],\n",
       "  [-54.396393, 11.148225, 3.0, -41.404797, 9.061213, 0.10793239],\n",
       "  [-52.142635, 11.38936, 1.2056793, -41.404884, 9.061232, 0.10793246],\n",
       "  [-49.857746, 11.459533, 0.35085994, -41.404926, 9.061241, 0.10793276]],\n",
       " [[-56.56604, 10.548224, 3.0, -41.40306, 9.060805, 0.10789752],\n",
       "  [-54.396393, 11.148225, 3.0, -41.40479, 9.061211, 0.10793215],\n",
       "  [-52.142635, 11.38936, 1.2056793, -41.404884, 9.061232, 0.10793246],\n",
       "  [-49.857746, 11.459533, 0.35085994, -41.404926, 9.061241, 0.10793276],\n",
       "  [-47.564804, 11.46989, 0.051787715, -41.404945, 9.061247, 0.107933074]],\n",
       " [[-54.396393, 11.148225, 3.0, -41.403942, 9.061008, 0.10791166],\n",
       "  [-52.142635, 11.38936, 1.2056793, -41.404884, 9.061232, 0.10793242],\n",
       "  [-49.857746, 11.459533, 0.35085994, -41.404926, 9.061241, 0.10793276],\n",
       "  [-47.564804, 11.46989, 0.051787715, -41.404945, 9.061247, 0.107933074],\n",
       "  [-45.271965, 11.458492, -0.05698871, -41.40496, 9.061249, 0.10793345]],\n",
       " [[-52.142635, 11.38936, 1.2056793, -41.404366, 9.061106, 0.107919246],\n",
       "  [-49.857746, 11.459533, 0.35085994, -41.404926, 9.061241, 0.10793276],\n",
       "  [-47.564804, 11.46989, 0.051787715, -41.404945, 9.061247, 0.107933074],\n",
       "  [-45.271965, 11.458492, -0.05698871, -41.40496, 9.061249, 0.10793345],\n",
       "  [-42.982277, 11.438406, -0.100432016, -41.404972, 9.061253, 0.1079337]],\n",
       " [[-49.857746, 11.459533, 0.35085994, -41.404583, 9.061156, 0.1079236],\n",
       "  [-47.564804, 11.46989, 0.051787715, -41.404945, 9.061247, 0.107933074],\n",
       "  [-45.271965, 11.458492, -0.05698871, -41.40496, 9.061249, 0.10793345],\n",
       "  [-42.982277, 11.438406, -0.100432016, -41.404972, 9.061253, 0.1079337],\n",
       "  [-40.69702, 11.414159, -0.12123386, -41.40498, 9.0612545, 0.10793397]],\n",
       " [[-47.564804, 11.46989, 0.051787715, -41.4047, 9.061186, 0.10792631],\n",
       "  [-45.271965, 11.458492, -0.05698871, -41.40496, 9.061249, 0.10793345],\n",
       "  [-42.982277, 11.438406, -0.100432016, -41.404972, 9.061253, 0.1079337],\n",
       "  [-40.69702, 11.414159, -0.12123386, -41.40498, 9.0612545, 0.10793397],\n",
       "  [-38.416862, 11.387408, -0.13375516, -41.404987, 9.061256, 0.10793418]],\n",
       " [[-45.271965, 11.458492, -0.05698871, -41.404778, 9.061203, 0.1079281],\n",
       "  [-42.982277, 11.438406, -0.100432016, -41.404972, 9.061253, 0.1079337],\n",
       "  [-40.69702, 11.414159, -0.12123386, -41.40498, 9.0612545, 0.10793397],\n",
       "  [-38.416862, 11.387408, -0.13375516, -41.404987, 9.061256, 0.10793418],\n",
       "  [-36.142227, 11.358948, -0.14229967, -41.40499, 9.061258, 0.107934386]],\n",
       " [[-42.982277, 11.438406, -0.100432016, -41.404827, 9.061216, 0.10792947],\n",
       "  [-40.69702, 11.414159, -0.12123386, -41.40498, 9.0612545, 0.10793397],\n",
       "  [-38.416862, 11.387408, -0.13375516, -41.404987, 9.061256, 0.10793418],\n",
       "  [-36.142227, 11.358948, -0.14229967, -41.40499, 9.061258, 0.107934386],\n",
       "  [-33.873386, 11.329469, -0.14739901, -41.405, 9.061258, 0.107934535]],\n",
       " [[-40.69702, 11.414159, -0.12123386, -41.40487, 9.061226, 0.10793048],\n",
       "  [-38.416862, 11.387408, -0.13375516, -41.404987, 9.061256, 0.10793418],\n",
       "  [-36.142227, 11.358948, -0.14229967, -41.40499, 9.061258, 0.107934386],\n",
       "  [-33.873386, 11.329469, -0.14739901, -41.405, 9.061258, 0.107934535],\n",
       "  [-31.610447, 11.299921, -0.14773439, -41.405003, 9.06126, 0.107934654]],\n",
       " [[-38.416862, 11.387408, -0.13375516, -41.404892, 9.061233, 0.1079313],\n",
       "  [-36.142227, 11.358948, -0.14229967, -41.40499, 9.061258, 0.107934386],\n",
       "  [-33.873386, 11.329469, -0.14739901, -41.405, 9.061258, 0.107934535],\n",
       "  [-31.610447, 11.299921, -0.14773439, -41.405003, 9.06126, 0.107934654],\n",
       "  [-29.353273, 11.271804, -0.14058802, -41.405006, 9.06126, 0.10793474]]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.test_run_comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3360/1318344120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mtime_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_run_comparision\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     '''\n\u001b[0;32m     25\u001b[0m     \u001b[0mpos_tref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_run_comparision\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#print(len(test_results.test_run_comparision[0][1]))\n",
    "\n",
    "#test_results.test_run_comparision[19][:]\n",
    "\n",
    "\n",
    "# Plot the results only for the HDV\n",
    "pos_t=[]\n",
    "vel_t=[]\n",
    "acc_t=[]\n",
    "pos_tref=[]\n",
    "vel_tref=[]\n",
    "acc_tref=[]\n",
    "pos_t_hdv=[]\n",
    "vel_t_hdv=[]\n",
    "acc_t_hdv=[]\n",
    "pos_tref_hdv=[]\n",
    "vel_tref_hdv=[]\n",
    "acc_tref_hdv=[]\n",
    "\n",
    "# set which timestep to plot\n",
    "time_step=10\n",
    "\n",
    "for index in range(len(test_results.test_run_comparision[time_step])):\n",
    "    '''\n",
    "    pos_tref.append(test_results.test_run_comparision[time_step][index][0])\n",
    "    vel_tref.append(test_results.test_run_comparision[time_step][index][2])\n",
    "    acc_tref.append(test_results.test_run_comparision[time_step][index][4])\n",
    "    pos_t.append(test_results.test_run_comparision[time_step][index][6])\n",
    "    vel_t.append(test_results.test_run_comparision[time_step][index][8])\n",
    "    acc_t.append(test_results.test_run_comparision[time_step][index][10])\n",
    "    \n",
    "    #pos_t_hdv.append(test_results.test_run_comparision[time_step][index][1])\n",
    "    #vel_t_hdv.append(test_results.test_run_comparision[time_step][index][3])\n",
    "    #acc_t_hdv.append(test_results.test_run_comparision[time_step][index][5])\n",
    "    #pos_tref_hdv.append(test_results.test_run_comparision[time_step][index][7])\n",
    "    #vel_tref_hdv.append(test_results.test_run_comparision[time_step][index][9])\n",
    "    #acc_tref_hdv.append(test_results.test_run_comparision[time_step][index][11])\n",
    "\n",
    "    \n",
    "    pos_tref_hdv.append(test_results.test_run_comparision[time_step][index][1])\n",
    "    vel_tref_hdv.append(test_results.test_run_comparision[time_step][index][3])\n",
    "    acc_tref_hdv.append(test_results.test_run_comparision[time_step][index][5])\n",
    "    pos_t_hdv.append(test_results.test_run_comparision[time_step][index][7])\n",
    "    vel_t_hdv.append(test_results.test_run_comparision[time_step][index][9])\n",
    "    acc_t_hdv.append(test_results.test_run_comparision[time_step][index][11])\n",
    "    '''\n",
    "\n",
    "    pos_tref_hdv.append(test_results.test_run_comparision[time_step][index][0])\n",
    "    vel_tref_hdv.append(test_results.test_run_comparision[time_step][index][1])\n",
    "    acc_tref_hdv.append(test_results.test_run_comparision[time_step][index][2])\n",
    "    pos_t_hdv.append(test_results.test_run_comparision[time_step][index][3])\n",
    "    vel_t_hdv.append(test_results.test_run_comparision[time_step][index][4])\n",
    "    acc_t_hdv.append(test_results.test_run_comparision[time_step][index][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data=data_irl[str(keys_for_testing[10])]    \n",
    "\n",
    "pos_t_hdv=[]\n",
    "vel_t_hdv=[]\n",
    "acc_t_hdv=[]\n",
    "pos_tref_hdv=[]\n",
    "vel_tref_hdv=[]\n",
    "acc_tref_hdv=[]\n",
    "\n",
    "    for index in range(len(plot_data[0])):\n",
    "\n",
    "        pos_t_hdv.append(test_results.test_run_comparision[time_step][index][1].detach().cpu().numpy())\n",
    "        vel_t_hdv.append(test_results.test_run_comparision[time_step][index][3].detach().cpu().numpy())\n",
    "        acc_t_hdv.append(test_results.test_run_comparision[time_step][index][5].detach().cpu().numpy())\n",
    "        pos_tref_hdv.append(test_results.test_run_comparision[time_step][index][7].detach().cpu().numpy())\n",
    "        vel_tref_hdv.append(test_results.test_run_comparision[time_step][index][9].detach().cpu().numpy())\n",
    "        acc_tref_hdv.append(test_results.test_run_comparision[time_step][index][11].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting outputs #\n",
    "import matplotlib.colors as mcolors\n",
    "####### For X - lateral#########\n",
    "fig, ax = plt.subplots()\n",
    "#plt.plot(y_ref,x_ref,'r',linewidth=2.0,label=\"Actual\")\n",
    "#plt.plot(y_pred,x_pred,'b',linewidth=2.0,label=\"Predicted\")\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(pos_t_hdv,mcolors.CSS4_COLORS['salmon'],linewidth=2.0,label=\"Actual\")\n",
    "plt.plot(pos_tref_hdv,mcolors.CSS4_COLORS['limegreen'],linewidth=2.0,label=\"Predicted\")\n",
    "plt.xlabel('Time in (1/10)s')\n",
    "plt.ylabel('Position along the road m')\n",
    "plt.title('Comparision_of_position_along_road')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('graphs/irl_graphs/Comparision_rollout10_timestep_min20_posref_pospred_g1_p2_lr0005.png')\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(facecolor='white')\n",
    "plt.plot(vel_t_hdv,mcolors.CSS4_COLORS['salmon'],linewidth=2.0,label=\"Actual\")\n",
    "plt.plot(vel_tref_hdv,mcolors.CSS4_COLORS['limegreen'],linewidth=2.0,label=\"Predicted\")\n",
    "plt.xlabel('Time in (1/10)s')\n",
    "plt.ylabel('Velocity along the road in m/s')\n",
    "plt.title('Comparision_Lateral_Velocities')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('graphs/irl_graphs/Comparision_rollout10_timestep_min20_vref_vpre_g1_p2_lr0005.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-46.4000, device='cuda:0'),\n",
       " tensor(-53.2063, device='cuda:0'),\n",
       " tensor(8., device='cuda:0'),\n",
       " tensor(7.4680, device='cuda:0'),\n",
       " tensor(-5., device='cuda:0'),\n",
       " tensor(-1.3502, device='cuda:0'),\n",
       " tensor(-31.8437, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       " tensor(-27.8377, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       " tensor(4.1773, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       " tensor(9.0293, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       " tensor(-1.2700, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       " tensor(0.0087, device='cuda:0', grad_fn=<UnbindBackward0>)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.test_run_comparision[1][0]\n",
    "#len(test_results.test_run_comparision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3],dtype=torch.float)\n",
    "b=torch.tensor([4],dtype=torch.float)\n",
    "c=torch.cat((a,b),0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19aadfa955e96a5e7fdf9b64cb086b0ad6aa114b0d422a86116b9caa90456979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
