{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy.linalg as LA\n",
    "import random\n",
    "import pandas as pd\n",
    "from numpy import inf\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "import pyprind\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/trajectories-0400-0415.csv')\n",
    "df2 = pd.read_csv('data/trajectories-0500-0515.csv')\n",
    "df3 = pd.read_csv('data/trajectories-0515-0530.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import train_test_split\\nimport numpy\\n\\nwith open(\"datafile.txt\", \"rb\") as f:\\n   data = f.read().split(\\'\\n\\')\\n   data = numpy.array(data)  #convert array to numpy type array\\n\\n   x_train ,x_test = train_test_split(data,test_size=0.5)       #test_size=0.5(whole_data)\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################### DO NOT TOUCH THIS SNIPPET ############################################### \n",
    "df1 = pd.read_csv('data/trajectories-0400-0415.csv')\n",
    "df2 = pd.read_csv('data/trajectories-0500-0515.csv')\n",
    "df3 = pd.read_csv('data/trajectories-0515-0530.csv')\n",
    "\n",
    "## Adding two empty columns for velocities ##\n",
    "df1['V_X']=np.nan\n",
    "df1['V_Y']=np.nan\n",
    "\n",
    "lane=7\n",
    "filtered_df=df1.loc[df1['Lane_ID']==lane]\n",
    "list_mergingvehicles=list(filtered_df.Vehicle_ID.unique())\n",
    "df1_merging_outliers= [5,210,376,388,409,458,465,743,1005,1097,1133,1215,1408,1724,1812,1909,2387,2438,1778,2911]\n",
    "\n",
    "#print(list_mergingvehicles)\n",
    "\n",
    "\n",
    "####### Filtering data #########\n",
    "    ####### AND ####### \n",
    "#### Calculating Velocities ####\n",
    "vehicles_actually_merging=[]\n",
    "vehicle_row_indices={}\n",
    "for vehicle in list_mergingvehicles:\n",
    "    if vehicle not in df1_merging_outliers:\n",
    "        #print(vehicle)\n",
    "        vehicles_actually_merging.append(vehicle)\n",
    "        temp=df1.loc[(df1['Vehicle_ID']==vehicle) & (df1['Lane_ID']==7)]\n",
    "        temp_row_indices=list(temp.loc[temp['Vehicle_ID']==vehicle].index.to_numpy())\n",
    "               \n",
    "        temp_extra_time=[]\n",
    "        extra_time_steps=15\n",
    "        for i in range(extra_time_steps):\n",
    "            temp_extra_time.append(temp_row_indices[len(temp_row_indices)-1]+i)\n",
    "        temp_row_indices.extend(temp_extra_time)\n",
    "        \n",
    "        key=str(vehicle)\n",
    "        vehicle_row_indices[key]=temp_row_indices\n",
    "\n",
    "        # Velocity #\n",
    "\n",
    "        for row_index in temp_row_indices[1:]:\n",
    "                vel_X=0\n",
    "                vel_Y=0                \n",
    "                dt=0.1 # Sec\n",
    "                                \n",
    "                vel_X=(df1.iat[row_index,4]-df1.iat[row_index-1,4])/dt\n",
    "                df1.iat[row_index,18]=round(vel_X,3)\n",
    "                \n",
    "                vel_y=(df1.iat[row_index,5]-df1.iat[row_index-1,5])/dt\n",
    "                df1.iat[row_index,19]=round(vel_y,3)\n",
    "\n",
    "dict_taining_data={}\n",
    "\n",
    "# sample 10% of actually merging  cars #\n",
    "vehicles_for_training=sample(vehicles_actually_merging,int(0.9*len(vehicles_actually_merging)))\n",
    "vehicles_for_testing=[]\n",
    "\n",
    "for vehicle in vehicles_actually_merging:\n",
    "    if vehicle not in vehicles_for_training:\n",
    "        vehicles_for_testing.append(vehicle)\n",
    "\n",
    "for vehicle in vehicles_for_training:\n",
    "    key=str(vehicle)\n",
    "    data_index=vehicle_row_indices[key]\n",
    "    ref_trajectory=[]\n",
    "    for index in data_index[1:]:\n",
    "        row=df1.iloc[index]\n",
    "        temp_traj_point=[df1.iat[index,4],df1.iat[index,5],df1.iat[index,18],df1.iat[index,19]] # x,y,vx,vy\n",
    "        ref_trajectory.append(temp_traj_point)\n",
    "    dict_taining_data[key]=ref_trajectory    \n",
    "    temp=df1.loc[(df1['Vehicle_ID']==vehicle)]\n",
    "\n",
    "############### coud be used for train and test split ############### \n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "\n",
    "with open(\"datafile.txt\", \"rb\") as f:\n",
    "   data = f.read().split('\\n')\n",
    "   data = numpy.array(data)  #convert array to numpy type array\n",
    "\n",
    "   x_train ,x_test = train_test_split(data,test_size=0.5)       #test_size=0.5(whole_data)\n",
    "'''    \n",
    "############################################### DO NOT TOUCH THIS SNIPPET ############################################### \n",
    "############################################### DO NOT TOUCH THIS SNIPPET ############################################### \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_data={}\n",
    "for vehicle in vehicles_for_testing:\n",
    "    key=str(vehicle)\n",
    "    data_index=vehicle_row_indices[key]\n",
    "    ref_trajectory=[]\n",
    "    for index in data_index[1:]:\n",
    "        row=df1.iloc[index]\n",
    "        temp_traj_point=[df1.iat[index,4],df1.iat[index,5],df1.iat[index,18],df1.iat[index,19]] # x,y,vx,vy\n",
    "        ref_trajectory.append(temp_traj_point)\n",
    "    dict_test_data[key]=ref_trajectory    \n",
    "    #temp=df1.loc[(df1['Vehicle_ID']==vehicle)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interaction Tupple ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################################################\n",
    "################################ AIS_gen ################################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class GenerateAis1(nn.Module):\n",
    "\n",
    "    #def __init__(self,n_input,n_state,n_psi2_in=64,n_psi2_out=128):\n",
    "    def __init__(self,n_input,n_state,n_psi2_in=8,n_psi2_out=16):\n",
    "        super(GenerateAis1,self).__init__()\n",
    "        self.PSI_layer1=nn.Linear(n_input,n_psi2_in)     # Use RELU after\n",
    "        self.PSI_layer2=nn.Linear(n_psi2_in,n_psi2_out)      # Use RELU after\n",
    "        self.PSI_layer3=nn.GRUCell(n_psi2_out,n_state)       # This is the Gated layer\n",
    "\n",
    "    def forward(self,x,h):\n",
    "        #x=torch.transpose(x,0,1)\n",
    "        #h=torch.transpose(h,0,1)\n",
    "        x=torch.relu(self.PSI_layer1(x))\n",
    "        x=torch.relu(self.PSI_layer2(x))\n",
    "        h=self.PSI_layer3(x,h)\n",
    "        return h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "################################ AIS_pred ###############################\n",
    "\n",
    "################################ Model 1 ################################ \n",
    "\n",
    "class PredictAis1(nn.Module):\n",
    "    \n",
    "    #def __init__(self,n_output,n_state,n_phi2_in=16,n_phi2_out=8):\n",
    "    def __init__(self,n_output,n_state,n_phi2_in=16,n_phi2_out=32):\n",
    "        super(PredictAis1,self).__init__()\n",
    "        self.PHI_layer1=nn.Linear(n_state,n_phi2_in)  # Use RELU after\n",
    "        self.PHI_layer2=nn.Linear(n_phi2_in,n_phi2_out)     # Use RELU after\n",
    "        self.PHI_layer3=nn.Linear(n_phi2_out,n_output)         # mean vector of a unit-variance multivariate Gaussian distribution, samples from which are used to predict the next observation\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=torch.relu(self.PHI_layer1(x))\n",
    "        x=torch.relu(self.PHI_layer2(x))\n",
    "        output=self.PHI_layer3(x)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_structure(object):\n",
    "    def __init__(self,n_train,n_test,n_input,n_output,n_state,learning_rate,ais_gen_model,ais_pred_model,device):\n",
    "        self.n_train=n_train\n",
    "        self.n_test=n_test\n",
    "        self.n_input=n_input\n",
    "        self.n_output=n_output\n",
    "        self.n_state=n_state    # Hidden state size in RNN\n",
    "        self.learning_rate=learning_rate                \n",
    "        self.device=device\n",
    "        self.ais_gen_model=ais_gen_model\n",
    "        self.ais_pred_model=ais_pred_model\n",
    "\n",
    "        if ais_gen_model==1:\n",
    "            self.gen_model=GenerateAis1(self.n_input,self.n_state).to(self.device)      \n",
    "        \n",
    "        if ais_pred_model==1:\n",
    "            self.pred_model=PredictAis1(self.n_output,self.n_state).to(self.device)\n",
    "\n",
    "\n",
    "    def save_model_weights(self,text=\"_\"):\n",
    "        name_gen_path=\"trained_models/ais_gen\"+str(self.ais_gen_model)+\"_pred\"+str(self.ais_pred_model)+\"_epochs\"+str(self.n_train)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state)+text+\".pth\"\n",
    "        torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "\n",
    "        name_pred_path=\"trained_models/ais_pred\"+str(self.ais_pred_model)+\"_gen\"+str(self.ais_gen_model)+\"_epochs\"+str(self.n_train)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state)+text+\".pth\"\n",
    "        torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "\n",
    "        return \"saved\"\n",
    "    \n",
    "    def load_model_weights(self,text=\"_\"):\n",
    "        name_gen_path=\"trained_models/ais_gen\"+str(self.ais_gen_model)+\"_pred\"+str(self.ais_pred_model)+\"_epochs\"+str(self.n_train)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state)+text+\".pth\"\n",
    "        #torch.save(self.gen_model.state_dict(),name_gen_path)\n",
    "        self.gen_model.load_state_dict(torch.load(name_gen_path))\n",
    "        self.gen_model.eval()\n",
    "\n",
    "\n",
    "        name_pred_path=\"trained_models/ais_pred\"+str(self.ais_pred_model)+\"_gen\"+str(self.ais_gen_model)+\"_epochs\"+str(self.n_train)+\"_learning_rate\"+str(self.learning_rate)+\"_hidden_states\"+str(self.n_state)+text+\".pth\"\n",
    "        #torch.save(self.pred_model.state_dict(),name_pred_path)\n",
    "        self.pred_model.load_state_dict(torch.load(name_pred_path))\n",
    "        self.pred_model.eval()\n",
    "\n",
    "        return \"loaded\"\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        train_bar=pyprind.ProgBar(self.n_train)\n",
    "        self.optimizer = torch.optim.Adam(list(self.gen_model.parameters()) + list(self.pred_model.parameters()), lr=self.learning_rate, amsgrad=True)\n",
    "        loss=nn.MSELoss()\n",
    "        #torch.distributions.MultivariateNormal(obs_pred_next_probs[0,:], torch.eye(obs_pred_next_probs[0,:].shape[0]).to(device)).log_prob(obs[step+1,:])\n",
    "\n",
    "        for epochs in range(self.n_train):\n",
    "            train_bar.update()\n",
    "            #print(\"epoch\")\n",
    "            training_car_list=list(dict_taining_data.keys())\n",
    "            training_car_list=sample(training_car_list,len(training_car_list))# Random order for training\n",
    "\n",
    "            \n",
    "            for car in training_car_list:\n",
    "                trajectory_data=dict_taining_data[str(car)]\n",
    "\n",
    "                # Ais initialization\n",
    "                ais=0.5*torch.ones(self.n_state,dtype=torch.float).to(self.device)\n",
    "\n",
    "                car_loss=0\n",
    "                    \n",
    "                for time in range(len(trajectory_data)-1): \n",
    "                    origin_offset=np.array(trajectory_data[0][0:2]) # only for position\n",
    "                    \n",
    "                    input_vector=np.array(trajectory_data[time])\n",
    "                    input_vector[0:2]=input_vector[0:2]-origin_offset\n",
    "\n",
    "                    ref_vector=np.array(trajectory_data[time+1])\n",
    "                    ref_vector[0:2]=ref_vector[0:2]-origin_offset\n",
    "\n",
    "                    train_input=torch.tensor(input_vector,dtype=torch.float).to(self.device)\n",
    "                    ref_output=torch.tensor(ref_vector,dtype=torch.float).to(self.device)\n",
    "\n",
    "                    ais=self.gen_model(train_input,ais)\n",
    "                    pred_output=self.pred_model(ais)\n",
    "                    \n",
    "                    car_loss+=loss(pred_output,ref_output)\n",
    "                    \n",
    "                self.optimizer.zero_grad()\n",
    "                car_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        print(\"saving model weights\")\n",
    "        status=self.save_model_weights()\n",
    "\n",
    "        return status\n",
    "\n",
    "\n",
    "    def test(self,vehicle):\n",
    "\n",
    "        # Testing for only one car data\n",
    "        # We test predictions based only newest observation\n",
    "        # Later we will test it only using initial condition\n",
    "\n",
    "        dict_test_results={}\n",
    "\n",
    "        for epochs in range(self.n_test):\n",
    "            test_car=vehicle            \n",
    "        \n",
    "            trajectory_data=dict_test_data[str(test_car)]\n",
    "\n",
    "            # Ais initialization\n",
    "            ais=0.5*torch.ones(self.n_state,dtype=torch.float).to(self.device)\n",
    "\n",
    "            car_loss=0\n",
    "            previous_prediction=0\n",
    "\n",
    "            test_results_trajectory=[]\n",
    "            for time in range(len(trajectory_data)-1): \n",
    "\n",
    "                temp_test_info=[]\n",
    "                origin_offset=np.array(trajectory_data[0][0:2]) # only for position\n",
    "                \n",
    "                input_vector=np.array(trajectory_data[time])\n",
    "                input_vector[0:2]=input_vector[0:2]-origin_offset\n",
    "                \n",
    "                #if time==0:\n",
    "                #    temp_test_info.extend(list(input_vector))\n",
    "                #    temp_test_info.extend(list(input_vector))\n",
    "\n",
    "                ref_vector=np.array(trajectory_data[time+1])\n",
    "                ref_vector[0:2]=ref_vector[0:2]-origin_offset\n",
    "\n",
    "                temp_test_info.extend(list(ref_vector))\n",
    "\n",
    "                train_input=torch.tensor(input_vector,dtype=torch.float).to(self.device)\n",
    "                ref_output=torch.tensor(ref_vector,dtype=torch.float).to(self.device)\n",
    "\n",
    "                ais=self.gen_model(train_input,ais)\n",
    "                pred_output=self.pred_model(ais)\n",
    "\n",
    "                pred_vector=pred_output.detach().cpu().numpy()\n",
    "\n",
    "                temp_test_info.extend(list(pred_vector))\n",
    "\n",
    "                test_results_trajectory.append(temp_test_info)\n",
    "            \n",
    "            dict_test_results[str(test_car)]=test_results_trajectory\n",
    "\n",
    "\n",
    "        return dict_test_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Parameters #######\n",
    "#n_train=len(sampled_index_all_init)\n",
    "n_train=500\n",
    "n_test=1\n",
    "n_input=4\n",
    "n_output=4\n",
    "n_state =24 \n",
    "learning_rate=0.0003\n",
    "gen_model=1\n",
    "pred_model=1\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 05:01:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'saved'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Initialise the neural network #######\n",
    "\n",
    "network=NN_structure(n_train,n_test,n_input,n_output,n_state,learning_rate,gen_model,pred_model,device)\n",
    "print(\"Training has started\")\n",
    "network.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loaded'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Load the neural network weights from saved models #######\n",
    "\n",
    "loaded_network=NN_structure(n_train,n_test,n_input,n_output,n_state,learning_rate,gen_model,pred_model,device)\n",
    "loaded_network.load_model_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_car=vehicles_for_testing[13]\n",
    "predicted_outputs=loaded_network.test(test_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting outputs #\n",
    "\n",
    "\n",
    "x_ref=[]\n",
    "y_ref=[]\n",
    "vx_ref=[]\n",
    "vy_ref=[]\n",
    "x_pred=[]\n",
    "y_pred=[]\n",
    "vx_pred=[]\n",
    "vy_pred=[]\n",
    "\n",
    "for elem in predicted_outputs[str(test_car)]:\n",
    "    x_ref.append(-elem[0])\n",
    "    y_ref.append(elem[1])\n",
    "    vx_ref.append(elem[2])\n",
    "    vy_ref.append(elem[3])\n",
    "    x_pred.append(-elem[4])\n",
    "    y_pred.append(elem[5])\n",
    "    vx_pred.append(elem[6])\n",
    "    vy_pred.append(elem[7])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#plt.plot(y_ref,x_ref,'r',linewidth=2.0,label=\"Actual\")\n",
    "#plt.plot(y_pred,x_pred,'b',linewidth=2.0,label=\"Predicted\")\n",
    "plt.plot(y_ref,'r',linewidth=2.0,label=\"Actual\")\n",
    "plt.plot(y_pred,'b',linewidth=2.0,label=\"Predicted\")\n",
    "plt.savefig('graphs/Comparision_xref_xpred_justonecar_g1_p1_lr0003_g_8_16_p_16_32.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19aadfa955e96a5e7fdf9b64cb086b0ad6aa114b0d422a86116b9caa90456979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
